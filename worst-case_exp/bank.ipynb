{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bart/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n",
      "/home/bart/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "/home/bart/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n",
      "/home/bart/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 45211 rows 15 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 45211 values\n",
      "  -> model_class       : sklearn.tree._classes.DecisionTreeClassifier (default)\n",
      "  -> label             : CART\n",
      "  -> predict function  : <function yhat_proba_default at 0x7f859cd1be50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 0.0, mean = 0.062, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = 0.0, mean = 0.0, max = 0.0\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 45211 rows 15 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 45211 values\n",
      "  -> model_class       : interpret.glassbox.ebm.ebm.ExplainableBoostingClassifier (default)\n",
      "  -> label             : EBM\n",
      "  -> predict function  : <function yhat_proba_default at 0x7f859cd1be50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 4.61e-16, mean = 0.062, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.836, mean = 5.44e-05, max = 0.981\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 45211 rows 15 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 45211 values\n",
      "  -> model_class       : sklearn.linear_model._logistic.LogisticRegression (default)\n",
      "  -> label             : LR_l2\n",
      "  -> predict function  : <function yhat_proba_default at 0x7f859cd1be50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 5.87e-27, mean = 0.062, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.619, mean = -9.2e-07, max = 0.637\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 45211 rows 15 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 45211 values\n",
      "  -> model_class       : sklearn.naive_bayes.GaussianNB (default)\n",
      "  -> label             : GNB\n",
      "  -> predict function  : <function yhat_proba_default at 0x7f859cd1be50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 3.33e-302, mean = 0.131, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -1.0, mean = -0.069, max = 1.0\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 45211 rows 15 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 45211 values\n",
      "  -> model_class       : sklearn.linear_model._logistic.LogisticRegression (default)\n",
      "  -> label             : LR\n",
      "  -> predict function  : <function yhat_proba_default at 0x7f859cd1be50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 0.0, mean = 0.062, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -1.88e-05, mean = 1.65e-10, max = 1.2e-05\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 45211 rows 15 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 45211 values\n",
      "  -> model_class       : interpret.glassbox.skoperules.DecisionListClassifier (default)\n",
      "  -> label             : DL\n",
      "  -> predict function  : <function yhat_proba_default at 0x7f859cd1be50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 0.062, mean = 0.111, max = 0.977\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.977, mean = -0.0485, max = 0.938\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n"
     ]
    }
   ],
   "source": [
    "import dalex as dx\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from interpret.glassbox import DecisionListClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "clfs = {\n",
    "    \"CART\": DecisionTreeClassifier(random_state=1234),\n",
    "    \"EBM\": ExplainableBoostingClassifier(),\n",
    "    \"LR_l2\": LogisticRegression(penalty=\"l2\",random_state=1234),\n",
    "    \"GNB\": GaussianNB(),\n",
    "    \"LR\": LogisticRegression(penalty=\"none\", random_state=1234),\n",
    "    \"DL\": DecisionListClassifier(random_state=1234) \n",
    "}\n",
    "\n",
    "dataset = 'bank'\n",
    "clf_name = \"LR\"\n",
    "\n",
    "import worstcase_helper\n",
    "import importlib\n",
    "importlib.reload(worstcase_helper)\n",
    "\n",
    "preprocess, X, y = worstcase_helper.load_dataset_with_preprocess(clf_name, dataset)\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "def make_pipeline_clf(clf_name):\n",
    "    clf = make_pipeline(\n",
    "        preprocess,\n",
    "        clfs[clf_name]\n",
    "    )\n",
    "    return clf\n",
    "\n",
    "clf_cart = make_pipeline_clf(\"CART\")\n",
    "clf_cart.fit(X, y)\n",
    "\n",
    "clf_ebm = make_pipeline_clf(\"EBM\")\n",
    "clf_ebm.fit(X, y)\n",
    "\n",
    "clf_lr_l2 = make_pipeline_clf(\"LR_l2\")\n",
    "clf_lr_l2.fit(X, y)\n",
    "\n",
    "clf_gnb = make_pipeline_clf(\"GNB\")\n",
    "clf_gnb.fit(X, y)\n",
    "\n",
    "clf_lr = make_pipeline_clf(\"LR\")\n",
    "clf_lr.fit(X, y)\n",
    "\n",
    "clf_dl = make_pipeline_clf(\"DL\")\n",
    "clf_dl.fit(X, y)\n",
    "\n",
    "clf_cart_exp = dx.Explainer(clf_cart, X, y, label=\"CART\")\n",
    "clf_ebm_exp = dx.Explainer(clf_ebm, X, y, label=\"EBM\")\n",
    "clf_lr_l2_exp = dx.Explainer(clf_lr_l2, X, y, label=\"LR_l2\")\n",
    "clf_gnb_exp = dx.Explainer(clf_gnb, X, y, label=\"GNB\")\n",
    "clf_lr_exp = dx.Explainer(clf_lr, X, y, label=\"LR\")\n",
    "clf_dl_exp = dx.Explainer(clf_dl, X, y, label=\"DL\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Partial Dependence profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('onehotencoder',\n",
       "                                 OneHotEncoder(handle_unknown='ignore',\n",
       "                                               sparse=False),\n",
       "                                 ['job', 'marital', 'education', 'default',\n",
       "                                  'housing', 'loan', 'contact', 'month',\n",
       "                                  'poutcome']),\n",
       "                                ('standardscaler', StandardScaler(),\n",
       "                                 ['age', 'balance', 'day', 'duration',\n",
       "                                  'campaign', 'previous'])])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat = ['job', 'marital', 'education', 'default',\n",
    "                                  'housing', 'loan', 'contact', 'month',\n",
    "                                  'poutcome']\n",
    "cont_feat = ['age', 'balance', 'day', 'duration',\n",
    "                                  'campaign', 'previous']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating ceteris paribus: 100%|██████████| 9/9 [00:00<00:00, 12.28it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 9/9 [00:04<00:00,  1.81it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 9/9 [00:01<00:00,  7.48it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 9/9 [00:00<00:00, 11.18it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 9/9 [00:01<00:00,  8.22it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 9/9 [00:04<00:00,  2.18it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 6/6 [00:02<00:00,  2.63it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 6/6 [00:54<00:00,  9.10s/it]\n",
      "Calculating ceteris paribus: 100%|██████████| 6/6 [00:03<00:00,  1.97it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 6/6 [00:02<00:00,  2.04it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 6/6 [00:02<00:00,  2.17it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 6/6 [00:05<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "#categorical pd profiles\n",
    "pd_cart_cat = clf_cart_exp.model_profile(variable_type=\"categorical\", variables=cat_feat)\n",
    "\n",
    "pd_ebm_cat = clf_ebm_exp.model_profile(variables= cat_feat,\n",
    "                                         variable_type=\"categorical\")\n",
    "\n",
    "pd_lr_l2_cat = clf_lr_l2_exp.model_profile(variables= cat_feat,\n",
    "                                         variable_type=\"categorical\")\n",
    "\n",
    "pd_gnb_cat = clf_gnb_exp.model_profile(variables= cat_feat,\n",
    "                                         variable_type=\"categorical\")\n",
    "\n",
    "pd_lr_cat = clf_lr_exp.model_profile(variables= cat_feat,\n",
    "                                         variable_type=\"categorical\")\n",
    "\n",
    "pd_dl_cat = clf_dl_exp.model_profile(variables= cat_feat,\n",
    "                                         variable_type=\"categorical\")\n",
    "\n",
    "#continous pd profiles\n",
    "pd_cart = clf_cart_exp.model_profile(variables= cont_feat)\n",
    "\n",
    "pd_ebm = clf_ebm_exp.model_profile(variables= cont_feat)\n",
    "\n",
    "pd_lr_l2 = clf_lr_l2_exp.model_profile(variables= cont_feat)\n",
    "\n",
    "pd_gnb = clf_gnb_exp.model_profile(variables= cont_feat)\n",
    "\n",
    "pd_lr = clf_lr_exp.model_profile(variables= cont_feat)\n",
    "\n",
    "pd_dl = clf_dl_exp.model_profile(variables= cont_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Aggregated Profiles for Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_cart_cat.plot([pd_ebm_cat, pd_gnb_cat, pd_lr_cat, pd_lr_l2_cat, pd_dl_cat], variables=cat_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Aggregated Profiles for Continous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_cart.plot([pd_ebm, pd_gnb, pd_lr, pd_lr_l2, pd_dl], variables=cont_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURES ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calc(feat_gen, feat_comp):\n",
    "    return np.abs(np.subtract(feat_gen[\"_yhat_\"], feat_comp[\"_yhat_\"])).sum()\n",
    "\n",
    "def select_feat_result_cont(feat_name):\n",
    "    feat_cart = pd_cart.result[pd_cart.result[\"_vname_\"] == feat_name]\n",
    "    feat_ebm = pd_ebm.result[pd_ebm.result[\"_vname_\"] == feat_name]\n",
    "    feat_lr = pd_lr.result[pd_lr.result[\"_vname_\"] == feat_name]\n",
    "    feat_gnb = pd_gnb.result[pd_gnb.result[\"_vname_\"] == feat_name]\n",
    "    feat_lr_l2 = pd_lr_l2.result[pd_lr_l2.result[\"_vname_\"] == feat_name]\n",
    "    feat_dl = pd_dl.result[pd_dl.result[\"_vname_\"] == feat_name]\n",
    "    \n",
    "    #define generator clf\n",
    "    gen_res = feat_lr\n",
    "\n",
    "    cart_res = calc(gen_res, feat_cart)\n",
    "    ebm_res = calc(gen_res, feat_ebm)\n",
    "    lr_res = calc(gen_res, feat_lr)\n",
    "    gnb_res = calc(gen_res, feat_gnb)\n",
    "    lr_l2_res = calc(gen_res, feat_lr_l2)\n",
    "    dl_res = calc(gen_res, feat_dl)\n",
    "\n",
    "    dict_result = {\n",
    "        \"Param\": feat_name,\n",
    "        \"CART\": cart_res,\n",
    "        \"EBM\": ebm_res,\n",
    "        \"LR\": lr_res,\n",
    "        \"GNB\": gnb_res,\n",
    "        \"LR_l2\": lr_l2_res,\n",
    "        \"DL\": dl_res\n",
    "    }\n",
    "\n",
    "    return dict_result\n",
    "\n",
    "def select_feat_result_cat(feat_name):\n",
    "    feat_cart = pd_cart_cat.result[pd_cart_cat.result[\"_vname_\"] == feat_name]\n",
    "    feat_ebm = pd_ebm_cat.result[pd_ebm_cat.result[\"_vname_\"] == feat_name]\n",
    "    feat_lr = pd_lr_cat.result[pd_lr_cat.result[\"_vname_\"] == feat_name]\n",
    "    feat_gnb = pd_gnb_cat.result[pd_gnb_cat.result[\"_vname_\"] == feat_name]\n",
    "    feat_lr_l2 = pd_lr_l2_cat.result[pd_lr_l2_cat.result[\"_vname_\"] == feat_name]\n",
    "    feat_dl = pd_dl_cat.result[pd_dl_cat.result[\"_vname_\"] == feat_name]\n",
    "    \n",
    "    #define generator clf\n",
    "    gen_res = feat_lr\n",
    "\n",
    "    cart_res = calc(gen_res, feat_cart)\n",
    "    ebm_res = calc(gen_res, feat_ebm)\n",
    "    lr_res = calc(gen_res, feat_lr)\n",
    "    gnb_res = calc(gen_res, feat_gnb)\n",
    "    lr_l2_res = calc(gen_res, feat_lr_l2)\n",
    "    dl_res = calc(gen_res, feat_dl)\n",
    "\n",
    "    dict_result = {\n",
    "        \"Param\": feat_name,\n",
    "        \"CART\": cart_res,\n",
    "        \"EBM\": ebm_res,\n",
    "        \"LR\": lr_res,\n",
    "        \"GNB\": gnb_res,\n",
    "        \"LR_l2\": lr_l2_res,\n",
    "        \"DL\": dl_res\n",
    "    }\n",
    "\n",
    "    return dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Param       CART        EBM   LR        GNB     LR_l2         DL\n",
      "Param       age   3.285423   1.102898  0.0   8.698937  3.482423   4.643256\n",
      "CART        age   3.285423   1.102898  0.0   8.698937  3.482423   4.643256\n",
      "EBM         age   3.285423   1.102898  0.0   8.698937  3.482423   4.643256\n",
      "LR          age   3.285423   1.102898  0.0   8.698937  3.482423   4.643256\n",
      "GNB         age   3.285423   1.102898  0.0   8.698937  3.482423   4.643256\n",
      "LR_l2       age   3.285423   1.102898  0.0   8.698937  3.482423   4.643256\n",
      "DL          age   3.285423   1.102898  0.0   8.698937  3.482423   4.643256\n",
      "Param   balance   2.307880   3.546941  0.0  63.123988  4.204960   2.935449\n",
      "CART    balance   2.307880   3.546941  0.0  63.123988  4.204960   2.935449\n",
      "EBM     balance   2.307880   3.546941  0.0  63.123988  4.204960   2.935449\n",
      "LR      balance   2.307880   3.546941  0.0  63.123988  4.204960   2.935449\n",
      "GNB     balance   2.307880   3.546941  0.0  63.123988  4.204960   2.935449\n",
      "LR_l2   balance   2.307880   3.546941  0.0  63.123988  4.204960   2.935449\n",
      "DL      balance   2.307880   3.546941  0.0  63.123988  4.204960   2.935449\n",
      "Param       day   3.486166   0.977956  0.0   6.011909  3.511660   4.602513\n",
      "CART        day   3.486166   0.977956  0.0   6.011909  3.511660   4.602513\n",
      "EBM         day   3.486166   0.977956  0.0   6.011909  3.511660   4.602513\n",
      "LR          day   3.486166   0.977956  0.0   6.011909  3.511660   4.602513\n",
      "GNB         day   3.486166   0.977956  0.0   6.011909  3.511660   4.602513\n",
      "LR_l2       day   3.486166   0.977956  0.0   6.011909  3.511660   4.602513\n",
      "DL          day   3.486166   0.977956  0.0   6.011909  3.511660   4.602513\n",
      "Param  duration   2.280729   2.833513  0.0   6.949160  0.480757   4.840830\n",
      "CART   duration   2.280729   2.833513  0.0   6.949160  0.480757   4.840830\n",
      "EBM    duration   2.280729   2.833513  0.0   6.949160  0.480757   4.840830\n",
      "LR     duration   2.280729   2.833513  0.0   6.949160  0.480757   4.840830\n",
      "GNB    duration   2.280729   2.833513  0.0   6.949160  0.480757   4.840830\n",
      "LR_l2  duration   2.280729   2.833513  0.0   6.949160  0.480757   4.840830\n",
      "DL     duration   2.280729   2.833513  0.0   6.949160  0.480757   4.840830\n",
      "Param  campaign   1.716740   2.092369  0.0   1.294873  0.778833  10.605419\n",
      "CART   campaign   1.716740   2.092369  0.0   1.294873  0.778833  10.605419\n",
      "EBM    campaign   1.716740   2.092369  0.0   1.294873  0.778833  10.605419\n",
      "LR     campaign   1.716740   2.092369  0.0   1.294873  0.778833  10.605419\n",
      "GNB    campaign   1.716740   2.092369  0.0   1.294873  0.778833  10.605419\n",
      "LR_l2  campaign   1.716740   2.092369  0.0   1.294873  0.778833  10.605419\n",
      "DL     campaign   1.716740   2.092369  0.0   1.294873  0.778833  10.605419\n",
      "Param  previous  23.855504  14.052380  0.0  69.602393  9.345536  16.127029\n",
      "CART   previous  23.855504  14.052380  0.0  69.602393  9.345536  16.127029\n",
      "EBM    previous  23.855504  14.052380  0.0  69.602393  9.345536  16.127029\n",
      "LR     previous  23.855504  14.052380  0.0  69.602393  9.345536  16.127029\n",
      "GNB    previous  23.855504  14.052380  0.0  69.602393  9.345536  16.127029\n",
      "LR_l2  previous  23.855504  14.052380  0.0  69.602393  9.345536  16.127029\n",
      "DL     previous  23.855504  14.052380  0.0  69.602393  9.345536  16.127029\n",
      "          Param      CART       EBM   LR       GNB     LR_l2        DL\n",
      "Param       job  0.394208  0.219588  0.0  1.230392  0.104112  0.605381\n",
      "CART        job  0.394208  0.219588  0.0  1.230392  0.104112  0.605381\n",
      "EBM         job  0.394208  0.219588  0.0  1.230392  0.104112  0.605381\n",
      "LR          job  0.394208  0.219588  0.0  1.230392  0.104112  0.605381\n",
      "GNB         job  0.394208  0.219588  0.0  1.230392  0.104112  0.605381\n",
      "...         ...       ...       ...  ...       ...       ...       ...\n",
      "EBM    poutcome  0.139410  0.056194  0.0  0.920002  0.016593  0.569446\n",
      "LR     poutcome  0.139410  0.056194  0.0  0.920002  0.016593  0.569446\n",
      "GNB    poutcome  0.139410  0.056194  0.0  0.920002  0.016593  0.569446\n",
      "LR_l2  poutcome  0.139410  0.056194  0.0  0.920002  0.016593  0.569446\n",
      "DL     poutcome  0.139410  0.056194  0.0  0.920002  0.016593  0.569446\n",
      "\n",
      "[63 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#**Continous results**\n",
    "cont_results = []\n",
    "for param in cont_feat:\n",
    "    param_result = select_feat_result_cont(param)\n",
    "    param_result = pd.DataFrame(param_result, index =list(param_result.keys()))\n",
    "    cont_results.append(param_result)\n",
    "cont_final_res = pd.concat(cont_results)\n",
    "print(cont_final_res)\n",
    "\n",
    "#Categorical results\n",
    "cat_results = []\n",
    "for param in cat_feat:\n",
    "    param_result = select_feat_result_cat(param)\n",
    "    param_result = pd.DataFrame(param_result, index =list(param_result.keys()))\n",
    "    cat_results.append(param_result)\n",
    "cat_final_res = pd.concat(cat_results)\n",
    "print(cat_final_res)\n",
    "pd.concat([cont_final_res, cat_final_res]).to_csv(f\"../worst-case_results/{dataset}_{clf_name}.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54107a2a0eb6a0b2996cb7a94c16d9283b5dc7f969a30a8a01f6dbe77c679ea9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mainenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
