{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bart/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n",
      "/home/bart/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n",
      "/home/bart/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 653 rows 15 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 653 values\n",
      "  -> model_class       : sklearn.tree._classes.DecisionTreeClassifier (default)\n",
      "  -> label             : CART\n",
      "  -> predict function  : <function yhat_proba_default at 0x7f86d84ace50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 0.0, mean = 0.487, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = 0.0, mean = 0.0, max = 0.0\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 653 rows 15 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 653 values\n",
      "  -> model_class       : interpret.glassbox.ebm.ebm.ExplainableBoostingClassifier (default)\n",
      "  -> label             : EBM\n",
      "  -> predict function  : <function yhat_proba_default at 0x7f86d84ace50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 1.08e-06, mean = 0.488, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.675, mean = -0.00138, max = 0.638\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 653 rows 15 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 653 values\n",
      "  -> model_class       : sklearn.linear_model._logistic.LogisticRegression (default)\n",
      "  -> label             : LR_l2\n",
      "  -> predict function  : <function yhat_proba_default at 0x7f86d84ace50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 3.08e-06, mean = 0.487, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.822, mean = -1.8e-07, max = 0.799\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 653 rows 15 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 653 values\n",
      "  -> model_class       : sklearn.naive_bayes.GaussianNB (default)\n",
      "  -> label             : GNB\n",
      "  -> predict function  : <function yhat_proba_default at 0x7f86d84ace50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 5.54e-62, mean = 0.293, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -1.0, mean = 0.194, max = 1.0\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 653 rows 15 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 653 values\n",
      "  -> model_class       : sklearn.linear_model._logistic.LogisticRegression (default)\n",
      "  -> label             : LR\n",
      "  -> predict function  : <function yhat_proba_default at 0x7f86d84ace50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 0.0, mean = 0.487, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.000185, mean = 1.5e-07, max = 0.000181\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 653 rows 15 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 653 values\n",
      "  -> model_class       : interpret.glassbox.skoperules.DecisionListClassifier (default)\n",
      "  -> label             : DL\n",
      "  -> predict function  : <function yhat_proba_default at 0x7f86d84ace50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 0.487, mean = 0.727, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.994, mean = -0.24, max = 0.513\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n"
     ]
    }
   ],
   "source": [
    "import dalex as dx\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from interpret.glassbox import DecisionListClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "clfs = {\n",
    "    \"CART\": DecisionTreeClassifier(random_state=1234),\n",
    "    \"EBM\": ExplainableBoostingClassifier(),\n",
    "    \"LR_l2\": LogisticRegression(penalty=\"l2\",random_state=1234),\n",
    "    \"GNB\": GaussianNB(),\n",
    "    \"LR\": LogisticRegression(penalty=\"none\", random_state=1234),\n",
    "    \"DL\": DecisionListClassifier(random_state=1234) \n",
    "}\n",
    "\n",
    "dataset = 'credit'\n",
    "clf_name = \"LR\"\n",
    "\n",
    "import worstcase_helper\n",
    "import importlib\n",
    "importlib.reload(worstcase_helper)\n",
    "\n",
    "preprocess, X, y = worstcase_helper.load_dataset_with_preprocess(clf_name, dataset)\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "def make_pipeline_clf(clf_name):\n",
    "    clf = make_pipeline(\n",
    "        preprocess,\n",
    "        clfs[clf_name]\n",
    "    )\n",
    "    return clf\n",
    "\n",
    "clf_cart = make_pipeline_clf(\"CART\")\n",
    "clf_cart.fit(X, y)\n",
    "\n",
    "clf_ebm = make_pipeline_clf(\"EBM\")\n",
    "clf_ebm.fit(X, y)\n",
    "\n",
    "clf_lr_l2 = make_pipeline_clf(\"LR_l2\")\n",
    "clf_lr_l2.fit(X, y)\n",
    "\n",
    "clf_gnb = make_pipeline_clf(\"GNB\")\n",
    "clf_gnb.fit(X, y)\n",
    "\n",
    "clf_lr = make_pipeline_clf(\"LR\")\n",
    "clf_lr.fit(X, y)\n",
    "\n",
    "clf_dl = make_pipeline_clf(\"DL\")\n",
    "clf_dl.fit(X, y)\n",
    "\n",
    "clf_cart_exp = dx.Explainer(clf_cart, X, y, label=\"CART\")\n",
    "clf_ebm_exp = dx.Explainer(clf_ebm, X, y, label=\"EBM\")\n",
    "clf_lr_l2_exp = dx.Explainer(clf_lr_l2, X, y, label=\"LR_l2\")\n",
    "clf_gnb_exp = dx.Explainer(clf_gnb, X, y, label=\"GNB\")\n",
    "clf_lr_exp = dx.Explainer(clf_lr, X, y, label=\"LR\")\n",
    "clf_dl_exp = dx.Explainer(clf_dl, X, y, label=\"DL\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Partial Dependence profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('onehotencoder',\n",
       "                                 OneHotEncoder(handle_unknown='ignore',\n",
       "                                               sparse=False),\n",
       "                                 ['a1', 'a4', 'a5', 'a6', 'a7', 'a9', 'a10',\n",
       "                                  'a12', 'a13']),\n",
       "                                ('standardscaler', StandardScaler(),\n",
       "                                 ['a2', 'a3', 'a8', 'a11', 'a14', 'a15'])])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat = ['a1', 'a4', 'a5', 'a6', 'a7', 'a9', 'a10',\n",
    "                                  'a12', 'a13']\n",
    "cont_feat = ['a2', 'a3', 'a8', 'a11', 'a14', 'a15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating ceteris paribus: 100%|██████████| 9/9 [00:00<00:00, 11.03it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 9/9 [00:03<00:00,  2.75it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 9/9 [00:01<00:00,  8.03it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 9/9 [00:00<00:00, 16.26it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 9/9 [00:00<00:00, 12.47it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 9/9 [00:03<00:00,  2.89it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 6/6 [00:01<00:00,  3.37it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 6/6 [00:41<00:00,  6.97s/it]\n",
      "Calculating ceteris paribus: 100%|██████████| 6/6 [00:02<00:00,  2.74it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 6/6 [00:01<00:00,  3.12it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 6/6 [00:01<00:00,  3.02it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 6/6 [00:04<00:00,  1.21it/s]\n"
     ]
    }
   ],
   "source": [
    "#categorical pd profiles\n",
    "pd_cart_cat = clf_cart_exp.model_profile(variable_type=\"categorical\", variables=cat_feat)\n",
    "\n",
    "pd_ebm_cat = clf_ebm_exp.model_profile(variables= cat_feat,\n",
    "                                         variable_type=\"categorical\")\n",
    "\n",
    "pd_lr_l2_cat = clf_lr_l2_exp.model_profile(variables= cat_feat,\n",
    "                                         variable_type=\"categorical\")\n",
    "\n",
    "pd_gnb_cat = clf_gnb_exp.model_profile(variables= cat_feat,\n",
    "                                         variable_type=\"categorical\")\n",
    "\n",
    "pd_lr_cat = clf_lr_exp.model_profile(variables= cat_feat,\n",
    "                                         variable_type=\"categorical\")\n",
    "\n",
    "pd_dl_cat = clf_dl_exp.model_profile(variables= cat_feat,\n",
    "                                         variable_type=\"categorical\")\n",
    "\n",
    "#continous pd profiles\n",
    "pd_cart = clf_cart_exp.model_profile(variables= cont_feat)\n",
    "\n",
    "pd_ebm = clf_ebm_exp.model_profile(variables= cont_feat)\n",
    "\n",
    "pd_lr_l2 = clf_lr_l2_exp.model_profile(variables= cont_feat)\n",
    "\n",
    "pd_gnb = clf_gnb_exp.model_profile(variables= cont_feat)\n",
    "\n",
    "pd_lr = clf_lr_exp.model_profile(variables= cont_feat)\n",
    "\n",
    "pd_dl = clf_dl_exp.model_profile(variables= cont_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Aggregated Profiles for Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_cart_cat.plot([pd_ebm_cat, pd_gnb_cat, pd_lr_cat, pd_lr_l2_cat, pd_dl_cat], variables=cat_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Aggregated Profiles for Continous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_cart.plot([pd_ebm, pd_gnb, pd_lr, pd_lr_l2, pd_dl], variables=cont_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURES ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calc(feat_gen, feat_comp):\n",
    "    return np.abs(np.subtract(feat_gen[\"_yhat_\"], feat_comp[\"_yhat_\"])).sum()\n",
    "\n",
    "def select_feat_result_cont(feat_name):\n",
    "    feat_cart = pd_cart.result[pd_cart.result[\"_vname_\"] == feat_name]\n",
    "    feat_ebm = pd_ebm.result[pd_ebm.result[\"_vname_\"] == feat_name]\n",
    "    feat_lr = pd_lr.result[pd_lr.result[\"_vname_\"] == feat_name]\n",
    "    feat_gnb = pd_gnb.result[pd_gnb.result[\"_vname_\"] == feat_name]\n",
    "    feat_lr_l2 = pd_lr_l2.result[pd_lr_l2.result[\"_vname_\"] == feat_name]\n",
    "    feat_dl = pd_dl.result[pd_dl.result[\"_vname_\"] == feat_name]\n",
    "    \n",
    "    #define generator clf\n",
    "    gen_res = feat_lr\n",
    "\n",
    "    cart_res = calc(gen_res, feat_cart)\n",
    "    ebm_res = calc(gen_res, feat_ebm)\n",
    "    lr_res = calc(gen_res, feat_lr)\n",
    "    gnb_res = calc(gen_res, feat_gnb)\n",
    "    lr_l2_res = calc(gen_res, feat_lr_l2)\n",
    "    dl_res = calc(gen_res, feat_dl)\n",
    "\n",
    "    dict_result = {\n",
    "        \"Param\": feat_name,\n",
    "        \"CART\": cart_res,\n",
    "        \"EBM\": ebm_res,\n",
    "        \"LR\": lr_res,\n",
    "        \"GNB\": gnb_res,\n",
    "        \"LR_l2\": lr_l2_res,\n",
    "        \"DL\": dl_res\n",
    "    }\n",
    "\n",
    "    return dict_result\n",
    "\n",
    "def select_feat_result_cat(feat_name):\n",
    "    feat_cart = pd_cart_cat.result[pd_cart_cat.result[\"_vname_\"] == feat_name]\n",
    "    feat_ebm = pd_ebm_cat.result[pd_ebm_cat.result[\"_vname_\"] == feat_name]\n",
    "    feat_lr = pd_lr_cat.result[pd_lr_cat.result[\"_vname_\"] == feat_name]\n",
    "    feat_gnb = pd_gnb_cat.result[pd_gnb_cat.result[\"_vname_\"] == feat_name]\n",
    "    feat_lr_l2 = pd_lr_l2_cat.result[pd_lr_l2_cat.result[\"_vname_\"] == feat_name]\n",
    "    feat_dl = pd_dl_cat.result[pd_dl_cat.result[\"_vname_\"] == feat_name]\n",
    "    \n",
    "    #define generator clf\n",
    "    gen_res = feat_lr\n",
    "\n",
    "    cart_res = calc(gen_res, feat_cart)\n",
    "    ebm_res = calc(gen_res, feat_ebm)\n",
    "    lr_res = calc(gen_res, feat_lr)\n",
    "    gnb_res = calc(gen_res, feat_gnb)\n",
    "    lr_l2_res = calc(gen_res, feat_lr_l2)\n",
    "    dl_res = calc(gen_res, feat_dl)\n",
    "\n",
    "    dict_result = {\n",
    "        \"Param\": feat_name,\n",
    "        \"CART\": cart_res,\n",
    "        \"EBM\": ebm_res,\n",
    "        \"LR\": lr_res,\n",
    "        \"GNB\": gnb_res,\n",
    "        \"LR_l2\": lr_l2_res,\n",
    "        \"DL\": dl_res\n",
    "    }\n",
    "\n",
    "    return dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Param       CART        EBM   LR        GNB      LR_l2         DL\n",
      "Param    a2   2.359889   2.064623  0.0  15.567961   3.347179  24.387902\n",
      "CART     a2   2.359889   2.064623  0.0  15.567961   3.347179  24.387902\n",
      "EBM      a2   2.359889   2.064623  0.0  15.567961   3.347179  24.387902\n",
      "LR       a2   2.359889   2.064623  0.0  15.567961   3.347179  24.387902\n",
      "GNB      a2   2.359889   2.064623  0.0  15.567961   3.347179  24.387902\n",
      "LR_l2    a2   2.359889   2.064623  0.0  15.567961   3.347179  24.387902\n",
      "DL       a2   2.359889   2.064623  0.0  15.567961   3.347179  24.387902\n",
      "Param    a3   4.893833   5.417365  0.0   9.087005   5.698754  29.807645\n",
      "CART     a3   4.893833   5.417365  0.0   9.087005   5.698754  29.807645\n",
      "EBM      a3   4.893833   5.417365  0.0   9.087005   5.698754  29.807645\n",
      "LR       a3   4.893833   5.417365  0.0   9.087005   5.698754  29.807645\n",
      "GNB      a3   4.893833   5.417365  0.0   9.087005   5.698754  29.807645\n",
      "LR_l2    a3   4.893833   5.417365  0.0   9.087005   5.698754  29.807645\n",
      "DL       a3   4.893833   5.417365  0.0   9.087005   5.698754  29.807645\n",
      "Param    a8   7.389874   6.575177  0.0  10.614550  10.530005  17.367195\n",
      "CART     a8   7.389874   6.575177  0.0  10.614550  10.530005  17.367195\n",
      "EBM      a8   7.389874   6.575177  0.0  10.614550  10.530005  17.367195\n",
      "LR       a8   7.389874   6.575177  0.0  10.614550  10.530005  17.367195\n",
      "GNB      a8   7.389874   6.575177  0.0  10.614550  10.530005  17.367195\n",
      "LR_l2    a8   7.389874   6.575177  0.0  10.614550  10.530005  17.367195\n",
      "DL       a8   7.389874   6.575177  0.0  10.614550  10.530005  17.367195\n",
      "Param   a11  33.703352  31.528513  0.0   7.223573   2.514556  19.371120\n",
      "CART    a11  33.703352  31.528513  0.0   7.223573   2.514556  19.371120\n",
      "EBM     a11  33.703352  31.528513  0.0   7.223573   2.514556  19.371120\n",
      "LR      a11  33.703352  31.528513  0.0   7.223573   2.514556  19.371120\n",
      "GNB     a11  33.703352  31.528513  0.0   7.223573   2.514556  19.371120\n",
      "LR_l2   a11  33.703352  31.528513  0.0   7.223573   2.514556  19.371120\n",
      "DL      a11  33.703352  31.528513  0.0   7.223573   2.514556  19.371120\n",
      "Param   a14  18.379402  22.273460  0.0  11.489397   5.929784  49.956252\n",
      "CART    a14  18.379402  22.273460  0.0  11.489397   5.929784  49.956252\n",
      "EBM     a14  18.379402  22.273460  0.0  11.489397   5.929784  49.956252\n",
      "LR      a14  18.379402  22.273460  0.0  11.489397   5.929784  49.956252\n",
      "GNB     a14  18.379402  22.273460  0.0  11.489397   5.929784  49.956252\n",
      "LR_l2   a14  18.379402  22.273460  0.0  11.489397   5.929784  49.956252\n",
      "DL      a14  18.379402  22.273460  0.0  11.489397   5.929784  49.956252\n",
      "Param   a15   5.999418  40.328841  0.0   1.294507   4.608122  26.471199\n",
      "CART    a15   5.999418  40.328841  0.0   1.294507   4.608122  26.471199\n",
      "EBM     a15   5.999418  40.328841  0.0   1.294507   4.608122  26.471199\n",
      "LR      a15   5.999418  40.328841  0.0   1.294507   4.608122  26.471199\n",
      "GNB     a15   5.999418  40.328841  0.0   1.294507   4.608122  26.471199\n",
      "LR_l2   a15   5.999418  40.328841  0.0   1.294507   4.608122  26.471199\n",
      "DL      a15   5.999418  40.328841  0.0   1.294507   4.608122  26.471199\n",
      "      Param      CART       EBM   LR       GNB     LR_l2        DL\n",
      "Param    a1  0.029709  0.062290  0.0  0.463521  0.013821  0.475017\n",
      "CART     a1  0.029709  0.062290  0.0  0.463521  0.013821  0.475017\n",
      "EBM      a1  0.029709  0.062290  0.0  0.463521  0.013821  0.475017\n",
      "LR       a1  0.029709  0.062290  0.0  0.463521  0.013821  0.475017\n",
      "GNB      a1  0.029709  0.062290  0.0  0.463521  0.013821  0.475017\n",
      "...     ...       ...       ...  ...       ...       ...       ...\n",
      "EBM     a13  0.064465  0.069217  0.0  0.662258  0.084957  0.742426\n",
      "LR      a13  0.064465  0.069217  0.0  0.662258  0.084957  0.742426\n",
      "GNB     a13  0.064465  0.069217  0.0  0.662258  0.084957  0.742426\n",
      "LR_l2   a13  0.064465  0.069217  0.0  0.662258  0.084957  0.742426\n",
      "DL      a13  0.064465  0.069217  0.0  0.662258  0.084957  0.742426\n",
      "\n",
      "[63 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#**Continous results**\n",
    "cont_results = []\n",
    "for param in cont_feat:\n",
    "    param_result = select_feat_result_cont(param)\n",
    "    param_result = pd.DataFrame(param_result, index =list(param_result.keys()))\n",
    "    cont_results.append(param_result)\n",
    "cont_final_res = pd.concat(cont_results)\n",
    "print(cont_final_res)\n",
    "\n",
    "#Categorical results\n",
    "cat_results = []\n",
    "for param in cat_feat:\n",
    "    param_result = select_feat_result_cat(param)\n",
    "    param_result = pd.DataFrame(param_result, index =list(param_result.keys()))\n",
    "    cat_results.append(param_result)\n",
    "cat_final_res = pd.concat(cat_results)\n",
    "print(cat_final_res)\n",
    "pd.concat([cont_final_res, cat_final_res]).to_csv(f\"../worst-case_results/{dataset}_{clf_name}.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54107a2a0eb6a0b2996cb7a94c16d9283b5dc7f969a30a8a01f6dbe77c679ea9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mainenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
