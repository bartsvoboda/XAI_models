{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bart/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n",
      "/home/bart/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n",
      "/home/bart/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 999 rows 20 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 999 values\n",
      "  -> model_class       : sklearn.tree._classes.DecisionTreeClassifier (default)\n",
      "  -> label             : CART\n",
      "  -> predict function  : <function yhat_proba_default at 0x7fe26e9a5e50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 0.0, mean = 0.759, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = 0.0, mean = 0.0, max = 0.0\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 999 rows 20 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 999 values\n",
      "  -> model_class       : interpret.glassbox.ebm.ebm.ExplainableBoostingClassifier (default)\n",
      "  -> label             : EBM\n",
      "  -> predict function  : <function yhat_proba_default at 0x7fe26e9a5e50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 7.25e-08, mean = 0.76, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.395, mean = -0.00154, max = 0.571\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 999 rows 20 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 999 values\n",
      "  -> model_class       : sklearn.linear_model._logistic.LogisticRegression (default)\n",
      "  -> label             : LR_l2\n",
      "  -> predict function  : <function yhat_proba_default at 0x7fe26e9a5e50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 0.000107, mean = 0.759, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.82, mean = 6.19e-07, max = 0.702\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 999 rows 20 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 999 values\n",
      "  -> model_class       : sklearn.naive_bayes.GaussianNB (default)\n",
      "  -> label             : GNB\n",
      "  -> predict function  : <function yhat_proba_default at 0x7fe26e9a5e50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 1.48e-30, mean = 0.532, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -1.0, mean = 0.226, max = 1.0\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 999 rows 20 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 999 values\n",
      "  -> model_class       : sklearn.linear_model._logistic.LogisticRegression (default)\n",
      "  -> label             : LR\n",
      "  -> predict function  : <function yhat_proba_default at 0x7fe26e9a5e50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 0.0, mean = 0.759, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -5.3e-05, mean = -1.11e-08, max = 4.6e-05\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 999 rows 20 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 999 values\n",
      "  -> model_class       : interpret.glassbox.skoperules.DecisionListClassifier (default)\n",
      "  -> label             : DL\n",
      "  -> predict function  : <function yhat_proba_default at 0x7fe26e9a5e50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 0.523, mean = 0.854, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -1.0, mean = -0.095, max = 0.477\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n"
     ]
    }
   ],
   "source": [
    "import dalex as dx\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from interpret.glassbox import DecisionListClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "clfs = {\n",
    "    \"CART\": DecisionTreeClassifier(random_state=1234),\n",
    "    \"EBM\": ExplainableBoostingClassifier(),\n",
    "    \"LR_l2\": LogisticRegression(penalty=\"l2\",random_state=1234),\n",
    "    \"GNB\": GaussianNB(),\n",
    "    \"LR\": LogisticRegression(penalty=\"none\", random_state=1234),\n",
    "    \"DL\": DecisionListClassifier(random_state=1234) \n",
    "}\n",
    "\n",
    "dataset = 'german'\n",
    "clf_name = \"LR\"\n",
    "\n",
    "import worstcase_helper\n",
    "import importlib\n",
    "importlib.reload(worstcase_helper)\n",
    "\n",
    "preprocess, X, y = worstcase_helper.load_dataset_with_preprocess(clf_name, dataset)\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "def make_pipeline_clf(clf_name):\n",
    "    clf = make_pipeline(\n",
    "        preprocess,\n",
    "        clfs[clf_name]\n",
    "    )\n",
    "    return clf\n",
    "\n",
    "clf_cart = make_pipeline_clf(\"CART\")\n",
    "clf_cart.fit(X, y)\n",
    "\n",
    "clf_ebm = make_pipeline_clf(\"EBM\")\n",
    "clf_ebm.fit(X, y)\n",
    "\n",
    "clf_lr_l2 = make_pipeline_clf(\"LR_l2\")\n",
    "clf_lr_l2.fit(X, y)\n",
    "\n",
    "clf_gnb = make_pipeline_clf(\"GNB\")\n",
    "clf_gnb.fit(X, y)\n",
    "\n",
    "clf_lr = make_pipeline_clf(\"LR\")\n",
    "clf_lr.fit(X, y)\n",
    "\n",
    "clf_dl = make_pipeline_clf(\"DL\")\n",
    "clf_dl.fit(X, y)\n",
    "\n",
    "clf_cart_exp = dx.Explainer(clf_cart, X, y, label=\"CART\")\n",
    "clf_ebm_exp = dx.Explainer(clf_ebm, X, y, label=\"EBM\")\n",
    "clf_lr_l2_exp = dx.Explainer(clf_lr_l2, X, y, label=\"LR_l2\")\n",
    "clf_gnb_exp = dx.Explainer(clf_gnb, X, y, label=\"GNB\")\n",
    "clf_lr_exp = dx.Explainer(clf_lr, X, y, label=\"LR\")\n",
    "clf_dl_exp = dx.Explainer(clf_dl, X, y, label=\"DL\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Partial Dependence profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('onehotencoder',\n",
       "                                 OneHotEncoder(handle_unknown='ignore',\n",
       "                                               sparse=False),\n",
       "                                 ['att1', 'att3', 'att4', 'att6', 'att7',\n",
       "                                  'att9', 'att10', 'att12', 'att14', 'att15',\n",
       "                                  'att17', 'att19', 'att20']),\n",
       "                                ('standardscaler', StandardScaler(),\n",
       "                                 ['att2', 'att5', 'att8', 'att11', 'att13',\n",
       "                                  'att16', 'att18'])])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat = ['att1', 'att3', 'att4', 'att6', 'att7',\n",
    "                                  'att9', 'att10', 'att12', 'att14', 'att15',\n",
    "                                  'att17', 'att19', 'att20']\n",
    "cont_feat = ['att2', 'att5', 'att8', 'att11', 'att13',\n",
    "                                  'att16', 'att18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating ceteris paribus: 100%|██████████| 13/13 [00:01<00:00, 10.76it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 13/13 [00:06<00:00,  1.88it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 13/13 [00:01<00:00,  8.53it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 13/13 [00:00<00:00, 13.48it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 13/13 [00:01<00:00,  7.60it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 13/13 [00:06<00:00,  2.02it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 7/7 [00:03<00:00,  2.25it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 7/7 [01:10<00:00, 10.00s/it]\n",
      "Calculating ceteris paribus: 100%|██████████| 7/7 [00:03<00:00,  2.11it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 7/7 [00:03<00:00,  2.03it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 7/7 [00:03<00:00,  2.05it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 7/7 [00:08<00:00,  1.21s/it]\n"
     ]
    }
   ],
   "source": [
    "#categorical pd profiles\n",
    "pd_cart_cat = clf_cart_exp.model_profile(variable_type=\"categorical\", variables=cat_feat)\n",
    "\n",
    "pd_ebm_cat = clf_ebm_exp.model_profile(variables= cat_feat,\n",
    "                                         variable_type=\"categorical\")\n",
    "\n",
    "pd_lr_l2_cat = clf_lr_l2_exp.model_profile(variables= cat_feat,\n",
    "                                         variable_type=\"categorical\")\n",
    "\n",
    "pd_gnb_cat = clf_gnb_exp.model_profile(variables= cat_feat,\n",
    "                                         variable_type=\"categorical\")\n",
    "\n",
    "pd_lr_cat = clf_lr_exp.model_profile(variables= cat_feat,\n",
    "                                         variable_type=\"categorical\")\n",
    "\n",
    "pd_dl_cat = clf_dl_exp.model_profile(variables= cat_feat,\n",
    "                                         variable_type=\"categorical\")\n",
    "\n",
    "#continous pd profiles\n",
    "pd_cart = clf_cart_exp.model_profile(variables= cont_feat)\n",
    "\n",
    "pd_ebm = clf_ebm_exp.model_profile(variables= cont_feat)\n",
    "\n",
    "pd_lr_l2 = clf_lr_l2_exp.model_profile(variables= cont_feat)\n",
    "\n",
    "pd_gnb = clf_gnb_exp.model_profile(variables= cont_feat)\n",
    "\n",
    "pd_lr = clf_lr_exp.model_profile(variables= cont_feat)\n",
    "\n",
    "pd_dl = clf_dl_exp.model_profile(variables= cont_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Aggregated Profiles for Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_cart_cat.plot([pd_ebm_cat, pd_gnb_cat, pd_lr_cat, pd_lr_l2_cat, pd_dl_cat], variables=cat_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Aggregated Profiles for Continous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_cart.plot([pd_ebm, pd_gnb, pd_lr, pd_lr_l2, pd_dl], variables=cont_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURES ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calc(feat_gen, feat_comp):\n",
    "    return np.abs(np.subtract(feat_gen[\"_yhat_\"], feat_comp[\"_yhat_\"])).sum()\n",
    "\n",
    "def select_feat_result_cont(feat_name):\n",
    "    feat_cart = pd_cart.result[pd_cart.result[\"_vname_\"] == feat_name]\n",
    "    feat_ebm = pd_ebm.result[pd_ebm.result[\"_vname_\"] == feat_name]\n",
    "    feat_lr = pd_lr.result[pd_lr.result[\"_vname_\"] == feat_name]\n",
    "    feat_gnb = pd_gnb.result[pd_gnb.result[\"_vname_\"] == feat_name]\n",
    "    feat_lr_l2 = pd_lr_l2.result[pd_lr_l2.result[\"_vname_\"] == feat_name]\n",
    "    feat_dl = pd_dl.result[pd_dl.result[\"_vname_\"] == feat_name]\n",
    "    \n",
    "    #define generator clf\n",
    "    gen_res = feat_lr\n",
    "\n",
    "    cart_res = calc(gen_res, feat_cart)\n",
    "    ebm_res = calc(gen_res, feat_ebm)\n",
    "    lr_res = calc(gen_res, feat_lr)\n",
    "    gnb_res = calc(gen_res, feat_gnb)\n",
    "    lr_l2_res = calc(gen_res, feat_lr_l2)\n",
    "    dl_res = calc(gen_res, feat_dl)\n",
    "\n",
    "    dict_result = {\n",
    "        \"Param\": feat_name,\n",
    "        \"CART\": cart_res,\n",
    "        \"EBM\": ebm_res,\n",
    "        \"LR\": lr_res,\n",
    "        \"GNB\": gnb_res,\n",
    "        \"LR_l2\": lr_l2_res,\n",
    "        \"DL\": dl_res\n",
    "    }\n",
    "\n",
    "    return dict_result\n",
    "\n",
    "def select_feat_result_cat(feat_name):\n",
    "    feat_cart = pd_cart_cat.result[pd_cart_cat.result[\"_vname_\"] == feat_name]\n",
    "    feat_ebm = pd_ebm_cat.result[pd_ebm_cat.result[\"_vname_\"] == feat_name]\n",
    "    feat_lr = pd_lr_cat.result[pd_lr_cat.result[\"_vname_\"] == feat_name]\n",
    "    feat_gnb = pd_gnb_cat.result[pd_gnb_cat.result[\"_vname_\"] == feat_name]\n",
    "    feat_lr_l2 = pd_lr_l2_cat.result[pd_lr_l2_cat.result[\"_vname_\"] == feat_name]\n",
    "    feat_dl = pd_dl_cat.result[pd_dl_cat.result[\"_vname_\"] == feat_name]\n",
    "    \n",
    "    #define generator clf\n",
    "    gen_res = feat_lr\n",
    "\n",
    "    cart_res = calc(gen_res, feat_cart)\n",
    "    ebm_res = calc(gen_res, feat_ebm)\n",
    "    lr_res = calc(gen_res, feat_lr)\n",
    "    gnb_res = calc(gen_res, feat_gnb)\n",
    "    lr_l2_res = calc(gen_res, feat_lr_l2)\n",
    "    dl_res = calc(gen_res, feat_dl)\n",
    "\n",
    "    dict_result = {\n",
    "        \"Param\": feat_name,\n",
    "        \"CART\": cart_res,\n",
    "        \"EBM\": ebm_res,\n",
    "        \"LR\": lr_res,\n",
    "        \"GNB\": gnb_res,\n",
    "        \"LR_l2\": lr_l2_res,\n",
    "        \"DL\": dl_res\n",
    "    }\n",
    "\n",
    "    return dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Param       CART       EBM   LR        GNB     LR_l2         DL\n",
      "Param   att2   6.108433  4.684365  0.0  15.348068  3.211787  14.381691\n",
      "CART    att2   6.108433  4.684365  0.0  15.348068  3.211787  14.381691\n",
      "EBM     att2   6.108433  4.684365  0.0  15.348068  3.211787  14.381691\n",
      "LR      att2   6.108433  4.684365  0.0  15.348068  3.211787  14.381691\n",
      "GNB     att2   6.108433  4.684365  0.0  15.348068  3.211787  14.381691\n",
      "LR_l2   att2   6.108433  4.684365  0.0  15.348068  3.211787  14.381691\n",
      "DL      att2   6.108433  4.684365  0.0  15.348068  3.211787  14.381691\n",
      "Param   att5  14.099630  6.864481  0.0  10.938970  6.093666  25.776194\n",
      "CART    att5  14.099630  6.864481  0.0  10.938970  6.093666  25.776194\n",
      "EBM     att5  14.099630  6.864481  0.0  10.938970  6.093666  25.776194\n",
      "LR      att5  14.099630  6.864481  0.0  10.938970  6.093666  25.776194\n",
      "GNB     att5  14.099630  6.864481  0.0  10.938970  6.093666  25.776194\n",
      "LR_l2   att5  14.099630  6.864481  0.0  10.938970  6.093666  25.776194\n",
      "DL      att5  14.099630  6.864481  0.0  10.938970  6.093666  25.776194\n",
      "Param   att8   2.572151  1.783676  0.0  21.717472  3.366957   8.351174\n",
      "CART    att8   2.572151  1.783676  0.0  21.717472  3.366957   8.351174\n",
      "EBM     att8   2.572151  1.783676  0.0  21.717472  3.366957   8.351174\n",
      "LR      att8   2.572151  1.783676  0.0  21.717472  3.366957   8.351174\n",
      "GNB     att8   2.572151  1.783676  0.0  21.717472  3.366957   8.351174\n",
      "LR_l2   att8   2.572151  1.783676  0.0  21.717472  3.366957   8.351174\n",
      "DL      att8   2.572151  1.783676  0.0  21.717472  3.366957   8.351174\n",
      "Param  att11   2.130956  1.983419  0.0  19.979836  2.795604  10.153928\n",
      "CART   att11   2.130956  1.983419  0.0  19.979836  2.795604  10.153928\n",
      "EBM    att11   2.130956  1.983419  0.0  19.979836  2.795604  10.153928\n",
      "LR     att11   2.130956  1.983419  0.0  19.979836  2.795604  10.153928\n",
      "GNB    att11   2.130956  1.983419  0.0  19.979836  2.795604  10.153928\n",
      "LR_l2  att11   2.130956  1.983419  0.0  19.979836  2.795604  10.153928\n",
      "DL     att11   2.130956  1.983419  0.0  19.979836  2.795604  10.153928\n",
      "Param  att13   2.459582  2.748743  0.0  22.950096  2.424851   7.983064\n",
      "CART   att13   2.459582  2.748743  0.0  22.950096  2.424851   7.983064\n",
      "EBM    att13   2.459582  2.748743  0.0  22.950096  2.424851   7.983064\n",
      "LR     att13   2.459582  2.748743  0.0  22.950096  2.424851   7.983064\n",
      "GNB    att13   2.459582  2.748743  0.0  22.950096  2.424851   7.983064\n",
      "LR_l2  att13   2.459582  2.748743  0.0  22.950096  2.424851   7.983064\n",
      "DL     att13   2.459582  2.748743  0.0  22.950096  2.424851   7.983064\n",
      "Param  att16   7.098581  4.708900  0.0  14.831052  3.355981  14.894886\n",
      "CART   att16   7.098581  4.708900  0.0  14.831052  3.355981  14.894886\n",
      "EBM    att16   7.098581  4.708900  0.0  14.831052  3.355981  14.894886\n",
      "LR     att16   7.098581  4.708900  0.0  14.831052  3.355981  14.894886\n",
      "GNB    att16   7.098581  4.708900  0.0  14.831052  3.355981  14.894886\n",
      "LR_l2  att16   7.098581  4.708900  0.0  14.831052  3.355981  14.894886\n",
      "DL     att16   7.098581  4.708900  0.0  14.831052  3.355981  14.894886\n",
      "Param  att18   3.550913  1.664735  0.0  18.957458  2.585789  11.180552\n",
      "CART   att18   3.550913  1.664735  0.0  18.957458  2.585789  11.180552\n",
      "EBM    att18   3.550913  1.664735  0.0  18.957458  2.585789  11.180552\n",
      "LR     att18   3.550913  1.664735  0.0  18.957458  2.585789  11.180552\n",
      "GNB    att18   3.550913  1.664735  0.0  18.957458  2.585789  11.180552\n",
      "LR_l2  att18   3.550913  1.664735  0.0  18.957458  2.585789  11.180552\n",
      "DL     att18   3.550913  1.664735  0.0  18.957458  2.585789  11.180552\n",
      "       Param      CART       EBM   LR       GNB     LR_l2        DL\n",
      "Param   att1  0.169693  0.083502  0.0  1.071716  0.048990  0.311810\n",
      "CART    att1  0.169693  0.083502  0.0  1.071716  0.048990  0.311810\n",
      "EBM     att1  0.169693  0.083502  0.0  1.071716  0.048990  0.311810\n",
      "LR      att1  0.169693  0.083502  0.0  1.071716  0.048990  0.311810\n",
      "GNB     att1  0.169693  0.083502  0.0  1.071716  0.048990  0.311810\n",
      "...      ...       ...       ...  ...       ...       ...       ...\n",
      "EBM    att20  0.166522  0.033305  0.0  0.339905  0.036298  0.166522\n",
      "LR     att20  0.166522  0.033305  0.0  0.339905  0.036298  0.166522\n",
      "GNB    att20  0.166522  0.033305  0.0  0.339905  0.036298  0.166522\n",
      "LR_l2  att20  0.166522  0.033305  0.0  0.339905  0.036298  0.166522\n",
      "DL     att20  0.166522  0.033305  0.0  0.339905  0.036298  0.166522\n",
      "\n",
      "[91 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#**Continous results**\n",
    "cont_results = []\n",
    "for param in cont_feat:\n",
    "    param_result = select_feat_result_cont(param)\n",
    "    param_result = pd.DataFrame(param_result, index =list(param_result.keys()))\n",
    "    cont_results.append(param_result)\n",
    "cont_final_res = pd.concat(cont_results)\n",
    "print(cont_final_res)\n",
    "\n",
    "#Categorical results\n",
    "cat_results = []\n",
    "for param in cat_feat:\n",
    "    param_result = select_feat_result_cat(param)\n",
    "    param_result = pd.DataFrame(param_result, index =list(param_result.keys()))\n",
    "    cat_results.append(param_result)\n",
    "cat_final_res = pd.concat(cat_results)\n",
    "print(cat_final_res)\n",
    "pd.concat([cont_final_res, cat_final_res]).to_csv(f\"../worst-case_results/{dataset}_{clf_name}.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54107a2a0eb6a0b2996cb7a94c16d9283b5dc7f969a30a8a01f6dbe77c679ea9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mainenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
