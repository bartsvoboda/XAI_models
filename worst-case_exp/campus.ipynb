{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bart/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/bart/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/bart/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 215 rows 12 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 215 values\n",
      "  -> model_class       : sklearn.tree._classes.DecisionTreeClassifier (default)\n",
      "  -> label             : CART\n",
      "  -> predict function  : <function yhat_proba_default at 0x7f6cd20d4e50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 0.0, mean = 0.707, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = 0.0, mean = 0.0, max = 0.0\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 215 rows 12 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 215 values\n",
      "  -> model_class       : interpret.glassbox.ebm.ebm.ExplainableBoostingClassifier (default)\n",
      "  -> label             : EBM\n",
      "  -> predict function  : <function yhat_proba_default at 0x7f6cd20d4e50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 4.42e-09, mean = 0.708, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.0918, mean = -0.000674, max = 0.0327\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 215 rows 12 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 215 values\n",
      "  -> model_class       : sklearn.linear_model._logistic.LogisticRegression (default)\n",
      "  -> label             : LR_l2\n",
      "  -> predict function  : <function yhat_proba_default at 0x7f6cd20d4e50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 5.56e-06, mean = 0.707, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.531, mean = -5.51e-07, max = 0.402\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 215 rows 12 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 215 values\n",
      "  -> model_class       : sklearn.naive_bayes.GaussianNB (default)\n",
      "  -> label             : GNB\n",
      "  -> predict function  : <function yhat_proba_default at 0x7f6cd20d4e50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 2.15e-16, mean = 0.697, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.985, mean = 0.01, max = 1.0\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 215 rows 12 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 215 values\n",
      "  -> model_class       : sklearn.linear_model._logistic.LogisticRegression (default)\n",
      "  -> label             : LR\n",
      "  -> predict function  : <function yhat_proba_default at 0x7f6cd20d4e50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 1.54e-102, mean = 0.707, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -1.41e-05, mean = 1.92e-07, max = 2.41e-05\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 215 rows 12 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 215 values\n",
      "  -> model_class       : interpret.glassbox.skoperules.DecisionListClassifier (default)\n",
      "  -> label             : DL\n",
      "  -> predict function  : <function yhat_proba_default at 0x7f6cd20d4e50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 0.5, mean = 0.922, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -1.0, mean = -0.215, max = 0.391\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n"
     ]
    }
   ],
   "source": [
    "import dalex as dx\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from interpret.glassbox import DecisionListClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "clfs = {\n",
    "    \"CART\": DecisionTreeClassifier(random_state=1234),\n",
    "    \"EBM\": ExplainableBoostingClassifier(),\n",
    "    \"LR_l2\": LogisticRegression(penalty=\"l2\",random_state=1234),\n",
    "    \"GNB\": GaussianNB(),\n",
    "    \"LR\": LogisticRegression(penalty=\"none\", random_state=1234),\n",
    "    \"DL\": DecisionListClassifier(random_state=1234) \n",
    "}\n",
    "\n",
    "dataset = 'campus'\n",
    "clf_name = \"LR_l2\"\n",
    "\n",
    "import worstcase_helper\n",
    "import importlib\n",
    "importlib.reload(worstcase_helper)\n",
    "\n",
    "preprocess, X, y = worstcase_helper.load_dataset_with_preprocess(clf_name, dataset)\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "def make_pipeline_clf(clf_name):\n",
    "    clf = make_pipeline(\n",
    "        preprocess,\n",
    "        clfs[clf_name]\n",
    "    )\n",
    "    return clf\n",
    "\n",
    "clf_cart = make_pipeline_clf(\"CART\")\n",
    "clf_cart.fit(X, y)\n",
    "\n",
    "clf_ebm = make_pipeline_clf(\"EBM\")\n",
    "clf_ebm.fit(X, y)\n",
    "\n",
    "clf_lr_l2 = make_pipeline_clf(\"LR_l2\")\n",
    "clf_lr_l2.fit(X, y)\n",
    "\n",
    "clf_gnb = make_pipeline_clf(\"GNB\")\n",
    "clf_gnb.fit(X, y)\n",
    "\n",
    "clf_lr = make_pipeline_clf(\"LR\")\n",
    "clf_lr.fit(X, y)\n",
    "\n",
    "clf_dl = make_pipeline_clf(\"DL\")\n",
    "clf_dl.fit(X, y)\n",
    "\n",
    "clf_cart_exp = dx.Explainer(clf_cart, X, y, label=\"CART\")\n",
    "clf_ebm_exp = dx.Explainer(clf_ebm, X, y, label=\"EBM\")\n",
    "clf_lr_l2_exp = dx.Explainer(clf_lr_l2, X, y, label=\"LR_l2\")\n",
    "clf_gnb_exp = dx.Explainer(clf_gnb, X, y, label=\"GNB\")\n",
    "clf_lr_exp = dx.Explainer(clf_lr, X, y, label=\"LR\")\n",
    "clf_dl_exp = dx.Explainer(clf_dl, X, y, label=\"DL\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Partial Dependence profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('onehotencoder',\n",
       "                                 OneHotEncoder(handle_unknown='ignore',\n",
       "                                               sparse=False),\n",
       "                                 ['gender', 'ssc_b', 'hsc_b', 'hsc_s',\n",
       "                                  'degree_t', 'workex', 'specialisation']),\n",
       "                                ('standardscaler', StandardScaler(),\n",
       "                                 ['ssc_p', 'hsc_p', 'degree_p', 'etest_p',\n",
       "                                  'mba_p'])])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat = ['gender', 'ssc_b', 'hsc_b', 'hsc_s',\n",
    "                                  'degree_t', 'workex', 'specialisation']\n",
    "cont_feat = ['ssc_p', 'hsc_p', 'degree_p', 'etest_p',\n",
    "                                  'mba_p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating ceteris paribus: 100%|██████████| 7/7 [00:00<00:00, 25.35it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 7/7 [00:01<00:00,  6.92it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 7/7 [00:00<00:00, 34.18it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 7/7 [00:00<00:00, 20.46it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 7/7 [00:00<00:00, 30.14it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 7/7 [00:02<00:00,  2.55it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 5/5 [00:00<00:00,  6.20it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 5/5 [00:11<00:00,  2.24s/it]\n",
      "Calculating ceteris paribus: 100%|██████████| 5/5 [00:01<00:00,  4.58it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 5/5 [00:00<00:00,  5.27it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 5/5 [00:00<00:00,  5.03it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 5/5 [00:03<00:00,  1.29it/s]\n"
     ]
    }
   ],
   "source": [
    "#categorical pd profiles\n",
    "pd_cart_cat = clf_cart_exp.model_profile(variable_type=\"categorical\", variables=cat_feat)\n",
    "\n",
    "pd_ebm_cat = clf_ebm_exp.model_profile(variables= cat_feat,\n",
    "                                         variable_type=\"categorical\")\n",
    "\n",
    "pd_lr_l2_cat = clf_lr_l2_exp.model_profile(variables= cat_feat,\n",
    "                                         variable_type=\"categorical\")\n",
    "\n",
    "pd_gnb_cat = clf_gnb_exp.model_profile(variables= cat_feat,\n",
    "                                         variable_type=\"categorical\")\n",
    "\n",
    "pd_lr_cat = clf_lr_exp.model_profile(variables= cat_feat,\n",
    "                                         variable_type=\"categorical\")\n",
    "\n",
    "pd_dl_cat = clf_dl_exp.model_profile(variables= cat_feat,\n",
    "                                         variable_type=\"categorical\")\n",
    "\n",
    "#continous pd profiles\n",
    "pd_cart = clf_cart_exp.model_profile(variables= cont_feat)\n",
    "\n",
    "pd_ebm = clf_ebm_exp.model_profile(variables= cont_feat)\n",
    "\n",
    "pd_lr_l2 = clf_lr_l2_exp.model_profile(variables= cont_feat)\n",
    "\n",
    "pd_gnb = clf_gnb_exp.model_profile(variables= cont_feat)\n",
    "\n",
    "pd_lr = clf_lr_exp.model_profile(variables= cont_feat)\n",
    "\n",
    "pd_dl = clf_dl_exp.model_profile(variables= cont_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Aggregated Profiles for Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_cart_cat.plot([pd_ebm_cat, pd_gnb_cat, pd_lr_cat, pd_lr_l2_cat, pd_dl_cat], variables=cat_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Aggregated Profiles for Continous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_cart.plot([pd_ebm, pd_gnb, pd_lr, pd_lr_l2, pd_dl], variables=cont_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURES ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calc(feat_gen, feat_comp):\n",
    "    return np.abs(np.subtract(feat_gen[\"_yhat_\"], feat_comp[\"_yhat_\"])).sum()\n",
    "\n",
    "def select_feat_result_cont(feat_name):\n",
    "    feat_cart = pd_cart.result[pd_cart.result[\"_vname_\"] == feat_name]\n",
    "    feat_ebm = pd_ebm.result[pd_ebm.result[\"_vname_\"] == feat_name]\n",
    "    feat_lr = pd_lr.result[pd_lr.result[\"_vname_\"] == feat_name]\n",
    "    feat_gnb = pd_gnb.result[pd_gnb.result[\"_vname_\"] == feat_name]\n",
    "    feat_lr_l2 = pd_lr_l2.result[pd_lr_l2.result[\"_vname_\"] == feat_name]\n",
    "    feat_dl = pd_dl.result[pd_dl.result[\"_vname_\"] == feat_name]\n",
    "    \n",
    "    #define generator clf\n",
    "    gen_res = feat_lr_l2\n",
    "\n",
    "    cart_res = calc(gen_res, feat_cart)\n",
    "    ebm_res = calc(gen_res, feat_ebm)\n",
    "    lr_res = calc(gen_res, feat_lr)\n",
    "    gnb_res = calc(gen_res, feat_gnb)\n",
    "    lr_l2_res = calc(gen_res, feat_lr_l2)\n",
    "    dl_res = calc(gen_res, feat_dl)\n",
    "\n",
    "    dict_result = {\n",
    "        \"Param\": feat_name,\n",
    "        \"CART\": cart_res,\n",
    "        \"EBM\": ebm_res,\n",
    "        \"LR\": lr_res,\n",
    "        \"GNB\": gnb_res,\n",
    "        \"LR_l2\": lr_l2_res,\n",
    "        \"DL\": dl_res\n",
    "    }\n",
    "\n",
    "    return dict_result\n",
    "\n",
    "def select_feat_result_cat(feat_name):\n",
    "    feat_cart = pd_cart_cat.result[pd_cart_cat.result[\"_vname_\"] == feat_name]\n",
    "    feat_ebm = pd_ebm_cat.result[pd_ebm_cat.result[\"_vname_\"] == feat_name]\n",
    "    feat_lr = pd_lr_cat.result[pd_lr_cat.result[\"_vname_\"] == feat_name]\n",
    "    feat_gnb = pd_gnb_cat.result[pd_gnb_cat.result[\"_vname_\"] == feat_name]\n",
    "    feat_lr_l2 = pd_lr_l2_cat.result[pd_lr_l2_cat.result[\"_vname_\"] == feat_name]\n",
    "    feat_dl = pd_dl_cat.result[pd_dl_cat.result[\"_vname_\"] == feat_name]\n",
    "    \n",
    "    #define generator clf\n",
    "    gen_res = feat_lr_l2\n",
    "\n",
    "    cart_res = calc(gen_res, feat_cart)\n",
    "    ebm_res = calc(gen_res, feat_ebm)\n",
    "    lr_res = calc(gen_res, feat_lr)\n",
    "    gnb_res = calc(gen_res, feat_gnb)\n",
    "    lr_l2_res = calc(gen_res, feat_lr_l2)\n",
    "    dl_res = calc(gen_res, feat_dl)\n",
    "\n",
    "    dict_result = {\n",
    "        \"Param\": feat_name,\n",
    "        \"CART\": cart_res,\n",
    "        \"EBM\": ebm_res,\n",
    "        \"LR\": lr_res,\n",
    "        \"GNB\": gnb_res,\n",
    "        \"LR_l2\": lr_l2_res,\n",
    "        \"DL\": dl_res\n",
    "    }\n",
    "\n",
    "    return dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Param       CART       EBM        LR        GNB  LR_l2         DL\n",
      "Param     ssc_p   7.824550  4.875948  1.915770  11.162580    0.0  23.061285\n",
      "CART      ssc_p   7.824550  4.875948  1.915770  11.162580    0.0  23.061285\n",
      "EBM       ssc_p   7.824550  4.875948  1.915770  11.162580    0.0  23.061285\n",
      "LR        ssc_p   7.824550  4.875948  1.915770  11.162580    0.0  23.061285\n",
      "GNB       ssc_p   7.824550  4.875948  1.915770  11.162580    0.0  23.061285\n",
      "LR_l2     ssc_p   7.824550  4.875948  1.915770  11.162580    0.0  23.061285\n",
      "DL        ssc_p   7.824550  4.875948  1.915770  11.162580    0.0  23.061285\n",
      "Param     hsc_p  11.594509  5.509065  3.718201   2.334532    0.0  21.681054\n",
      "CART      hsc_p  11.594509  5.509065  3.718201   2.334532    0.0  21.681054\n",
      "EBM       hsc_p  11.594509  5.509065  3.718201   2.334532    0.0  21.681054\n",
      "LR        hsc_p  11.594509  5.509065  3.718201   2.334532    0.0  21.681054\n",
      "GNB       hsc_p  11.594509  5.509065  3.718201   2.334532    0.0  21.681054\n",
      "LR_l2     hsc_p  11.594509  5.509065  3.718201   2.334532    0.0  21.681054\n",
      "DL        hsc_p  11.594509  5.509065  3.718201   2.334532    0.0  21.681054\n",
      "Param  degree_p  12.582373  7.065634  2.858930   3.339549    0.0  16.652124\n",
      "CART   degree_p  12.582373  7.065634  2.858930   3.339549    0.0  16.652124\n",
      "EBM    degree_p  12.582373  7.065634  2.858930   3.339549    0.0  16.652124\n",
      "LR     degree_p  12.582373  7.065634  2.858930   3.339549    0.0  16.652124\n",
      "GNB    degree_p  12.582373  7.065634  2.858930   3.339549    0.0  16.652124\n",
      "LR_l2  degree_p  12.582373  7.065634  2.858930   3.339549    0.0  16.652124\n",
      "DL     degree_p  12.582373  7.065634  2.858930   3.339549    0.0  16.652124\n",
      "Param   etest_p   1.784995  2.552465  1.214668   4.289225    0.0  23.370880\n",
      "CART    etest_p   1.784995  2.552465  1.214668   4.289225    0.0  23.370880\n",
      "EBM     etest_p   1.784995  2.552465  1.214668   4.289225    0.0  23.370880\n",
      "LR      etest_p   1.784995  2.552465  1.214668   4.289225    0.0  23.370880\n",
      "GNB     etest_p   1.784995  2.552465  1.214668   4.289225    0.0  23.370880\n",
      "LR_l2   etest_p   1.784995  2.552465  1.214668   4.289225    0.0  23.370880\n",
      "DL      etest_p   1.784995  2.552465  1.214668   4.289225    0.0  23.370880\n",
      "Param     mba_p  10.058548  5.519555  0.761019  11.107061    0.0  26.980609\n",
      "CART      mba_p  10.058548  5.519555  0.761019  11.107061    0.0  26.980609\n",
      "EBM       mba_p  10.058548  5.519555  0.761019  11.107061    0.0  26.980609\n",
      "LR        mba_p  10.058548  5.519555  0.761019  11.107061    0.0  26.980609\n",
      "GNB       mba_p  10.058548  5.519555  0.761019  11.107061    0.0  26.980609\n",
      "LR_l2     mba_p  10.058548  5.519555  0.761019  11.107061    0.0  26.980609\n",
      "DL        mba_p  10.058548  5.519555  0.761019  11.107061    0.0  26.980609\n",
      "                Param      CART       EBM        LR       GNB  LR_l2        DL\n",
      "Param          gender  0.077416  0.060347  0.012736  0.025817    0.0  0.451271\n",
      "CART           gender  0.077416  0.060347  0.012736  0.025817    0.0  0.451271\n",
      "EBM            gender  0.077416  0.060347  0.012736  0.025817    0.0  0.451271\n",
      "LR             gender  0.077416  0.060347  0.012736  0.025817    0.0  0.451271\n",
      "GNB            gender  0.077416  0.060347  0.012736  0.025817    0.0  0.451271\n",
      "LR_l2          gender  0.077416  0.060347  0.012736  0.025817    0.0  0.451271\n",
      "DL             gender  0.077416  0.060347  0.012736  0.025817    0.0  0.451271\n",
      "Param           ssc_b  0.032381  0.024656  0.032400  0.021203    0.0  0.428275\n",
      "CART            ssc_b  0.032381  0.024656  0.032400  0.021203    0.0  0.428275\n",
      "EBM             ssc_b  0.032381  0.024656  0.032400  0.021203    0.0  0.428275\n",
      "LR              ssc_b  0.032381  0.024656  0.032400  0.021203    0.0  0.428275\n",
      "GNB             ssc_b  0.032381  0.024656  0.032400  0.021203    0.0  0.428275\n",
      "LR_l2           ssc_b  0.032381  0.024656  0.032400  0.021203    0.0  0.428275\n",
      "DL              ssc_b  0.032381  0.024656  0.032400  0.021203    0.0  0.428275\n",
      "Param           hsc_b  0.029805  0.023164  0.029806  0.025311    0.0  0.420829\n",
      "CART            hsc_b  0.029805  0.023164  0.029806  0.025311    0.0  0.420829\n",
      "EBM             hsc_b  0.029805  0.023164  0.029806  0.025311    0.0  0.420829\n",
      "LR              hsc_b  0.029805  0.023164  0.029806  0.025311    0.0  0.420829\n",
      "GNB             hsc_b  0.029805  0.023164  0.029806  0.025311    0.0  0.420829\n",
      "LR_l2           hsc_b  0.029805  0.023164  0.029806  0.025311    0.0  0.420829\n",
      "DL              hsc_b  0.029805  0.023164  0.029806  0.025311    0.0  0.420829\n",
      "Param           hsc_s  0.053345  0.034756  0.039414  0.536645    0.0  0.647777\n",
      "CART            hsc_s  0.053345  0.034756  0.039414  0.536645    0.0  0.647777\n",
      "EBM             hsc_s  0.053345  0.034756  0.039414  0.536645    0.0  0.647777\n",
      "LR              hsc_s  0.053345  0.034756  0.039414  0.536645    0.0  0.647777\n",
      "GNB             hsc_s  0.053345  0.034756  0.039414  0.536645    0.0  0.647777\n",
      "LR_l2           hsc_s  0.053345  0.034756  0.039414  0.536645    0.0  0.647777\n",
      "DL              hsc_s  0.053345  0.034756  0.039414  0.536645    0.0  0.647777\n",
      "Param        degree_t  0.066069  0.125853  0.157049  0.700647    0.0  0.753364\n",
      "CART         degree_t  0.066069  0.125853  0.157049  0.700647    0.0  0.753364\n",
      "EBM          degree_t  0.066069  0.125853  0.157049  0.700647    0.0  0.753364\n",
      "LR           degree_t  0.066069  0.125853  0.157049  0.700647    0.0  0.753364\n",
      "GNB          degree_t  0.066069  0.125853  0.157049  0.700647    0.0  0.753364\n",
      "LR_l2        degree_t  0.066069  0.125853  0.157049  0.700647    0.0  0.753364\n",
      "DL           degree_t  0.066069  0.125853  0.157049  0.700647    0.0  0.753364\n",
      "Param          workex  0.091318  0.073850  0.012650  0.084412    0.0  0.388777\n",
      "CART           workex  0.091318  0.073850  0.012650  0.084412    0.0  0.388777\n",
      "EBM            workex  0.091318  0.073850  0.012650  0.084412    0.0  0.388777\n",
      "LR             workex  0.091318  0.073850  0.012650  0.084412    0.0  0.388777\n",
      "GNB            workex  0.091318  0.073850  0.012650  0.084412    0.0  0.388777\n",
      "LR_l2          workex  0.091318  0.073850  0.012650  0.084412    0.0  0.388777\n",
      "DL             workex  0.091318  0.073850  0.012650  0.084412    0.0  0.388777\n",
      "Param  specialisation  0.058018  0.050474  0.014151  0.086373    0.0  0.431311\n",
      "CART   specialisation  0.058018  0.050474  0.014151  0.086373    0.0  0.431311\n",
      "EBM    specialisation  0.058018  0.050474  0.014151  0.086373    0.0  0.431311\n",
      "LR     specialisation  0.058018  0.050474  0.014151  0.086373    0.0  0.431311\n",
      "GNB    specialisation  0.058018  0.050474  0.014151  0.086373    0.0  0.431311\n",
      "LR_l2  specialisation  0.058018  0.050474  0.014151  0.086373    0.0  0.431311\n",
      "DL     specialisation  0.058018  0.050474  0.014151  0.086373    0.0  0.431311\n"
     ]
    }
   ],
   "source": [
    "#**Continous results**\n",
    "cont_results = []\n",
    "for param in cont_feat:\n",
    "    param_result = select_feat_result_cont(param)\n",
    "    param_result = pd.DataFrame(param_result, index =list(param_result.keys()))\n",
    "    cont_results.append(param_result)\n",
    "cont_final_res = pd.concat(cont_results)\n",
    "print(cont_final_res)\n",
    "\n",
    "#Categorical results\n",
    "cat_results = []\n",
    "for param in cat_feat:\n",
    "    param_result = select_feat_result_cat(param)\n",
    "    param_result = pd.DataFrame(param_result, index =list(param_result.keys()))\n",
    "    cat_results.append(param_result)\n",
    "cat_final_res = pd.concat(cat_results)\n",
    "print(cat_final_res)\n",
    "pd.concat([cont_final_res, cat_final_res]).to_csv(f\"../worst-case_results/{dataset}_{clf_name}.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54107a2a0eb6a0b2996cb7a94c16d9283b5dc7f969a30a8a01f6dbe77c679ea9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mainenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
