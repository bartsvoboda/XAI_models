{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bart/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n",
      "/home/bart/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n",
      "/home/bart/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 10000 rows 10 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 10000 values\n",
      "  -> model_class       : sklearn.tree._classes.DecisionTreeClassifier (default)\n",
      "  -> label             : CART\n",
      "  -> predict function  : <function yhat_proba_default at 0x7fb76f155e50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 0.0, mean = 0.0722, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = 0.0, mean = 0.0, max = 0.0\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 10000 rows 10 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 10000 values\n",
      "  -> model_class       : interpret.glassbox.ebm.ebm.ExplainableBoostingClassifier (default)\n",
      "  -> label             : EBM\n",
      "  -> predict function  : <function yhat_proba_default at 0x7fb76f155e50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 3.98e-20, mean = 0.0719, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.591, mean = 0.00033, max = 0.685\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 10000 rows 10 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 10000 values\n",
      "  -> model_class       : sklearn.linear_model._logistic.LogisticRegression (default)\n",
      "  -> label             : LR_l2\n",
      "  -> predict function  : <function yhat_proba_default at 0x7fb76f155e50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 1.36e-20, mean = 0.0722, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.546, mean = 4.39e-08, max = 0.605\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 10000 rows 10 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 10000 values\n",
      "  -> model_class       : sklearn.naive_bayes.GaussianNB (default)\n",
      "  -> label             : GNB\n",
      "  -> predict function  : <function yhat_proba_default at 0x7fb76f155e50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 1.23e-07, mean = 0.102, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.871, mean = -0.0296, max = 0.985\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 10000 rows 10 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 10000 values\n",
      "  -> model_class       : sklearn.linear_model._logistic.LogisticRegression (default)\n",
      "  -> label             : LR\n",
      "  -> predict function  : <function yhat_proba_default at 0x7fb76f155e50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 0.0, mean = 0.0722, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.967, mean = -4.73e-10, max = 0.701\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 10000 rows 10 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 10000 values\n",
      "  -> model_class       : interpret.glassbox.skoperules.DecisionListClassifier (default)\n",
      "  -> label             : DL\n",
      "  -> predict function  : <function yhat_proba_default at 0x7fb76f155e50> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 0.0722, mean = 0.11, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -1.0, mean = -0.0381, max = 0.928\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n"
     ]
    }
   ],
   "source": [
    "import dalex as dx\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from interpret.glassbox import DecisionListClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "clfs = {\n",
    "    \"CART\": DecisionTreeClassifier(random_state=1234),\n",
    "    \"EBM\": ExplainableBoostingClassifier(),\n",
    "    \"LR_l2\": LogisticRegression(penalty=\"l2\",random_state=1234),\n",
    "    \"GNB\": GaussianNB(),\n",
    "    \"LR\": LogisticRegression(penalty=\"none\", random_state=1234),\n",
    "    \"DL\": DecisionListClassifier(random_state=1234) \n",
    "}\n",
    "\n",
    "dataset = 'churn'\n",
    "clf_name = \"LR_l2\"\n",
    "\n",
    "import worstcase_helper\n",
    "import importlib\n",
    "importlib.reload(worstcase_helper)\n",
    "\n",
    "preprocess, X, y = worstcase_helper.load_dataset_with_preprocess(clf_name, dataset)\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "def make_pipeline_clf(clf_name):\n",
    "    clf = make_pipeline(\n",
    "        preprocess,\n",
    "        clfs[clf_name]\n",
    "    )\n",
    "    return clf\n",
    "\n",
    "clf_cart = make_pipeline_clf(\"CART\")\n",
    "clf_cart.fit(X, y)\n",
    "\n",
    "clf_ebm = make_pipeline_clf(\"EBM\")\n",
    "clf_ebm.fit(X, y)\n",
    "\n",
    "clf_lr_l2 = make_pipeline_clf(\"LR_l2\")\n",
    "clf_lr_l2.fit(X, y)\n",
    "\n",
    "clf_gnb = make_pipeline_clf(\"GNB\")\n",
    "clf_gnb.fit(X, y)\n",
    "\n",
    "clf_lr = make_pipeline_clf(\"LR\")\n",
    "clf_lr.fit(X, y)\n",
    "\n",
    "clf_dl = make_pipeline_clf(\"DL\")\n",
    "clf_dl.fit(X, y)\n",
    "\n",
    "clf_cart_exp = dx.Explainer(clf_cart, X, y, label=\"CART\")\n",
    "clf_ebm_exp = dx.Explainer(clf_ebm, X, y, label=\"EBM\")\n",
    "clf_lr_l2_exp = dx.Explainer(clf_lr_l2, X, y, label=\"LR_l2\")\n",
    "clf_gnb_exp = dx.Explainer(clf_gnb, X, y, label=\"GNB\")\n",
    "clf_lr_exp = dx.Explainer(clf_lr, X, y, label=\"LR\")\n",
    "clf_dl_exp = dx.Explainer(clf_dl, X, y, label=\"DL\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Partial Dependence profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('onehotencoder',\n",
       "                                 OneHotEncoder(handle_unknown='ignore',\n",
       "                                               sparse=False),\n",
       "                                 ['Geography', 'Gender', 'HasCrCard',\n",
       "                                  'IsActiveMember']),\n",
       "                                ('standardscaler', StandardScaler(),\n",
       "                                 ['CreditScore', 'Age', 'Tenure', 'Balance',\n",
       "                                  'NumOfProducts', 'EstimatedSalary'])])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat = ['Geography', 'Gender', 'HasCrCard',\n",
    "                                  'IsActiveMember']\n",
    "cont_feat = ['CreditScore', 'Age', 'Tenure', 'Balance',\n",
    "                                  'NumOfProducts', 'EstimatedSalary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating ceteris paribus: 100%|██████████| 4/4 [00:00<00:00, 18.35it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 4/4 [00:00<00:00, 11.12it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 4/4 [00:00<00:00, 34.49it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 4/4 [00:00<00:00, 21.72it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 4/4 [00:00<00:00, 28.58it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 4/4 [00:00<00:00,  8.02it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 6/6 [00:01<00:00,  5.63it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 6/6 [00:09<00:00,  1.62s/it]\n",
      "Calculating ceteris paribus: 100%|██████████| 6/6 [00:01<00:00,  4.90it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 6/6 [00:01<00:00,  5.50it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 6/6 [00:01<00:00,  3.87it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 6/6 [00:01<00:00,  3.65it/s]\n"
     ]
    }
   ],
   "source": [
    "#categorical pd profiles\n",
    "pd_cart_cat = clf_cart_exp.model_profile(variable_type=\"categorical\", variables=cat_feat)\n",
    "\n",
    "pd_ebm_cat = clf_ebm_exp.model_profile(variables= cat_feat,\n",
    "                                         variable_type=\"categorical\")\n",
    "\n",
    "pd_lr_l2_cat = clf_lr_l2_exp.model_profile(variables= cat_feat,\n",
    "                                         variable_type=\"categorical\")\n",
    "\n",
    "pd_gnb_cat = clf_gnb_exp.model_profile(variables= cat_feat,\n",
    "                                         variable_type=\"categorical\")\n",
    "\n",
    "pd_lr_cat = clf_lr_exp.model_profile(variables= cat_feat,\n",
    "                                         variable_type=\"categorical\")\n",
    "\n",
    "pd_dl_cat = clf_dl_exp.model_profile(variables= cat_feat,\n",
    "                                         variable_type=\"categorical\")\n",
    "\n",
    "#continous pd profiles\n",
    "pd_cart = clf_cart_exp.model_profile(variables= cont_feat)\n",
    "\n",
    "pd_ebm = clf_ebm_exp.model_profile(variables= cont_feat)\n",
    "\n",
    "pd_lr_l2 = clf_lr_l2_exp.model_profile(variables= cont_feat)\n",
    "\n",
    "pd_gnb = clf_gnb_exp.model_profile(variables= cont_feat)\n",
    "\n",
    "pd_lr = clf_lr_exp.model_profile(variables= cont_feat)\n",
    "\n",
    "pd_dl = clf_dl_exp.model_profile(variables= cont_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Aggregated Profiles for Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_cart_cat.plot([pd_ebm_cat, pd_gnb_cat, pd_lr_cat, pd_lr_l2_cat, pd_dl_cat], variables=cat_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Aggregated Profiles for Continous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_cart.plot([pd_ebm, pd_gnb, pd_lr, pd_lr_l2, pd_dl], variables=cont_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURES ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calc(feat_gen, feat_comp):\n",
    "    return np.abs(np.subtract(feat_gen[\"_yhat_\"], feat_comp[\"_yhat_\"])).sum()\n",
    "\n",
    "def select_feat_result_cont(feat_name):\n",
    "    feat_cart = pd_cart.result[pd_cart.result[\"_vname_\"] == feat_name]\n",
    "    feat_ebm = pd_ebm.result[pd_ebm.result[\"_vname_\"] == feat_name]\n",
    "    feat_lr = pd_lr.result[pd_lr.result[\"_vname_\"] == feat_name]\n",
    "    feat_gnb = pd_gnb.result[pd_gnb.result[\"_vname_\"] == feat_name]\n",
    "    feat_lr_l2 = pd_lr_l2.result[pd_lr_l2.result[\"_vname_\"] == feat_name]\n",
    "    feat_dl = pd_dl.result[pd_dl.result[\"_vname_\"] == feat_name]\n",
    "    \n",
    "    #define generator clf\n",
    "    gen_res = feat_lr_l2\n",
    "\n",
    "    cart_res = calc(gen_res, feat_cart)\n",
    "    ebm_res = calc(gen_res, feat_ebm)\n",
    "    lr_res = calc(gen_res, feat_lr)\n",
    "    gnb_res = calc(gen_res, feat_gnb)\n",
    "    lr_l2_res = calc(gen_res, feat_lr_l2)\n",
    "    dl_res = calc(gen_res, feat_dl)\n",
    "\n",
    "    dict_result = {\n",
    "        \"Param\": feat_name,\n",
    "        \"CART\": cart_res,\n",
    "        \"EBM\": ebm_res,\n",
    "        \"LR\": lr_res,\n",
    "        \"GNB\": gnb_res,\n",
    "        \"LR_l2\": lr_l2_res,\n",
    "        \"DL\": dl_res\n",
    "    }\n",
    "\n",
    "    return dict_result\n",
    "\n",
    "def select_feat_result_cat(feat_name):\n",
    "    feat_cart = pd_cart_cat.result[pd_cart_cat.result[\"_vname_\"] == feat_name]\n",
    "    feat_ebm = pd_ebm_cat.result[pd_ebm_cat.result[\"_vname_\"] == feat_name]\n",
    "    feat_lr = pd_lr_cat.result[pd_lr_cat.result[\"_vname_\"] == feat_name]\n",
    "    feat_gnb = pd_gnb_cat.result[pd_gnb_cat.result[\"_vname_\"] == feat_name]\n",
    "    feat_lr_l2 = pd_lr_l2_cat.result[pd_lr_l2_cat.result[\"_vname_\"] == feat_name]\n",
    "    feat_dl = pd_dl_cat.result[pd_dl_cat.result[\"_vname_\"] == feat_name]\n",
    "    \n",
    "    #define generator clf\n",
    "    gen_res = feat_lr_l2\n",
    "\n",
    "    cart_res = calc(gen_res, feat_cart)\n",
    "    ebm_res = calc(gen_res, feat_ebm)\n",
    "    lr_res = calc(gen_res, feat_lr)\n",
    "    gnb_res = calc(gen_res, feat_gnb)\n",
    "    lr_l2_res = calc(gen_res, feat_lr_l2)\n",
    "    dl_res = calc(gen_res, feat_dl)\n",
    "\n",
    "    dict_result = {\n",
    "        \"Param\": feat_name,\n",
    "        \"CART\": cart_res,\n",
    "        \"EBM\": ebm_res,\n",
    "        \"LR\": lr_res,\n",
    "        \"GNB\": gnb_res,\n",
    "        \"LR_l2\": lr_l2_res,\n",
    "        \"DL\": dl_res\n",
    "    }\n",
    "\n",
    "    return dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Param      CART       EBM        LR        GNB  LR_l2  \\\n",
      "Param      CreditScore  1.115942  1.354550  2.741803   5.231652    0.0   \n",
      "CART       CreditScore  1.115942  1.354550  2.741803   5.231652    0.0   \n",
      "EBM        CreditScore  1.115942  1.354550  2.741803   5.231652    0.0   \n",
      "LR         CreditScore  1.115942  1.354550  2.741803   5.231652    0.0   \n",
      "GNB        CreditScore  1.115942  1.354550  2.741803   5.231652    0.0   \n",
      "LR_l2      CreditScore  1.115942  1.354550  2.741803   5.231652    0.0   \n",
      "DL         CreditScore  1.115942  1.354550  2.741803   5.231652    0.0   \n",
      "Param              Age  2.286471  1.894085  1.115891  10.580212    0.0   \n",
      "CART               Age  2.286471  1.894085  1.115891  10.580212    0.0   \n",
      "EBM                Age  2.286471  1.894085  1.115891  10.580212    0.0   \n",
      "LR                 Age  2.286471  1.894085  1.115891  10.580212    0.0   \n",
      "GNB                Age  2.286471  1.894085  1.115891  10.580212    0.0   \n",
      "LR_l2              Age  2.286471  1.894085  1.115891  10.580212    0.0   \n",
      "DL                 Age  2.286471  1.894085  1.115891  10.580212    0.0   \n",
      "Param           Tenure  1.656829  1.177718  2.110591   5.089568    0.0   \n",
      "CART            Tenure  1.656829  1.177718  2.110591   5.089568    0.0   \n",
      "EBM             Tenure  1.656829  1.177718  2.110591   5.089568    0.0   \n",
      "LR              Tenure  1.656829  1.177718  2.110591   5.089568    0.0   \n",
      "GNB             Tenure  1.656829  1.177718  2.110591   5.089568    0.0   \n",
      "LR_l2           Tenure  1.656829  1.177718  2.110591   5.089568    0.0   \n",
      "DL              Tenure  1.656829  1.177718  2.110591   5.089568    0.0   \n",
      "Param          Balance  1.189633  1.246986  2.578295   3.030991    0.0   \n",
      "CART           Balance  1.189633  1.246986  2.578295   3.030991    0.0   \n",
      "EBM            Balance  1.189633  1.246986  2.578295   3.030991    0.0   \n",
      "LR             Balance  1.189633  1.246986  2.578295   3.030991    0.0   \n",
      "GNB            Balance  1.189633  1.246986  2.578295   3.030991    0.0   \n",
      "LR_l2          Balance  1.189633  1.246986  2.578295   3.030991    0.0   \n",
      "DL             Balance  1.189633  1.246986  2.578295   3.030991    0.0   \n",
      "Param    NumOfProducts  2.864122  1.302837  1.945575   5.593580    0.0   \n",
      "CART     NumOfProducts  2.864122  1.302837  1.945575   5.593580    0.0   \n",
      "EBM      NumOfProducts  2.864122  1.302837  1.945575   5.593580    0.0   \n",
      "LR       NumOfProducts  2.864122  1.302837  1.945575   5.593580    0.0   \n",
      "GNB      NumOfProducts  2.864122  1.302837  1.945575   5.593580    0.0   \n",
      "LR_l2    NumOfProducts  2.864122  1.302837  1.945575   5.593580    0.0   \n",
      "DL       NumOfProducts  2.864122  1.302837  1.945575   5.593580    0.0   \n",
      "Param  EstimatedSalary  1.714513  1.386113  2.238888   5.030736    0.0   \n",
      "CART   EstimatedSalary  1.714513  1.386113  2.238888   5.030736    0.0   \n",
      "EBM    EstimatedSalary  1.714513  1.386113  2.238888   5.030736    0.0   \n",
      "LR     EstimatedSalary  1.714513  1.386113  2.238888   5.030736    0.0   \n",
      "GNB    EstimatedSalary  1.714513  1.386113  2.238888   5.030736    0.0   \n",
      "LR_l2  EstimatedSalary  1.714513  1.386113  2.238888   5.030736    0.0   \n",
      "DL     EstimatedSalary  1.714513  1.386113  2.238888   5.030736    0.0   \n",
      "\n",
      "              DL  \n",
      "Param   1.969005  \n",
      "CART    1.969005  \n",
      "EBM     1.969005  \n",
      "LR      1.969005  \n",
      "GNB     1.969005  \n",
      "LR_l2   1.969005  \n",
      "DL      1.969005  \n",
      "Param  13.272032  \n",
      "CART   13.272032  \n",
      "EBM    13.272032  \n",
      "LR     13.272032  \n",
      "GNB    13.272032  \n",
      "LR_l2  13.272032  \n",
      "DL     13.272032  \n",
      "Param   2.515663  \n",
      "CART    2.515663  \n",
      "EBM     2.515663  \n",
      "LR      2.515663  \n",
      "GNB     2.515663  \n",
      "LR_l2   2.515663  \n",
      "DL      2.515663  \n",
      "Param   2.221333  \n",
      "CART    2.221333  \n",
      "EBM     2.221333  \n",
      "LR      2.221333  \n",
      "GNB     2.221333  \n",
      "LR_l2   2.221333  \n",
      "DL      2.221333  \n",
      "Param   3.816289  \n",
      "CART    3.816289  \n",
      "EBM     3.816289  \n",
      "LR      3.816289  \n",
      "GNB     3.816289  \n",
      "LR_l2   3.816289  \n",
      "DL      3.816289  \n",
      "Param   2.440013  \n",
      "CART    2.440013  \n",
      "EBM     2.440013  \n",
      "LR      2.440013  \n",
      "GNB     2.440013  \n",
      "LR_l2   2.440013  \n",
      "DL      2.440013  \n",
      "                Param      CART       EBM        LR       GNB  LR_l2        DL\n",
      "Param       Geography  0.047985  0.035394  0.058043  0.134055    0.0  0.075883\n",
      "CART        Geography  0.047985  0.035394  0.058043  0.134055    0.0  0.075883\n",
      "EBM         Geography  0.047985  0.035394  0.058043  0.134055    0.0  0.075883\n",
      "LR          Geography  0.047985  0.035394  0.058043  0.134055    0.0  0.075883\n",
      "GNB         Geography  0.047985  0.035394  0.058043  0.134055    0.0  0.075883\n",
      "LR_l2       Geography  0.047985  0.035394  0.058043  0.134055    0.0  0.075883\n",
      "DL          Geography  0.047985  0.035394  0.058043  0.134055    0.0  0.075883\n",
      "Param          Gender  0.014392  0.030938  0.077501  0.028914    0.0  0.077726\n",
      "CART           Gender  0.014392  0.030938  0.077501  0.028914    0.0  0.077726\n",
      "EBM            Gender  0.014392  0.030938  0.077501  0.028914    0.0  0.077726\n",
      "LR             Gender  0.014392  0.030938  0.077501  0.028914    0.0  0.077726\n",
      "GNB            Gender  0.014392  0.030938  0.077501  0.028914    0.0  0.077726\n",
      "LR_l2          Gender  0.014392  0.030938  0.077501  0.028914    0.0  0.077726\n",
      "DL             Gender  0.014392  0.030938  0.077501  0.028914    0.0  0.077726\n",
      "Param       HasCrCard  0.024037  0.017579  0.049297  0.022637    0.0  0.006381\n",
      "CART        HasCrCard  0.024037  0.017579  0.049297  0.022637    0.0  0.006381\n",
      "EBM         HasCrCard  0.024037  0.017579  0.049297  0.022637    0.0  0.006381\n",
      "LR          HasCrCard  0.024037  0.017579  0.049297  0.022637    0.0  0.006381\n",
      "GNB         HasCrCard  0.024037  0.017579  0.049297  0.022637    0.0  0.006381\n",
      "LR_l2       HasCrCard  0.024037  0.017579  0.049297  0.022637    0.0  0.006381\n",
      "DL          HasCrCard  0.024037  0.017579  0.049297  0.022637    0.0  0.006381\n",
      "Param  IsActiveMember  0.052634  0.042779  0.023799  0.065204    0.0  0.081070\n",
      "CART   IsActiveMember  0.052634  0.042779  0.023799  0.065204    0.0  0.081070\n",
      "EBM    IsActiveMember  0.052634  0.042779  0.023799  0.065204    0.0  0.081070\n",
      "LR     IsActiveMember  0.052634  0.042779  0.023799  0.065204    0.0  0.081070\n",
      "GNB    IsActiveMember  0.052634  0.042779  0.023799  0.065204    0.0  0.081070\n",
      "LR_l2  IsActiveMember  0.052634  0.042779  0.023799  0.065204    0.0  0.081070\n",
      "DL     IsActiveMember  0.052634  0.042779  0.023799  0.065204    0.0  0.081070\n"
     ]
    }
   ],
   "source": [
    "#**Continous results**\n",
    "cont_results = []\n",
    "for param in cont_feat:\n",
    "    param_result = select_feat_result_cont(param)\n",
    "    param_result = pd.DataFrame(param_result, index =list(param_result.keys()))\n",
    "    cont_results.append(param_result)\n",
    "cont_final_res = pd.concat(cont_results)\n",
    "print(cont_final_res)\n",
    "\n",
    "#Categorical results\n",
    "cat_results = []\n",
    "for param in cat_feat:\n",
    "    param_result = select_feat_result_cat(param)\n",
    "    param_result = pd.DataFrame(param_result, index =list(param_result.keys()))\n",
    "    cat_results.append(param_result)\n",
    "cat_final_res = pd.concat(cat_results)\n",
    "print(cat_final_res)\n",
    "pd.concat([cont_final_res, cat_final_res]).to_csv(f\"../worst-case_results/{dataset}_{clf_name}.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54107a2a0eb6a0b2996cb7a94c16d9283b5dc7f969a30a8a01f6dbe77c679ea9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mainenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
