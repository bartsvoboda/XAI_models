{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [\"CART\", \"EBM\", \"LR_l2\", \"GNB\", \"LR\", \"DL\"]\n",
    "dataset_names = ['breast', 'campus', 'churn', 'climate',\n",
    "            'compas', 'diabetes', 'german', 'heart',\n",
    "            'adult', 'student', 'bank', 'credit']\n",
    "\n",
    "dataset_names_dl = ['breast', 'churn', 'compas', 'diabetes',\n",
    "                      'heart', 'adult', 'bank', 'credit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_n = 5\n",
    "dataset_n = 12\n",
    "dataset_dl_n = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CART generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_names_cart = [\"EBM\", \"LR_l2\", \"GNB\", \"LR\", \"DL\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores:\n",
      " (5, 12, 10)\n",
      "\n",
      "Mean results:\n",
      " [[0.96071068 0.97088023 0.9257684  0.95712843 0.92681457]\n",
      " [0.83428571 0.82833333 0.74809524 0.84047619 0.53690476]\n",
      " [0.7251629  0.58751781 0.6596794  0.58788254 0.67504435]\n",
      " [0.6        0.81697959 0.71297959 0.82441837 0.5       ]\n",
      " [0.86368026 0.68169285 0.73417893 0.68169285 0.7919974 ]\n",
      " [0.70537037 0.73139316 0.72405983 0.72939316 0.72859544]\n",
      " [0.66160455 0.67374741 0.67024845 0.67516563 0.5       ]\n",
      " [0.7732381  0.78621429 0.78084524 0.7885119  0.719     ]\n",
      " [0.79438539 0.76725923 0.69613415 0.76725443 0.73287384]\n",
      " [0.64820474 0.68368772 0.66743485 0.67732153 0.50555556]\n",
      " [0.70005165 0.66000264 0.70265968 0.6602862  0.68188161]\n",
      " [0.88084428 0.87087986 0.69917077 0.86689381 0.87017515]]\n",
      "\n",
      "Ranks:\n",
      " [[4.  5.  1.  3.  2. ]\n",
      " [4.  3.  2.  5.  1. ]\n",
      " [5.  1.  3.  2.  4. ]\n",
      " [2.  4.  3.  5.  1. ]\n",
      " [5.  1.5 3.  1.5 4. ]\n",
      " [1.  5.  2.  4.  3. ]\n",
      " [2.  4.  3.  5.  1. ]\n",
      " [2.  4.  3.  5.  1. ]\n",
      " [5.  4.  1.  3.  2. ]\n",
      " [2.  5.  3.  4.  1. ]\n",
      " [4.  1.  5.  2.  3. ]\n",
      " [5.  4.  1.  2.  3. ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.41666667, 3.45833333, 2.5       , 3.45833333, 2.16666667])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_cart = np.load(f'../test_results/acc_fidelity_res/auc_results_{clfs[0]}.npy')\n",
    "print(\"\\nScores:\\n\", results_cart.shape)\n",
    "\n",
    "mean_results_cart = np.mean(results_cart, axis=2).T\n",
    "print(\"\\nMean results:\\n\", mean_results_cart)\n",
    "\n",
    "from scipy.stats import rankdata\n",
    "ranks_cart = []\n",
    "for mr in mean_results_cart:\n",
    "    ranks_cart.append(rankdata(mr).tolist())\n",
    "ranks_cart = np.array(ranks_cart)\n",
    "print(\"\\nRanks:\\n\", ranks_cart)\n",
    "\n",
    "mean_ranks_cart = np.mean(ranks_cart, axis=0)\n",
    "mean_ranks_cart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EBM</th>\n",
       "      <th>LR_l2</th>\n",
       "      <th>GNB</th>\n",
       "      <th>LR</th>\n",
       "      <th>DL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.416667</td>\n",
       "      <td>3.458333</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.458333</td>\n",
       "      <td>2.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EBM     LR_l2  GNB        LR        DL\n",
       "0  3.416667  3.458333  2.5  3.458333  2.166667"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(mean_ranks_cart, index=clf_names_cart).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bias and variance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bias and variance accross all datasets and clfs\n",
    "results_bias_cart = []\n",
    "for clf_name in clf_names_cart:\n",
    "    res_df = pd.read_csv(f\"../test_results/acc_fidelity_res/CART/{clf_name}.csv\")\n",
    "    results_bias_cart.append(res_df)\n",
    "\n",
    "\n",
    "final_results_bias_cart = np.zeros(shape=(clf_n, dataset_n))\n",
    "final_results_var_cart = np.zeros(shape=(clf_n, dataset_n))\n",
    "\n",
    "for clf_id, clf_name in enumerate(clf_names_cart):\n",
    "    for dataset_id, dataset_name in enumerate(dataset_names):\n",
    "        res_df_cart = results_bias_cart[clf_id]\n",
    "        res_dataset_df = res_df_cart[res_df_cart[\"dataset_name\"] == dataset_name]\n",
    "        final_results_bias_cart[clf_id, dataset_id] = res_dataset_df.describe().iloc[1][1]\n",
    "        final_results_var_cart[clf_id, dataset_id] = res_dataset_df.describe().iloc[1][2]  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44870269, 0.35641515, 0.26757809, 0.09066251, 0.30725562,\n",
       "       0.38477855, 0.31368805, 0.44884313, 0.33096236, 0.36642416,\n",
       "       0.16654259, 0.46953688])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results_bias_cart[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45814728, 0.38469155, 0.2410139 , 0.11473658, 0.28740577,\n",
       "       0.40832612, 0.33764565, 0.46066253, 0.33609287, 0.38469185,\n",
       "       0.16183654, 0.47224216])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results_bias_cart[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45900662, 0.34324827, 0.27983168, 0.1001361 , 0.31799261,\n",
       "       0.41302759, 0.43292795, 0.46979646, 0.59954392, 0.40313231,\n",
       "       0.22055441, 0.40398407])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results_bias_cart[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4502288 , 0.37520127, 0.2412035 , 0.13262281, 0.28727723,\n",
       "       0.40881426, 0.33691729, 0.45775216, 0.33593103, 0.37588182,\n",
       "       0.16199617, 0.45707239])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results_bias_cart[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45819379, 0.30781562, 0.26443163, 0.08517983, 0.3060735 ,\n",
       "       0.40266402, 0.29976729, 0.44458341, 0.32492219, 0.44603573,\n",
       "       0.17044358, 0.49006575])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results_bias_cart[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ranks:\n",
      " [[5 3 1 4 2]\n",
      " [3 1 4 2 5]\n",
      " [2 5 1 4 3]\n",
      " [4 2 3 1 5]\n",
      " [2 4 1 5 3]\n",
      " [5 3 1 2 4]\n",
      " [4 2 1 3 5]\n",
      " [4 2 1 3 5]\n",
      " [4 2 1 3 5]\n",
      " [5 3 2 4 1]\n",
      " [3 5 1 4 2]\n",
      " [3 2 5 4 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.66666667, 2.83333333, 1.83333333, 3.25      , 3.41666667])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(final_results_bias_cart.T)\n",
    "\n",
    "ranks_bias_cart = []\n",
    "for mr in final_results_bias_cart.T:\n",
    "    ranks_bias_cart.append(rankdata(mr).tolist())\n",
    "ranks_bias_cart = np.array(ranks_bias_cart)\n",
    "ranks_bias_cart = len(ranks_bias_cart[0])+1 - ranks_bias_cart.astype(int)\n",
    "print(\"\\nRanks:\\n\", ranks_bias_cart)\n",
    "\n",
    "mean_ranks_bias_cart = np.mean(ranks_bias_cart, axis=0)\n",
    "mean_ranks_bias_cart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.25      ,  0.625     ,  0.66666667,  0.20833333, -1.25      ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.subtract(mean_ranks_cart, mean_ranks_bias_cart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_acc_bias_cart = np.array([ 0      ,  0.625     ,  0.66666667,  0.20833333, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EBM</th>\n",
       "      <th>LR_l2</th>\n",
       "      <th>GNB</th>\n",
       "      <th>LR</th>\n",
       "      <th>DL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EBM  LR_l2       GNB        LR   DL\n",
       "0  0.0  0.625  0.666667  0.208333  0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(final_acc_bias_cart, index=clf_names_cart).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EBM generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores:\n",
      " (5, 12, 10)\n",
      "\n",
      "Mean results:\n",
      " [[0.91590909 0.97088023 0.9257684  0.95712843 0.92681457]\n",
      " [0.79       0.82833333 0.74809524 0.84047619 0.53690476]\n",
      " [0.94649328 0.67456559 0.74935789 0.67569886 0.85882901]\n",
      " [0.68771429 0.81697959 0.71297959 0.82441837 0.5       ]\n",
      " [0.9997342  0.96956596 0.95667769 0.99982285 0.86698976]\n",
      " [0.86027056 0.86796537 0.84999459 0.87034632 0.82700216]\n",
      " [0.76822755 0.86177757 0.77197043 0.87456478 0.5       ]\n",
      " [0.88211905 0.92428571 0.91595238 0.91164286 0.86871429]\n",
      " [0.93758855 0.90625434 0.74266489 0.90691091 0.83057514]\n",
      " [0.67920833 0.80733333 0.78191667 0.80004167 0.50979167]\n",
      " [0.89253552 0.83882165 0.83254986 0.83944322 0.78527201]\n",
      " [0.92368212 0.93184964 0.78097678 0.92492184 0.92551188]]\n",
      "\n",
      "Ranks:\n",
      " [[1. 5. 2. 4. 3.]\n",
      " [3. 4. 2. 5. 1.]\n",
      " [5. 1. 3. 2. 4.]\n",
      " [2. 4. 3. 5. 1.]\n",
      " [4. 3. 2. 5. 1.]\n",
      " [3. 4. 2. 5. 1.]\n",
      " [2. 4. 3. 5. 1.]\n",
      " [2. 5. 4. 3. 1.]\n",
      " [5. 3. 1. 4. 2.]\n",
      " [2. 5. 3. 4. 1.]\n",
      " [5. 3. 2. 4. 1.]\n",
      " [2. 5. 1. 3. 4.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.        , 3.83333333, 2.33333333, 4.08333333, 1.75      ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_names_ebm = [\"CART\", \"LR_l2\", \"GNB\", \"LR\", \"DL\"] \n",
    "results_ebm = np.load(f'../test_results/acc_fidelity_res/auc_results_{clfs[1]}.npy')\n",
    "print(\"\\nScores:\\n\", results_ebm.shape)\n",
    "\n",
    "mean_results_ebm = np.mean(results_ebm, axis=2).T\n",
    "print(\"\\nMean results:\\n\", mean_results_ebm)\n",
    "\n",
    "from scipy.stats import rankdata\n",
    "ranks_ebm = []\n",
    "for mr in mean_results_ebm:\n",
    "    ranks_ebm.append(rankdata(mr).tolist())\n",
    "ranks_ebm = np.array(ranks_ebm)\n",
    "print(\"\\nRanks:\\n\", ranks_ebm)\n",
    "\n",
    "mean_ranks_ebm = np.mean(ranks_ebm, axis=0)\n",
    "mean_ranks_ebm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CART</th>\n",
       "      <th>LR_l2</th>\n",
       "      <th>GNB</th>\n",
       "      <th>LR</th>\n",
       "      <th>DL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>4.083333</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CART     LR_l2       GNB        LR    DL\n",
       "0   3.0  3.833333  2.333333  4.083333  1.75"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(mean_ranks_ebm, index=clf_names_ebm).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bias and variance accross all datasets and clfs\n",
    "results_bias_ebm = []\n",
    "for clf_name in clf_names_ebm:\n",
    "    res_df = pd.read_csv(f\"../test_results/acc_fidelity_res/EBM/{clf_name}.csv\")\n",
    "    results_bias_ebm.append(res_df)\n",
    "\n",
    "\n",
    "final_results_bias_ebm = np.zeros(shape=(clf_n, dataset_n))\n",
    "final_results_var_ebm = np.zeros(shape=(clf_n, dataset_n))\n",
    "\n",
    "for clf_id, clf_name in enumerate(clf_names_ebm):\n",
    "    for dataset_id, dataset_name in enumerate(dataset_names):\n",
    "        res_df_ebm = results_bias_ebm[clf_id]\n",
    "        res_dataset_df = res_df_ebm[res_df_ebm[\"dataset_name\"] == dataset_name]\n",
    "        final_results_bias_ebm[clf_id, dataset_id] = res_dataset_df.describe().iloc[1][1]\n",
    "        final_results_var_ebm[clf_id, dataset_id] = res_dataset_df.describe().iloc[1][2]  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ranks:\n",
      " [[5 3 1 4 2]\n",
      " [4 1 3 2 5]\n",
      " [2 5 3 4 1]\n",
      " [3 2 4 1 5]\n",
      " [2 4 1 3 5]\n",
      " [5 2 3 4 1]\n",
      " [4 2 1 3 5]\n",
      " [5 1 3 2 4]\n",
      " [4 2 1 3 5]\n",
      " [5 1 4 2 3]\n",
      " [4 3 1 2 5]\n",
      " [4 2 5 3 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.91666667, 2.33333333, 2.5       , 2.75      , 3.5       ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(final_results_bias_ebm.T)\n",
    "\n",
    "ranks_bias_ebm = []\n",
    "for mr in final_results_bias_ebm.T:\n",
    "    ranks_bias_ebm.append(rankdata(mr).tolist())\n",
    "ranks_bias_ebm = np.array(ranks_bias_ebm)\n",
    "ranks_bias_ebm = len(ranks_bias_ebm[0])+1 - ranks_bias_ebm.astype(int)\n",
    "print(\"\\nRanks:\\n\", ranks_bias_ebm)\n",
    "\n",
    "mean_ranks_bias_ebm = np.mean(ranks_bias_ebm, axis=0)\n",
    "mean_ranks_bias_ebm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.91666667,  1.5       , -0.16666667,  1.33333333, -1.75      ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.subtract(mean_ranks_ebm, mean_ranks_bias_ebm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_acc_bias_ebm = np.array([ 0,  1.5       , 0,  1.33333333, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CART</th>\n",
       "      <th>LR_l2</th>\n",
       "      <th>GNB</th>\n",
       "      <th>LR</th>\n",
       "      <th>DL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CART  LR_l2  GNB        LR   DL\n",
       "0   0.0    1.5  0.0  1.333333  0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(final_acc_bias_ebm, index=clf_names_ebm).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR_l2 generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores:\n",
      " (5, 12, 10)\n",
      "\n",
      "Mean results:\n",
      " [[0.93718254 0.96059524 0.93380952 0.99007937 0.93650794]\n",
      " [0.81845238 0.93044643 0.80282738 0.96758929 0.5       ]\n",
      " [0.94562791 0.95859702 0.87870321 0.99408626 0.74906346]\n",
      " [0.67394118 0.59285294 0.71985294 0.95122549 0.5       ]\n",
      " [0.99838272 0.99764727 0.81819358 0.99973545 0.80787498]\n",
      " [0.87590368 0.94103896 0.90528139 0.99017857 0.88987013]\n",
      " [0.78813201 0.91597602 0.84762889 0.96321393 0.5       ]\n",
      " [0.93728745 0.96479757 0.91954453 0.98204453 0.88216599]\n",
      " [0.94041697 0.98736321 0.773278   0.99642703 0.88386056]\n",
      " [0.75871963 0.87361466 0.82166454 0.90286658 0.51725277]\n",
      " [0.935699   0.97411801 0.8612715  0.99694053 0.87129287]\n",
      " [0.95544508 0.97258523 0.91543561 0.98011364 0.95904356]]\n",
      "\n",
      "Ranks:\n",
      " [[3. 4. 1. 5. 2.]\n",
      " [3. 4. 2. 5. 1.]\n",
      " [3. 4. 2. 5. 1.]\n",
      " [3. 2. 4. 5. 1.]\n",
      " [4. 3. 2. 5. 1.]\n",
      " [1. 4. 3. 5. 2.]\n",
      " [2. 4. 3. 5. 1.]\n",
      " [3. 4. 2. 5. 1.]\n",
      " [3. 4. 1. 5. 2.]\n",
      " [2. 4. 3. 5. 1.]\n",
      " [3. 4. 1. 5. 2.]\n",
      " [2. 4. 1. 5. 3.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.66666667, 3.75      , 2.08333333, 5.        , 1.5       ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_names_lr_l2 = [\"CART\", \"EBM\", \"GNB\", \"LR\", \"DL\"] \n",
    "results_lr_l2 = np.load(f'../test_results/acc_fidelity_res/auc_results_{clfs[2]}.npy')\n",
    "print(\"\\nScores:\\n\", results_lr_l2.shape)\n",
    "\n",
    "mean_results_lr_l2 = np.mean(results_lr_l2, axis=2).T\n",
    "print(\"\\nMean results:\\n\", mean_results_lr_l2)\n",
    "\n",
    "from scipy.stats import rankdata\n",
    "ranks_lr_l2 = []\n",
    "for mr in mean_results_lr_l2:\n",
    "    ranks_lr_l2.append(rankdata(mr).tolist())\n",
    "ranks_lr_l2 = np.array(ranks_lr_l2)\n",
    "print(\"\\nRanks:\\n\", ranks_lr_l2)\n",
    "\n",
    "mean_ranks_lr_l2 = np.mean(ranks_lr_l2, axis=0)\n",
    "mean_ranks_lr_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CART</th>\n",
       "      <th>EBM</th>\n",
       "      <th>GNB</th>\n",
       "      <th>LR</th>\n",
       "      <th>DL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CART   EBM       GNB   LR   DL\n",
       "0  2.666667  3.75  2.083333  5.0  1.5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(mean_ranks_lr_l2, index=clf_names_lr_l2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bias and variance accross all datasets and clfs\n",
    "results_bias_lr_l2 = []\n",
    "for clf_name in clf_names_lr_l2:\n",
    "    res_df = pd.read_csv(f\"../test_results/acc_fidelity_res/LR_l2/{clf_name}.csv\")\n",
    "    results_bias_lr_l2.append(res_df)\n",
    "\n",
    "\n",
    "final_results_bias_lr_l2 = np.zeros(shape=(clf_n, dataset_n))\n",
    "final_results_var_lr_l2 = np.zeros(shape=(clf_n, dataset_n))\n",
    "\n",
    "for clf_id, clf_name in enumerate(clf_names_lr_l2):\n",
    "    for dataset_id, dataset_name in enumerate(dataset_names):\n",
    "        res_df_lr_l2 = results_bias_lr_l2[clf_id]\n",
    "        res_dataset_df = res_df_lr_l2[res_df_lr_l2[\"dataset_name\"] == dataset_name]\n",
    "        final_results_bias_lr_l2[clf_id, dataset_id] = res_dataset_df.describe().iloc[1][1]\n",
    "        final_results_var_lr_l2[clf_id, dataset_id] = res_dataset_df.describe().iloc[1][2]  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ranks:\n",
      " [[5 4 3 2 1]\n",
      " [4 2 3 1 5]\n",
      " [4 3 1 2 5]\n",
      " [3 4 2 1 5]\n",
      " [4 3 1 2 5]\n",
      " [5 4 3 1 2]\n",
      " [4 3 1 2 5]\n",
      " [5 2 3 1 4]\n",
      " [5 3 1 2 4]\n",
      " [5 3 2 1 4]\n",
      " [5 3 1 2 4]\n",
      " [4 2 5 3 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4.41666667, 3.        , 2.16666667, 1.66666667, 3.75      ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(final_results_bias_lr_l2.T)\n",
    "\n",
    "ranks_bias_lr_l2 = []\n",
    "for mr in final_results_bias_lr_l2.T:\n",
    "    ranks_bias_lr_l2.append(rankdata(mr).tolist())\n",
    "ranks_bias_lr_l2 = np.array(ranks_bias_lr_l2)\n",
    "ranks_bias_lr_l2 = len(ranks_bias_lr_l2[0])+1 - ranks_bias_lr_l2.astype(int)\n",
    "print(\"\\nRanks:\\n\", ranks_bias_lr_l2)\n",
    "\n",
    "mean_ranks_bias_lr_l2 = np.mean(ranks_bias_lr_l2, axis=0)\n",
    "mean_ranks_bias_lr_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.75      ,  0.75      , -0.08333333,  3.33333333, -2.25      ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.subtract(mean_ranks_lr_l2, mean_ranks_bias_lr_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_acc_bias_lr_l2 = np.array([0      ,  0.75      , 0,  3.33333333, 0      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CART</th>\n",
       "      <th>EBM</th>\n",
       "      <th>GNB</th>\n",
       "      <th>LR</th>\n",
       "      <th>DL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CART   EBM  GNB        LR   DL\n",
       "0   0.0  0.75  0.0  3.333333  0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(final_acc_bias_lr_l2, index=clf_names_lr_l2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNB generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores:\n",
      " (5, 12, 10)\n",
      "\n",
      "Mean results:\n",
      " [[0.94951308 0.98535714 0.96344166 0.95780459 0.94151544]\n",
      " [0.82482143 0.91720238 0.90803571 0.96785714 0.5       ]\n",
      " [0.95934092 0.97692897 0.90173047 0.9036407  0.8463934 ]\n",
      " [0.73235294 0.68235294 0.88039216 0.90882353 0.5       ]\n",
      " [0.99689092 0.99844833 0.99094426 0.99207413 0.88724386]\n",
      " [0.88484887 0.94480238 0.93062751 0.93091463 0.86549676]\n",
      " [0.78418579 0.95918562 0.93435644 0.95681209 0.4994084 ]\n",
      " [0.92693398 0.96231494 0.94489719 0.9576342  0.88787121]\n",
      " [0.98408389 0.99392331 0.97825363 0.99480194 0.5       ]\n",
      " [0.8645     0.90992857 0.93339286 0.92047619 0.5102381 ]\n",
      " [0.95715053 0.98252266 0.95800245 0.9650574  0.76785847]\n",
      " [0.88572506 0.93263575 0.93834842 0.93420868 0.89011258]]\n",
      "\n",
      "Ranks:\n",
      " [[2. 5. 4. 3. 1.]\n",
      " [2. 4. 3. 5. 1.]\n",
      " [4. 5. 2. 3. 1.]\n",
      " [3. 2. 4. 5. 1.]\n",
      " [4. 5. 2. 3. 1.]\n",
      " [2. 5. 3. 4. 1.]\n",
      " [2. 5. 3. 4. 1.]\n",
      " [2. 5. 3. 4. 1.]\n",
      " [3. 4. 2. 5. 1.]\n",
      " [2. 3. 5. 4. 1.]\n",
      " [2. 5. 3. 4. 1.]\n",
      " [1. 3. 5. 4. 2.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.41666667, 4.25      , 3.25      , 4.        , 1.08333333])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_names_gnb = [\"CART\", \"EBM\", \"LR_l2\", \"LR\", \"DL\"] \n",
    "results_gnb = np.load(f'../test_results/acc_fidelity_res/auc_results_{clfs[3]}.npy')\n",
    "print(\"\\nScores:\\n\", results_gnb.shape)\n",
    "\n",
    "mean_results_gnb = np.mean(results_gnb, axis=2).T\n",
    "print(\"\\nMean results:\\n\", mean_results_gnb)\n",
    "\n",
    "from scipy.stats import rankdata\n",
    "ranks_gnb = []\n",
    "for mr in mean_results_gnb:\n",
    "    ranks_gnb.append(rankdata(mr).tolist())\n",
    "ranks_gnb = np.array(ranks_gnb)\n",
    "print(\"\\nRanks:\\n\", ranks_gnb)\n",
    "\n",
    "mean_ranks_gnb = np.mean(ranks_gnb, axis=0)\n",
    "mean_ranks_gnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CART</th>\n",
       "      <th>EBM</th>\n",
       "      <th>LR_l2</th>\n",
       "      <th>LR</th>\n",
       "      <th>DL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.416667</td>\n",
       "      <td>4.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CART   EBM  LR_l2   LR        DL\n",
       "0  2.416667  4.25   3.25  4.0  1.083333"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(mean_ranks_gnb, index=clf_names_gnb).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bias and variance accross all datasets and clfs\n",
    "results_bias_gnb= []\n",
    "for clf_name in clf_names_gnb:\n",
    "    res_df = pd.read_csv(f\"../test_results/acc_fidelity_res/GNB/{clf_name}.csv\")\n",
    "    results_bias_gnb.append(res_df)\n",
    "\n",
    "\n",
    "final_results_bias_gnb = np.zeros(shape=(clf_n, dataset_n))\n",
    "final_results_var_gnb = np.zeros(shape=(clf_n, dataset_n))\n",
    "\n",
    "for clf_id, clf_name in enumerate(clf_names_gnb):\n",
    "    for dataset_id, dataset_name in enumerate(dataset_names):\n",
    "        res_df_gnb = results_bias_gnb[clf_id]\n",
    "        res_dataset_df = res_df_gnb[res_df_gnb[\"dataset_name\"] == dataset_name]\n",
    "        final_results_bias_gnb[clf_id, dataset_id] = res_dataset_df.describe().iloc[1][1]\n",
    "        final_results_var_gnb[clf_id, dataset_id] = res_dataset_df.describe().iloc[1][2]  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ranks:\n",
      " [[5 3 2 4 1]\n",
      " [4 3 2 1 5]\n",
      " [4 1 3 2 5]\n",
      " [3 4 2 1 5]\n",
      " [5 3 2 4 1]\n",
      " [5 4 2 1 3]\n",
      " [5 3 1 2 4]\n",
      " [5 3 1 2 4]\n",
      " [4 2 3 1 5]\n",
      " [4 2 1 3 5]\n",
      " [4 2 3 1 5]\n",
      " [5 4 3 2 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4.41666667, 2.83333333, 2.08333333, 2.        , 3.66666667])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(final_results_bias_gnb.T)\n",
    "\n",
    "ranks_bias_gnb = []\n",
    "for mr in final_results_bias_gnb.T:\n",
    "    ranks_bias_gnb.append(rankdata(mr).tolist())\n",
    "ranks_bias_gnb = np.array(ranks_bias_gnb)\n",
    "ranks_bias_gnb = len(ranks_bias_gnb[0])+1 - ranks_bias_gnb.astype(int)\n",
    "print(\"\\nRanks:\\n\", ranks_bias_gnb)\n",
    "\n",
    "mean_ranks_bias_gnb = np.mean(ranks_bias_gnb, axis=0)\n",
    "mean_ranks_bias_gnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.        ,  1.41666667,  1.16666667,  2.        , -2.58333333])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.subtract(mean_ranks_gnb, mean_ranks_bias_gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_acc_bias_gnb = np.array([0,  1.41666667,  1.16666667,  2.        , 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CART</th>\n",
       "      <th>EBM</th>\n",
       "      <th>LR_l2</th>\n",
       "      <th>LR</th>\n",
       "      <th>DL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CART       EBM     LR_l2   LR   DL\n",
       "0   0.0  1.416667  1.166667  2.0  0.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(final_acc_bias_gnb, index=clf_names_gnb).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores:\n",
      " (5, 12, 10)\n",
      "\n",
      "Mean results:\n",
      " [[0.93248918 0.96785714 0.97685426 0.92621934 0.93861111]\n",
      " [0.83309524 0.92809524 0.96571429 0.81238095 0.50714286]\n",
      " [0.94562791 0.95859702 0.97751152 0.87870321 0.74906346]\n",
      " [0.65295098 0.58135294 0.87916667 0.69901961 0.5       ]\n",
      " [0.99838272 0.99764727 0.99331414 0.81819358 0.80787498]\n",
      " [0.89458333 0.91910714 0.97517857 0.90327381 0.89386905]\n",
      " [0.76773684 0.91638158 0.9349386  0.81864912 0.50208333]\n",
      " [0.9216336  0.9667753  0.96269231 0.92502834 0.88462146]\n",
      " [0.93893897 0.98749896 0.98882197 0.76661897 0.88250361]\n",
      " [0.77205301 0.91155909 0.92650474 0.79243345 0.50995844]\n",
      " [0.93760899 0.97737672 0.98513495 0.86175666 0.87223156]\n",
      " [0.93261924 0.95161793 0.95621074 0.76458109 0.93843834]]\n",
      "\n",
      "Ranks:\n",
      " [[2. 4. 5. 1. 3.]\n",
      " [3. 4. 5. 2. 1.]\n",
      " [3. 4. 5. 2. 1.]\n",
      " [3. 2. 5. 4. 1.]\n",
      " [5. 4. 3. 2. 1.]\n",
      " [2. 4. 5. 3. 1.]\n",
      " [2. 4. 5. 3. 1.]\n",
      " [2. 5. 4. 3. 1.]\n",
      " [3. 4. 5. 1. 2.]\n",
      " [2. 4. 5. 3. 1.]\n",
      " [3. 4. 5. 1. 2.]\n",
      " [2. 4. 5. 1. 3.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.66666667, 3.91666667, 4.75      , 2.16666667, 1.5       ])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_names_lr = [\"CART\", \"EBM\", \"LR_l2\", \"GNB\", \"DL\"] \n",
    "results_lr = np.load(f'../test_results/acc_fidelity_res/auc_results_{clfs[4]}.npy')\n",
    "print(\"\\nScores:\\n\", results_lr.shape)\n",
    "\n",
    "mean_results_lr = np.mean(results_lr, axis=2).T\n",
    "print(\"\\nMean results:\\n\", mean_results_lr)\n",
    "\n",
    "from scipy.stats import rankdata\n",
    "ranks_lr = []\n",
    "for mr in mean_results_lr:\n",
    "    ranks_lr.append(rankdata(mr).tolist())\n",
    "ranks_lr = np.array(ranks_lr)\n",
    "print(\"\\nRanks:\\n\", ranks_lr)\n",
    "\n",
    "mean_ranks_lr = np.mean(ranks_lr, axis=0)\n",
    "mean_ranks_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CART</th>\n",
       "      <th>EBM</th>\n",
       "      <th>LR_l2</th>\n",
       "      <th>GNB</th>\n",
       "      <th>DL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>4.75</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CART       EBM  LR_l2       GNB   DL\n",
       "0  2.666667  3.916667   4.75  2.166667  1.5"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(mean_ranks_lr, index=clf_names_lr).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bias and variance accross all datasets and clfs\n",
    "results_bias_lr = []\n",
    "for clf_name in clf_names_lr:\n",
    "    res_df = pd.read_csv(f\"../test_results/acc_fidelity_res/LR/{clf_name}.csv\")\n",
    "    results_bias_lr.append(res_df)\n",
    "\n",
    "\n",
    "final_results_bias_lr = np.zeros(shape=(clf_n, dataset_n))\n",
    "final_results_var_lr = np.zeros(shape=(clf_n, dataset_n))\n",
    "\n",
    "for clf_id, clf_name in enumerate(clf_names_lr):\n",
    "    for dataset_id, dataset_name in enumerate(dataset_names):\n",
    "        res_df_lr = results_bias_lr[clf_id]\n",
    "        res_dataset_df = res_df_lr[res_df_lr[\"dataset_name\"] == dataset_name]\n",
    "        final_results_bias_lr[clf_id, dataset_id] = res_dataset_df.describe().iloc[1][1]\n",
    "        final_results_var_lr[clf_id, dataset_id] = res_dataset_df.describe().iloc[1][2]  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ranks:\n",
      " [[5 4 2 3 1]\n",
      " [4 2 1 3 5]\n",
      " [4 3 2 1 5]\n",
      " [2 4 1 3 5]\n",
      " [4 3 2 1 5]\n",
      " [5 4 2 3 1]\n",
      " [4 3 2 1 5]\n",
      " [5 2 1 4 3]\n",
      " [5 3 2 1 4]\n",
      " [5 2 1 4 3]\n",
      " [5 3 2 1 4]\n",
      " [4 3 2 5 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4.33333333, 3.        , 1.66666667, 2.5       , 3.5       ])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(final_results_bias_lr.T)\n",
    "\n",
    "ranks_bias_lr = []\n",
    "for mr in final_results_bias_lr.T:\n",
    "    ranks_bias_lr.append(rankdata(mr).tolist())\n",
    "ranks_bias_lr = np.array(ranks_bias_lr)\n",
    "ranks_bias_lr = len(ranks_bias_lr[0])+1 - ranks_bias_lr.astype(int)\n",
    "print(\"\\nRanks:\\n\", ranks_bias_lr)\n",
    "\n",
    "mean_ranks_bias_lr = np.mean(ranks_bias_lr, axis=0)\n",
    "mean_ranks_bias_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.66666667,  0.91666667,  3.08333333, -0.33333333, -2.        ])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.subtract(mean_ranks_lr, mean_ranks_bias_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_acc_bias_lr = np.array([0,  0.91666667,  3.08333333, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CART</th>\n",
       "      <th>EBM</th>\n",
       "      <th>LR_l2</th>\n",
       "      <th>GNB</th>\n",
       "      <th>DL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CART       EBM     LR_l2  GNB   DL\n",
       "0   0.0  0.916667  3.083333  0.0  0.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(final_acc_bias_lr, index=clf_names_lr).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DL generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores:\n",
      " (6, 8, 10)\n",
      "\n",
      "Mean results:\n",
      " [[0.96154867 0.97005299 0.96819538 0.92952947 0.9556576  0.        ]\n",
      " [1.         1.         0.77422546 0.86001147 0.77783191 0.        ]\n",
      " [1.         0.99918699 1.         0.99918699 0.99989858 0.        ]\n",
      " [0.98548265 0.97779035 0.94288989 0.88581599 0.94473756 0.        ]\n",
      " [0.95399374 0.94812253 0.91763011 0.89275362 0.93022069 0.        ]\n",
      " [1.         0.99943467 0.99197968 0.77924443 0.9932277  0.        ]\n",
      " [0.99983713 0.99891653 0.99374393 0.89338678 0.99827905 0.        ]\n",
      " [1.         1.         0.9983871  1.         0.9983871  0.        ]]\n",
      "\n",
      "Ranks:\n",
      " [[4.  6.  5.  2.  3.  1. ]\n",
      " [5.5 5.5 2.  4.  3.  1. ]\n",
      " [5.5 2.5 5.5 2.5 4.  1. ]\n",
      " [6.  5.  3.  2.  4.  1. ]\n",
      " [6.  5.  3.  2.  4.  1. ]\n",
      " [6.  5.  3.  2.  4.  1. ]\n",
      " [6.  5.  3.  2.  4.  1. ]\n",
      " [5.  5.  2.5 5.  2.5 1. ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5.5   , 4.875 , 3.375 , 2.6875, 3.5625])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_names_dl = [\"CART\", \"EBM\", \"LR_l2\", \"GNB\", \"LR\"]\n",
    "results_dl = np.load(f'../test_results/acc_fidelity_res/auc_results_{clfs[5]}.npy')\n",
    "print(\"\\nScores:\\n\", results_dl.shape)\n",
    "\n",
    "mean_results_dl = np.mean(results_dl, axis=2).T\n",
    "print(\"\\nMean results:\\n\", mean_results_dl)\n",
    "\n",
    "from scipy.stats import rankdata\n",
    "ranks_dl = []\n",
    "for mr in mean_results_dl:\n",
    "    ranks_dl.append(rankdata(mr).tolist())\n",
    "ranks_dl = np.array(ranks_dl)\n",
    "print(\"\\nRanks:\\n\", ranks_dl)\n",
    "\n",
    "mean_ranks_dl = np.mean(ranks_dl, axis=0)\n",
    "mean_ranks_dl[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CART</th>\n",
       "      <th>EBM</th>\n",
       "      <th>LR_l2</th>\n",
       "      <th>GNB</th>\n",
       "      <th>LR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.5</td>\n",
       "      <td>4.875</td>\n",
       "      <td>3.375</td>\n",
       "      <td>2.6875</td>\n",
       "      <td>3.5625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CART    EBM  LR_l2     GNB      LR\n",
       "0   5.5  4.875  3.375  2.6875  3.5625"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(mean_ranks_dl[:-1], index=clf_names_dl).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bias and variance accross all datasets and clfs\n",
    "results_bias_dl = []\n",
    "for clf_name in clf_names_dl:\n",
    "    res_df = pd.read_csv(f\"../test_results/acc_fidelity_res/DL/{clf_name}.csv\")\n",
    "    results_bias_dl.append(res_df)\n",
    "\n",
    "\n",
    "final_results_bias_dl = np.zeros(shape=(clf_n, dataset_n))\n",
    "final_results_var_dl = np.zeros(shape=(clf_n, dataset_n))\n",
    "\n",
    "for clf_id, clf_name in enumerate(clf_names_dl):\n",
    "    for dataset_id, dataset_name in enumerate(dataset_names_dl):\n",
    "        res_df_dl = results_bias_dl[clf_id]\n",
    "        res_dataset_df = res_df_dl[res_df_dl[\"dataset_name\"] == dataset_name]\n",
    "        final_results_bias_dl[clf_id, dataset_id] = res_dataset_df.describe().iloc[1][1]\n",
    "        final_results_var_dl[clf_id, dataset_id] = res_dataset_df.describe().iloc[1][2]  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ranks:\n",
      " [[5 3 2 1 4]\n",
      " [2 2 5 3 4]\n",
      " [1 4 3 5 2]\n",
      " [3 1 4 5 2]\n",
      " [5 4 2 1 3]\n",
      " [2 5 4 1 3]\n",
      " [2 3 5 1 4]\n",
      " [2 2 5 2 5]\n",
      " [3 3 3 3 3]\n",
      " [3 3 3 3 3]\n",
      " [3 3 3 3 3]\n",
      " [3 3 3 3 3]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.83333333, 3.        , 3.5       , 2.58333333, 3.25      ])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(final_results_bias_dl.T)\n",
    "\n",
    "ranks_bias_dl = []\n",
    "for mr in final_results_bias_dl.T:\n",
    "    ranks_bias_dl.append(rankdata(mr).tolist())\n",
    "ranks_bias_dl = np.array(ranks_bias_dl)\n",
    "ranks_bias_dl = len(ranks_bias_dl[0])+1 - ranks_bias_dl.astype(int)\n",
    "print(\"\\nRanks:\\n\", ranks_bias_dl)\n",
    "\n",
    "mean_ranks_bias_dl = np.mean(ranks_bias_dl, axis=0)\n",
    "mean_ranks_bias_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.66666667,  1.875     , -0.125     ,  0.10416667,  0.3125    ])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.subtract(mean_ranks_dl[:-1], mean_ranks_bias_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_acc_bias_dl = np.array([2.66666667,  1.875     , 0   ,  0.10416667,  0.3125])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CART</th>\n",
       "      <th>EBM</th>\n",
       "      <th>LR_l2</th>\n",
       "      <th>GNB</th>\n",
       "      <th>LR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CART    EBM  LR_l2       GNB      LR\n",
       "0  2.666667  1.875    0.0  0.104167  0.3125"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(final_acc_bias_dl, index=clf_names_dl).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_1 = final_acc_bias_ebm[0]\n",
    "ebm_1 = final_acc_bias_cart[0]\n",
    "lr_l2_1 = final_acc_bias_cart[1]\n",
    "gnb_1 = final_acc_bias_cart[2]\n",
    "lr_1 = final_acc_bias_cart[3]\n",
    "dl_1 = final_acc_bias_cart[4]\n",
    "\n",
    "cart_2 = final_acc_bias_lr_l2[0]\n",
    "ebm_2 = final_acc_bias_lr_l2[1]\n",
    "lr_l2_2 = final_acc_bias_ebm[1]\n",
    "gnb_2 = final_acc_bias_ebm[2]\n",
    "lr_2 = final_acc_bias_ebm[3]\n",
    "dl_2 = final_acc_bias_ebm[4]\n",
    "\n",
    "cart_3 = final_acc_bias_gnb[0]\n",
    "ebm_3 = final_acc_bias_gnb[1]\n",
    "lr_l2_3 = final_acc_bias_gnb[2]\n",
    "gnb_3 = final_acc_bias_lr_l2[3]\n",
    "lr_3 = final_acc_bias_gnb[3]\n",
    "dl_3 = final_acc_bias_lr_l2[4]\n",
    "\n",
    "cart_4 = final_acc_bias_lr[0]\n",
    "ebm_4 = final_acc_bias_lr[1]\n",
    "lr_l2_4 = final_acc_bias_lr[2]\n",
    "gnb_4 = final_acc_bias_lr[3]\n",
    "lr_4 = final_acc_bias_lr_l2[3]\n",
    "dl_4 = final_acc_bias_gnb[4]\n",
    "\n",
    "cart_5 = final_acc_bias_dl[0]\n",
    "ebm_5 = final_acc_bias_dl[1]\n",
    "lr_l2_5 = final_acc_bias_dl[2]\n",
    "gnb_5 = final_acc_bias_dl[3]\n",
    "lr_5 = final_acc_bias_dl[4]\n",
    "dl_5 = final_acc_bias_lr[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_list = [cart_1, cart_2, cart_3, cart_4, cart_5]\n",
    "cart_fin = pd.DataFrame(cart_list).T.mean(axis=1)\n",
    "\n",
    "gnb_list = [gnb_1, gnb_2, gnb_3, gnb_4, gnb_5]\n",
    "gnb_fin = pd.DataFrame(gnb_list).T.mean(axis=1)\n",
    "\n",
    "lr_list = [lr_1, lr_2, lr_3, lr_4, lr_5]\n",
    "lr_fin = pd.DataFrame(lr_list).T.mean(axis=1)\n",
    "\n",
    "lr_l2_list = [lr_l2_1, lr_l2_2, lr_l2_3, lr_l2_4, lr_l2_5]\n",
    "lr_l2_fin = pd.DataFrame(lr_l2_list).T.mean(axis=1)\n",
    "\n",
    "dl_list = [dl_1, dl_2, dl_3, dl_4, dl_5]\n",
    "dl_fin = pd.DataFrame(dl_list).T.mean(axis=1)\n",
    "\n",
    "ebm_list = [ebm_1, ebm_2, ebm_3, ebm_4, ebm_5]\n",
    "ebm_fin = pd.DataFrame(ebm_list).T.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.533333\n",
       "dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cart_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 2.66666667]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cart_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.66666667, 0.0, 3.33333333, 0.0, 0.10416667]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.820833\n",
       "dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.4375\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.20833333, 1.33333333, 2.0, 3.33333333, 0.3125]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.275\n",
       "dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_l2_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.625, 1.5, 1.16666667, 3.08333333, 0.0]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_l2_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.991667\n",
       "dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebm_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.75, 1.41666667, 0.91666667, 1.875]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebm_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>1.4375</td>\n",
       "      <td>1.275</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2       3      4    5\n",
       "0  0.533333  0.991667  0.820833  1.4375  1.275  0.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame((cart_fin, ebm_fin, gnb_fin, lr_fin, lr_l2_fin, dl_fin)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54107a2a0eb6a0b2996cb7a94c16d9283b5dc7f969a30a8a01f6dbe77c679ea9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mainenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
