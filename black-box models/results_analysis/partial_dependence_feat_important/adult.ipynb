{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bart/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:53:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Learning rate set to 0.045587\n",
      "0:\tlearn: 0.6453971\ttotal: 385ms\tremaining: 6m 24s\n",
      "1:\tlearn: 0.6070598\ttotal: 759ms\tremaining: 6m 18s\n",
      "2:\tlearn: 0.5687926\ttotal: 1s\tremaining: 5m 32s\n",
      "3:\tlearn: 0.5409262\ttotal: 1.18s\tremaining: 4m 52s\n",
      "4:\tlearn: 0.5131559\ttotal: 1.31s\tremaining: 4m 20s\n",
      "5:\tlearn: 0.4893856\ttotal: 1.48s\tremaining: 4m 5s\n",
      "6:\tlearn: 0.4684633\ttotal: 1.62s\tremaining: 3m 50s\n",
      "7:\tlearn: 0.4495447\ttotal: 1.85s\tremaining: 3m 49s\n",
      "8:\tlearn: 0.4352291\ttotal: 2.1s\tremaining: 3m 50s\n",
      "9:\tlearn: 0.4225243\ttotal: 2.3s\tremaining: 3m 47s\n",
      "10:\tlearn: 0.4126622\ttotal: 2.6s\tremaining: 3m 54s\n",
      "11:\tlearn: 0.4023751\ttotal: 2.87s\tremaining: 3m 55s\n",
      "12:\tlearn: 0.3935590\ttotal: 2.99s\tremaining: 3m 46s\n",
      "13:\tlearn: 0.3855693\ttotal: 3.12s\tremaining: 3m 39s\n",
      "14:\tlearn: 0.3792088\ttotal: 3.23s\tremaining: 3m 32s\n",
      "15:\tlearn: 0.3732908\ttotal: 3.46s\tremaining: 3m 33s\n",
      "16:\tlearn: 0.3681541\ttotal: 3.64s\tremaining: 3m 30s\n",
      "17:\tlearn: 0.3625345\ttotal: 3.83s\tremaining: 3m 28s\n",
      "18:\tlearn: 0.3580752\ttotal: 4.05s\tremaining: 3m 29s\n",
      "19:\tlearn: 0.3541798\ttotal: 4.21s\tremaining: 3m 26s\n",
      "20:\tlearn: 0.3509149\ttotal: 4.41s\tremaining: 3m 25s\n",
      "21:\tlearn: 0.3488286\ttotal: 4.58s\tremaining: 3m 23s\n",
      "22:\tlearn: 0.3453138\ttotal: 4.7s\tremaining: 3m 19s\n",
      "23:\tlearn: 0.3432476\ttotal: 4.93s\tremaining: 3m 20s\n",
      "24:\tlearn: 0.3409013\ttotal: 5.09s\tremaining: 3m 18s\n",
      "25:\tlearn: 0.3386057\ttotal: 5.45s\tremaining: 3m 24s\n",
      "26:\tlearn: 0.3369752\ttotal: 5.8s\tremaining: 3m 28s\n",
      "27:\tlearn: 0.3351898\ttotal: 6.3s\tremaining: 3m 38s\n",
      "28:\tlearn: 0.3330826\ttotal: 6.63s\tremaining: 3m 41s\n",
      "29:\tlearn: 0.3313416\ttotal: 7.03s\tremaining: 3m 47s\n",
      "30:\tlearn: 0.3295273\ttotal: 7.29s\tremaining: 3m 48s\n",
      "31:\tlearn: 0.3279276\ttotal: 7.61s\tremaining: 3m 50s\n",
      "32:\tlearn: 0.3262894\ttotal: 7.87s\tremaining: 3m 50s\n",
      "33:\tlearn: 0.3248889\ttotal: 8.13s\tremaining: 3m 51s\n",
      "34:\tlearn: 0.3237433\ttotal: 8.4s\tremaining: 3m 51s\n",
      "35:\tlearn: 0.3225043\ttotal: 8.72s\tremaining: 3m 53s\n",
      "36:\tlearn: 0.3215296\ttotal: 8.96s\tremaining: 3m 53s\n",
      "37:\tlearn: 0.3204568\ttotal: 9.2s\tremaining: 3m 52s\n",
      "38:\tlearn: 0.3193986\ttotal: 9.46s\tremaining: 3m 53s\n",
      "39:\tlearn: 0.3185160\ttotal: 9.7s\tremaining: 3m 52s\n",
      "40:\tlearn: 0.3176114\ttotal: 10.1s\tremaining: 3m 56s\n",
      "41:\tlearn: 0.3168176\ttotal: 10.4s\tremaining: 3m 57s\n",
      "42:\tlearn: 0.3160411\ttotal: 10.6s\tremaining: 3m 55s\n",
      "43:\tlearn: 0.3153738\ttotal: 10.8s\tremaining: 3m 53s\n",
      "44:\tlearn: 0.3148235\ttotal: 11s\tremaining: 3m 54s\n",
      "45:\tlearn: 0.3139021\ttotal: 11.3s\tremaining: 3m 53s\n",
      "46:\tlearn: 0.3135089\ttotal: 11.4s\tremaining: 3m 51s\n",
      "47:\tlearn: 0.3127031\ttotal: 11.8s\tremaining: 3m 53s\n",
      "48:\tlearn: 0.3119884\ttotal: 12.1s\tremaining: 3m 55s\n",
      "49:\tlearn: 0.3114949\ttotal: 12.3s\tremaining: 3m 53s\n",
      "50:\tlearn: 0.3107107\ttotal: 12.5s\tremaining: 3m 52s\n",
      "51:\tlearn: 0.3103130\ttotal: 12.8s\tremaining: 3m 52s\n",
      "52:\tlearn: 0.3098642\ttotal: 12.9s\tremaining: 3m 50s\n",
      "53:\tlearn: 0.3094605\ttotal: 13s\tremaining: 3m 48s\n",
      "54:\tlearn: 0.3090952\ttotal: 13.2s\tremaining: 3m 46s\n",
      "55:\tlearn: 0.3084834\ttotal: 13.4s\tremaining: 3m 45s\n",
      "56:\tlearn: 0.3078931\ttotal: 13.7s\tremaining: 3m 47s\n",
      "57:\tlearn: 0.3075458\ttotal: 14.2s\tremaining: 3m 49s\n",
      "58:\tlearn: 0.3070227\ttotal: 14.5s\tremaining: 3m 50s\n",
      "59:\tlearn: 0.3066252\ttotal: 14.7s\tremaining: 3m 50s\n",
      "60:\tlearn: 0.3059127\ttotal: 14.8s\tremaining: 3m 48s\n",
      "61:\tlearn: 0.3054422\ttotal: 15.2s\tremaining: 3m 49s\n",
      "62:\tlearn: 0.3046223\ttotal: 15.6s\tremaining: 3m 51s\n",
      "63:\tlearn: 0.3037952\ttotal: 15.7s\tremaining: 3m 49s\n",
      "64:\tlearn: 0.3034521\ttotal: 16.1s\tremaining: 3m 51s\n",
      "65:\tlearn: 0.3030470\ttotal: 16.3s\tremaining: 3m 51s\n",
      "66:\tlearn: 0.3025866\ttotal: 16.5s\tremaining: 3m 49s\n",
      "67:\tlearn: 0.3023402\ttotal: 16.7s\tremaining: 3m 48s\n",
      "68:\tlearn: 0.3020332\ttotal: 17s\tremaining: 3m 49s\n",
      "69:\tlearn: 0.3016756\ttotal: 17.2s\tremaining: 3m 49s\n",
      "70:\tlearn: 0.3013184\ttotal: 17.4s\tremaining: 3m 47s\n",
      "71:\tlearn: 0.3006602\ttotal: 17.6s\tremaining: 3m 47s\n",
      "72:\tlearn: 0.3003314\ttotal: 17.9s\tremaining: 3m 47s\n",
      "73:\tlearn: 0.2997657\ttotal: 18.2s\tremaining: 3m 48s\n",
      "74:\tlearn: 0.2993501\ttotal: 18.5s\tremaining: 3m 47s\n",
      "75:\tlearn: 0.2990578\ttotal: 18.8s\tremaining: 3m 48s\n",
      "76:\tlearn: 0.2987282\ttotal: 19.1s\tremaining: 3m 48s\n",
      "77:\tlearn: 0.2984095\ttotal: 19.5s\tremaining: 3m 51s\n",
      "78:\tlearn: 0.2981484\ttotal: 20s\tremaining: 3m 53s\n",
      "79:\tlearn: 0.2979435\ttotal: 20.4s\tremaining: 3m 55s\n",
      "80:\tlearn: 0.2976342\ttotal: 20.9s\tremaining: 3m 56s\n",
      "81:\tlearn: 0.2973271\ttotal: 21.2s\tremaining: 3m 57s\n",
      "82:\tlearn: 0.2971141\ttotal: 21.5s\tremaining: 3m 57s\n",
      "83:\tlearn: 0.2968366\ttotal: 21.8s\tremaining: 3m 57s\n",
      "84:\tlearn: 0.2964529\ttotal: 22s\tremaining: 3m 56s\n",
      "85:\tlearn: 0.2962943\ttotal: 22.3s\tremaining: 3m 57s\n",
      "86:\tlearn: 0.2960130\ttotal: 22.7s\tremaining: 3m 57s\n",
      "87:\tlearn: 0.2956063\ttotal: 23.1s\tremaining: 3m 59s\n",
      "88:\tlearn: 0.2954570\ttotal: 23.5s\tremaining: 4m\n",
      "89:\tlearn: 0.2952317\ttotal: 23.9s\tremaining: 4m 1s\n",
      "90:\tlearn: 0.2950427\ttotal: 24.3s\tremaining: 4m 3s\n",
      "91:\tlearn: 0.2948617\ttotal: 24.7s\tremaining: 4m 3s\n",
      "92:\tlearn: 0.2945172\ttotal: 25.1s\tremaining: 4m 5s\n",
      "93:\tlearn: 0.2942850\ttotal: 25.6s\tremaining: 4m 6s\n",
      "94:\tlearn: 0.2939731\ttotal: 26s\tremaining: 4m 7s\n",
      "95:\tlearn: 0.2937859\ttotal: 26.4s\tremaining: 4m 8s\n",
      "96:\tlearn: 0.2936515\ttotal: 26.8s\tremaining: 4m 9s\n",
      "97:\tlearn: 0.2934790\ttotal: 27.2s\tremaining: 4m 10s\n",
      "98:\tlearn: 0.2932675\ttotal: 27.6s\tremaining: 4m 11s\n",
      "99:\tlearn: 0.2930736\ttotal: 28.1s\tremaining: 4m 12s\n",
      "100:\tlearn: 0.2928709\ttotal: 28.6s\tremaining: 4m 14s\n",
      "101:\tlearn: 0.2926501\ttotal: 28.9s\tremaining: 4m 14s\n",
      "102:\tlearn: 0.2922690\ttotal: 29.2s\tremaining: 4m 14s\n",
      "103:\tlearn: 0.2920921\ttotal: 29.5s\tremaining: 4m 14s\n",
      "104:\tlearn: 0.2918594\ttotal: 29.9s\tremaining: 4m 15s\n",
      "105:\tlearn: 0.2916655\ttotal: 30.3s\tremaining: 4m 15s\n",
      "106:\tlearn: 0.2913540\ttotal: 30.7s\tremaining: 4m 16s\n",
      "107:\tlearn: 0.2911260\ttotal: 31s\tremaining: 4m 16s\n",
      "108:\tlearn: 0.2909497\ttotal: 31.2s\tremaining: 4m 15s\n",
      "109:\tlearn: 0.2905881\ttotal: 31.4s\tremaining: 4m 14s\n",
      "110:\tlearn: 0.2904250\ttotal: 31.6s\tremaining: 4m 13s\n",
      "111:\tlearn: 0.2901827\ttotal: 31.8s\tremaining: 4m 12s\n",
      "112:\tlearn: 0.2900288\ttotal: 32.1s\tremaining: 4m 11s\n",
      "113:\tlearn: 0.2899216\ttotal: 32.4s\tremaining: 4m 11s\n",
      "114:\tlearn: 0.2898185\ttotal: 32.8s\tremaining: 4m 12s\n",
      "115:\tlearn: 0.2896994\ttotal: 33s\tremaining: 4m 11s\n",
      "116:\tlearn: 0.2895299\ttotal: 33.2s\tremaining: 4m 10s\n",
      "117:\tlearn: 0.2892425\ttotal: 33.3s\tremaining: 4m 9s\n",
      "118:\tlearn: 0.2890754\ttotal: 33.5s\tremaining: 4m 7s\n",
      "119:\tlearn: 0.2889291\ttotal: 33.7s\tremaining: 4m 6s\n",
      "120:\tlearn: 0.2888069\ttotal: 33.9s\tremaining: 4m 6s\n",
      "121:\tlearn: 0.2886747\ttotal: 34s\tremaining: 4m 4s\n",
      "122:\tlearn: 0.2884897\ttotal: 34.3s\tremaining: 4m 4s\n",
      "123:\tlearn: 0.2881096\ttotal: 34.5s\tremaining: 4m 3s\n",
      "124:\tlearn: 0.2879696\ttotal: 34.7s\tremaining: 4m 2s\n",
      "125:\tlearn: 0.2878124\ttotal: 34.8s\tremaining: 4m 1s\n",
      "126:\tlearn: 0.2874997\ttotal: 35s\tremaining: 4m\n",
      "127:\tlearn: 0.2873975\ttotal: 35.2s\tremaining: 3m 59s\n",
      "128:\tlearn: 0.2870335\ttotal: 35.7s\tremaining: 4m\n",
      "129:\tlearn: 0.2869032\ttotal: 36.1s\tremaining: 4m 1s\n",
      "130:\tlearn: 0.2867786\ttotal: 36.5s\tremaining: 4m 2s\n",
      "131:\tlearn: 0.2866513\ttotal: 36.8s\tremaining: 4m 2s\n",
      "132:\tlearn: 0.2863547\ttotal: 37.1s\tremaining: 4m 2s\n",
      "133:\tlearn: 0.2862560\ttotal: 37.4s\tremaining: 4m 1s\n",
      "134:\tlearn: 0.2861134\ttotal: 37.6s\tremaining: 4m 1s\n",
      "135:\tlearn: 0.2859169\ttotal: 37.9s\tremaining: 4m\n",
      "136:\tlearn: 0.2858223\ttotal: 38s\tremaining: 3m 59s\n",
      "137:\tlearn: 0.2857038\ttotal: 38.3s\tremaining: 3m 59s\n",
      "138:\tlearn: 0.2856107\ttotal: 38.6s\tremaining: 3m 59s\n",
      "139:\tlearn: 0.2854780\ttotal: 38.9s\tremaining: 3m 59s\n",
      "140:\tlearn: 0.2853625\ttotal: 39.3s\tremaining: 3m 59s\n",
      "141:\tlearn: 0.2852413\ttotal: 39.6s\tremaining: 3m 59s\n",
      "142:\tlearn: 0.2851381\ttotal: 39.9s\tremaining: 3m 58s\n",
      "143:\tlearn: 0.2850264\ttotal: 40.1s\tremaining: 3m 58s\n",
      "144:\tlearn: 0.2849083\ttotal: 40.3s\tremaining: 3m 57s\n",
      "145:\tlearn: 0.2847936\ttotal: 40.6s\tremaining: 3m 57s\n",
      "146:\tlearn: 0.2846373\ttotal: 41s\tremaining: 3m 57s\n",
      "147:\tlearn: 0.2845510\ttotal: 41.2s\tremaining: 3m 57s\n",
      "148:\tlearn: 0.2844438\ttotal: 41.4s\tremaining: 3m 56s\n",
      "149:\tlearn: 0.2840235\ttotal: 41.4s\tremaining: 3m 54s\n",
      "150:\tlearn: 0.2836800\ttotal: 41.5s\tremaining: 3m 53s\n",
      "151:\tlearn: 0.2835736\ttotal: 41.6s\tremaining: 3m 52s\n",
      "152:\tlearn: 0.2834861\ttotal: 41.7s\tremaining: 3m 51s\n",
      "153:\tlearn: 0.2832605\ttotal: 41.8s\tremaining: 3m 49s\n",
      "154:\tlearn: 0.2831173\ttotal: 42s\tremaining: 3m 48s\n",
      "155:\tlearn: 0.2829322\ttotal: 42.1s\tremaining: 3m 47s\n",
      "156:\tlearn: 0.2827955\ttotal: 42.2s\tremaining: 3m 46s\n",
      "157:\tlearn: 0.2827375\ttotal: 42.3s\tremaining: 3m 45s\n",
      "158:\tlearn: 0.2826219\ttotal: 42.5s\tremaining: 3m 44s\n",
      "159:\tlearn: 0.2825196\ttotal: 42.6s\tremaining: 3m 43s\n",
      "160:\tlearn: 0.2824223\ttotal: 42.8s\tremaining: 3m 42s\n",
      "161:\tlearn: 0.2822815\ttotal: 42.9s\tremaining: 3m 41s\n",
      "162:\tlearn: 0.2821317\ttotal: 43.1s\tremaining: 3m 41s\n",
      "163:\tlearn: 0.2819886\ttotal: 43.3s\tremaining: 3m 40s\n",
      "164:\tlearn: 0.2818955\ttotal: 43.4s\tremaining: 3m 39s\n",
      "165:\tlearn: 0.2818181\ttotal: 43.5s\tremaining: 3m 38s\n",
      "166:\tlearn: 0.2816814\ttotal: 43.6s\tremaining: 3m 37s\n",
      "167:\tlearn: 0.2815810\ttotal: 43.7s\tremaining: 3m 36s\n",
      "168:\tlearn: 0.2814174\ttotal: 43.9s\tremaining: 3m 35s\n",
      "169:\tlearn: 0.2813156\ttotal: 44.1s\tremaining: 3m 35s\n",
      "170:\tlearn: 0.2812340\ttotal: 44.3s\tremaining: 3m 34s\n",
      "171:\tlearn: 0.2811509\ttotal: 44.4s\tremaining: 3m 33s\n",
      "172:\tlearn: 0.2810800\ttotal: 44.5s\tremaining: 3m 32s\n",
      "173:\tlearn: 0.2809434\ttotal: 44.6s\tremaining: 3m 31s\n",
      "174:\tlearn: 0.2807945\ttotal: 44.7s\tremaining: 3m 30s\n",
      "175:\tlearn: 0.2807268\ttotal: 44.9s\tremaining: 3m 30s\n",
      "176:\tlearn: 0.2805188\ttotal: 45.1s\tremaining: 3m 29s\n",
      "177:\tlearn: 0.2804225\ttotal: 45.2s\tremaining: 3m 28s\n",
      "178:\tlearn: 0.2803267\ttotal: 45.4s\tremaining: 3m 28s\n",
      "179:\tlearn: 0.2802486\ttotal: 45.5s\tremaining: 3m 27s\n",
      "180:\tlearn: 0.2801596\ttotal: 45.7s\tremaining: 3m 26s\n",
      "181:\tlearn: 0.2800363\ttotal: 45.8s\tremaining: 3m 25s\n",
      "182:\tlearn: 0.2799615\ttotal: 45.9s\tremaining: 3m 25s\n",
      "183:\tlearn: 0.2799240\ttotal: 46s\tremaining: 3m 24s\n",
      "184:\tlearn: 0.2797874\ttotal: 46.1s\tremaining: 3m 23s\n",
      "185:\tlearn: 0.2796941\ttotal: 46.4s\tremaining: 3m 22s\n",
      "186:\tlearn: 0.2796127\ttotal: 46.5s\tremaining: 3m 22s\n",
      "187:\tlearn: 0.2792496\ttotal: 46.7s\tremaining: 3m 21s\n",
      "188:\tlearn: 0.2791264\ttotal: 46.8s\tremaining: 3m 20s\n",
      "189:\tlearn: 0.2790496\ttotal: 47s\tremaining: 3m 20s\n",
      "190:\tlearn: 0.2789096\ttotal: 47.2s\tremaining: 3m 19s\n",
      "191:\tlearn: 0.2787155\ttotal: 47.3s\tremaining: 3m 19s\n",
      "192:\tlearn: 0.2785041\ttotal: 47.6s\tremaining: 3m 18s\n",
      "193:\tlearn: 0.2784170\ttotal: 47.7s\tremaining: 3m 18s\n",
      "194:\tlearn: 0.2783205\ttotal: 47.8s\tremaining: 3m 17s\n",
      "195:\tlearn: 0.2781929\ttotal: 47.9s\tremaining: 3m 16s\n",
      "196:\tlearn: 0.2780662\ttotal: 48.1s\tremaining: 3m 16s\n",
      "197:\tlearn: 0.2779868\ttotal: 48.2s\tremaining: 3m 15s\n",
      "198:\tlearn: 0.2779286\ttotal: 48.3s\tremaining: 3m 14s\n",
      "199:\tlearn: 0.2777543\ttotal: 48.4s\tremaining: 3m 13s\n",
      "200:\tlearn: 0.2776561\ttotal: 48.4s\tremaining: 3m 12s\n",
      "201:\tlearn: 0.2776049\ttotal: 48.5s\tremaining: 3m 11s\n",
      "202:\tlearn: 0.2774285\ttotal: 48.6s\tremaining: 3m 10s\n",
      "203:\tlearn: 0.2773569\ttotal: 48.8s\tremaining: 3m 10s\n",
      "204:\tlearn: 0.2772241\ttotal: 49s\tremaining: 3m 10s\n",
      "205:\tlearn: 0.2771501\ttotal: 49.2s\tremaining: 3m 9s\n",
      "206:\tlearn: 0.2770530\ttotal: 49.4s\tremaining: 3m 9s\n",
      "207:\tlearn: 0.2769280\ttotal: 49.6s\tremaining: 3m 8s\n",
      "208:\tlearn: 0.2768584\ttotal: 49.7s\tremaining: 3m 8s\n",
      "209:\tlearn: 0.2767890\ttotal: 49.9s\tremaining: 3m 7s\n",
      "210:\tlearn: 0.2767146\ttotal: 50s\tremaining: 3m 6s\n",
      "211:\tlearn: 0.2766112\ttotal: 50.1s\tremaining: 3m 6s\n",
      "212:\tlearn: 0.2765419\ttotal: 50.2s\tremaining: 3m 5s\n",
      "213:\tlearn: 0.2764441\ttotal: 50.3s\tremaining: 3m 4s\n",
      "214:\tlearn: 0.2762760\ttotal: 50.4s\tremaining: 3m 4s\n",
      "215:\tlearn: 0.2761628\ttotal: 50.6s\tremaining: 3m 3s\n",
      "216:\tlearn: 0.2760896\ttotal: 50.8s\tremaining: 3m 3s\n",
      "217:\tlearn: 0.2759675\ttotal: 51s\tremaining: 3m 2s\n",
      "218:\tlearn: 0.2758906\ttotal: 51.1s\tremaining: 3m 2s\n",
      "219:\tlearn: 0.2757506\ttotal: 51.2s\tremaining: 3m 1s\n",
      "220:\tlearn: 0.2756508\ttotal: 51.3s\tremaining: 3m\n",
      "221:\tlearn: 0.2755937\ttotal: 51.5s\tremaining: 3m\n",
      "222:\tlearn: 0.2755583\ttotal: 51.7s\tremaining: 3m\n",
      "223:\tlearn: 0.2754722\ttotal: 51.8s\tremaining: 2m 59s\n",
      "224:\tlearn: 0.2752605\ttotal: 51.9s\tremaining: 2m 58s\n",
      "225:\tlearn: 0.2751563\ttotal: 52s\tremaining: 2m 58s\n",
      "226:\tlearn: 0.2750807\ttotal: 52.2s\tremaining: 2m 57s\n",
      "227:\tlearn: 0.2749991\ttotal: 52.3s\tremaining: 2m 56s\n",
      "228:\tlearn: 0.2749074\ttotal: 52.4s\tremaining: 2m 56s\n",
      "229:\tlearn: 0.2748412\ttotal: 52.5s\tremaining: 2m 55s\n",
      "230:\tlearn: 0.2747286\ttotal: 52.6s\tremaining: 2m 55s\n",
      "231:\tlearn: 0.2746471\ttotal: 52.8s\tremaining: 2m 54s\n",
      "232:\tlearn: 0.2745361\ttotal: 52.9s\tremaining: 2m 54s\n",
      "233:\tlearn: 0.2744675\ttotal: 53s\tremaining: 2m 53s\n",
      "234:\tlearn: 0.2743771\ttotal: 53.1s\tremaining: 2m 52s\n",
      "235:\tlearn: 0.2737968\ttotal: 53.2s\tremaining: 2m 52s\n",
      "236:\tlearn: 0.2737043\ttotal: 53.3s\tremaining: 2m 51s\n",
      "237:\tlearn: 0.2735187\ttotal: 53.4s\tremaining: 2m 51s\n",
      "238:\tlearn: 0.2734102\ttotal: 53.5s\tremaining: 2m 50s\n",
      "239:\tlearn: 0.2733384\ttotal: 53.6s\tremaining: 2m 49s\n",
      "240:\tlearn: 0.2732879\ttotal: 53.7s\tremaining: 2m 49s\n",
      "241:\tlearn: 0.2732300\ttotal: 53.9s\tremaining: 2m 48s\n",
      "242:\tlearn: 0.2729875\ttotal: 54.1s\tremaining: 2m 48s\n",
      "243:\tlearn: 0.2729421\ttotal: 54.3s\tremaining: 2m 48s\n",
      "244:\tlearn: 0.2728617\ttotal: 54.4s\tremaining: 2m 47s\n",
      "245:\tlearn: 0.2727425\ttotal: 54.6s\tremaining: 2m 47s\n",
      "246:\tlearn: 0.2726636\ttotal: 54.7s\tremaining: 2m 46s\n",
      "247:\tlearn: 0.2726191\ttotal: 54.8s\tremaining: 2m 46s\n",
      "248:\tlearn: 0.2725433\ttotal: 54.8s\tremaining: 2m 45s\n",
      "249:\tlearn: 0.2724702\ttotal: 54.9s\tremaining: 2m 44s\n",
      "250:\tlearn: 0.2723690\ttotal: 55.1s\tremaining: 2m 44s\n",
      "251:\tlearn: 0.2722921\ttotal: 55.2s\tremaining: 2m 43s\n",
      "252:\tlearn: 0.2721685\ttotal: 55.3s\tremaining: 2m 43s\n",
      "253:\tlearn: 0.2720761\ttotal: 55.4s\tremaining: 2m 42s\n",
      "254:\tlearn: 0.2719600\ttotal: 55.5s\tremaining: 2m 42s\n",
      "255:\tlearn: 0.2718542\ttotal: 55.6s\tremaining: 2m 41s\n",
      "256:\tlearn: 0.2717108\ttotal: 55.7s\tremaining: 2m 41s\n",
      "257:\tlearn: 0.2714106\ttotal: 55.9s\tremaining: 2m 40s\n",
      "258:\tlearn: 0.2711376\ttotal: 55.9s\tremaining: 2m 40s\n",
      "259:\tlearn: 0.2710498\ttotal: 56s\tremaining: 2m 39s\n",
      "260:\tlearn: 0.2709665\ttotal: 56.1s\tremaining: 2m 38s\n",
      "261:\tlearn: 0.2708735\ttotal: 56.3s\tremaining: 2m 38s\n",
      "262:\tlearn: 0.2708042\ttotal: 56.4s\tremaining: 2m 38s\n",
      "263:\tlearn: 0.2707469\ttotal: 56.5s\tremaining: 2m 37s\n",
      "264:\tlearn: 0.2706596\ttotal: 56.7s\tremaining: 2m 37s\n",
      "265:\tlearn: 0.2705040\ttotal: 57s\tremaining: 2m 37s\n",
      "266:\tlearn: 0.2704388\ttotal: 57.3s\tremaining: 2m 37s\n",
      "267:\tlearn: 0.2703638\ttotal: 57.4s\tremaining: 2m 36s\n",
      "268:\tlearn: 0.2702617\ttotal: 57.6s\tremaining: 2m 36s\n",
      "269:\tlearn: 0.2701619\ttotal: 57.8s\tremaining: 2m 36s\n",
      "270:\tlearn: 0.2700620\ttotal: 57.9s\tremaining: 2m 35s\n",
      "271:\tlearn: 0.2699881\ttotal: 58.1s\tremaining: 2m 35s\n",
      "272:\tlearn: 0.2698469\ttotal: 58.2s\tremaining: 2m 34s\n",
      "273:\tlearn: 0.2697466\ttotal: 58.2s\tremaining: 2m 34s\n",
      "274:\tlearn: 0.2696699\ttotal: 58.4s\tremaining: 2m 33s\n",
      "275:\tlearn: 0.2695882\ttotal: 58.5s\tremaining: 2m 33s\n",
      "276:\tlearn: 0.2694983\ttotal: 58.5s\tremaining: 2m 32s\n",
      "277:\tlearn: 0.2694264\ttotal: 58.7s\tremaining: 2m 32s\n",
      "278:\tlearn: 0.2693327\ttotal: 58.7s\tremaining: 2m 31s\n",
      "279:\tlearn: 0.2691032\ttotal: 58.9s\tremaining: 2m 31s\n",
      "280:\tlearn: 0.2690116\ttotal: 59s\tremaining: 2m 31s\n",
      "281:\tlearn: 0.2689582\ttotal: 59.1s\tremaining: 2m 30s\n",
      "282:\tlearn: 0.2689041\ttotal: 59.2s\tremaining: 2m 29s\n",
      "283:\tlearn: 0.2688316\ttotal: 59.2s\tremaining: 2m 29s\n",
      "284:\tlearn: 0.2687627\ttotal: 59.4s\tremaining: 2m 28s\n",
      "285:\tlearn: 0.2686709\ttotal: 59.4s\tremaining: 2m 28s\n",
      "286:\tlearn: 0.2684977\ttotal: 59.5s\tremaining: 2m 27s\n",
      "287:\tlearn: 0.2684656\ttotal: 59.6s\tremaining: 2m 27s\n",
      "288:\tlearn: 0.2684034\ttotal: 59.7s\tremaining: 2m 26s\n",
      "289:\tlearn: 0.2683171\ttotal: 59.7s\tremaining: 2m 26s\n",
      "290:\tlearn: 0.2682180\ttotal: 59.9s\tremaining: 2m 25s\n",
      "291:\tlearn: 0.2681174\ttotal: 60s\tremaining: 2m 25s\n",
      "292:\tlearn: 0.2678220\ttotal: 1m\tremaining: 2m 24s\n",
      "293:\tlearn: 0.2677626\ttotal: 1m\tremaining: 2m 24s\n",
      "294:\tlearn: 0.2677003\ttotal: 1m\tremaining: 2m 23s\n",
      "295:\tlearn: 0.2676254\ttotal: 1m\tremaining: 2m 23s\n",
      "296:\tlearn: 0.2675467\ttotal: 1m\tremaining: 2m 22s\n",
      "297:\tlearn: 0.2674383\ttotal: 1m\tremaining: 2m 22s\n",
      "298:\tlearn: 0.2673502\ttotal: 1m\tremaining: 2m 21s\n",
      "299:\tlearn: 0.2672729\ttotal: 1m\tremaining: 2m 21s\n",
      "300:\tlearn: 0.2672333\ttotal: 1m\tremaining: 2m 21s\n",
      "301:\tlearn: 0.2671564\ttotal: 1m\tremaining: 2m 20s\n",
      "302:\tlearn: 0.2670753\ttotal: 1m\tremaining: 2m 20s\n",
      "303:\tlearn: 0.2670121\ttotal: 1m 1s\tremaining: 2m 19s\n",
      "304:\tlearn: 0.2669202\ttotal: 1m 1s\tremaining: 2m 19s\n",
      "305:\tlearn: 0.2668319\ttotal: 1m 1s\tremaining: 2m 19s\n",
      "306:\tlearn: 0.2665651\ttotal: 1m 1s\tremaining: 2m 18s\n",
      "307:\tlearn: 0.2664988\ttotal: 1m 1s\tremaining: 2m 18s\n",
      "308:\tlearn: 0.2664511\ttotal: 1m 1s\tremaining: 2m 18s\n",
      "309:\tlearn: 0.2663910\ttotal: 1m 1s\tremaining: 2m 17s\n",
      "310:\tlearn: 0.2663054\ttotal: 1m 2s\tremaining: 2m 17s\n",
      "311:\tlearn: 0.2662388\ttotal: 1m 2s\tremaining: 2m 16s\n",
      "312:\tlearn: 0.2661463\ttotal: 1m 2s\tremaining: 2m 16s\n",
      "313:\tlearn: 0.2660836\ttotal: 1m 2s\tremaining: 2m 15s\n",
      "314:\tlearn: 0.2660160\ttotal: 1m 2s\tremaining: 2m 15s\n",
      "315:\tlearn: 0.2659284\ttotal: 1m 2s\tremaining: 2m 15s\n",
      "316:\tlearn: 0.2657256\ttotal: 1m 2s\tremaining: 2m 14s\n",
      "317:\tlearn: 0.2655584\ttotal: 1m 2s\tremaining: 2m 14s\n",
      "318:\tlearn: 0.2654897\ttotal: 1m 2s\tremaining: 2m 13s\n",
      "319:\tlearn: 0.2654166\ttotal: 1m 2s\tremaining: 2m 13s\n",
      "320:\tlearn: 0.2653644\ttotal: 1m 2s\tremaining: 2m 13s\n",
      "321:\tlearn: 0.2652835\ttotal: 1m 2s\tremaining: 2m 12s\n",
      "322:\tlearn: 0.2652248\ttotal: 1m 3s\tremaining: 2m 12s\n",
      "323:\tlearn: 0.2649834\ttotal: 1m 3s\tremaining: 2m 11s\n",
      "324:\tlearn: 0.2649148\ttotal: 1m 3s\tremaining: 2m 11s\n",
      "325:\tlearn: 0.2648625\ttotal: 1m 3s\tremaining: 2m 11s\n",
      "326:\tlearn: 0.2647781\ttotal: 1m 3s\tremaining: 2m 10s\n",
      "327:\tlearn: 0.2647243\ttotal: 1m 3s\tremaining: 2m 10s\n",
      "328:\tlearn: 0.2646566\ttotal: 1m 3s\tremaining: 2m 10s\n",
      "329:\tlearn: 0.2646033\ttotal: 1m 3s\tremaining: 2m 9s\n",
      "330:\tlearn: 0.2645423\ttotal: 1m 4s\tremaining: 2m 9s\n",
      "331:\tlearn: 0.2644646\ttotal: 1m 4s\tremaining: 2m 9s\n",
      "332:\tlearn: 0.2644018\ttotal: 1m 4s\tremaining: 2m 8s\n",
      "333:\tlearn: 0.2643305\ttotal: 1m 4s\tremaining: 2m 8s\n",
      "334:\tlearn: 0.2641581\ttotal: 1m 4s\tremaining: 2m 8s\n",
      "335:\tlearn: 0.2640807\ttotal: 1m 4s\tremaining: 2m 7s\n",
      "336:\tlearn: 0.2640317\ttotal: 1m 4s\tremaining: 2m 7s\n",
      "337:\tlearn: 0.2639605\ttotal: 1m 4s\tremaining: 2m 6s\n",
      "338:\tlearn: 0.2638231\ttotal: 1m 4s\tremaining: 2m 6s\n",
      "339:\tlearn: 0.2636929\ttotal: 1m 5s\tremaining: 2m 6s\n",
      "340:\tlearn: 0.2636195\ttotal: 1m 5s\tremaining: 2m 5s\n",
      "341:\tlearn: 0.2635649\ttotal: 1m 5s\tremaining: 2m 5s\n",
      "342:\tlearn: 0.2635170\ttotal: 1m 5s\tremaining: 2m 5s\n",
      "343:\tlearn: 0.2634592\ttotal: 1m 5s\tremaining: 2m 4s\n",
      "344:\tlearn: 0.2633879\ttotal: 1m 5s\tremaining: 2m 4s\n",
      "345:\tlearn: 0.2633408\ttotal: 1m 5s\tremaining: 2m 4s\n",
      "346:\tlearn: 0.2632759\ttotal: 1m 5s\tremaining: 2m 3s\n",
      "347:\tlearn: 0.2632222\ttotal: 1m 5s\tremaining: 2m 3s\n",
      "348:\tlearn: 0.2631514\ttotal: 1m 5s\tremaining: 2m 2s\n",
      "349:\tlearn: 0.2630743\ttotal: 1m 5s\tremaining: 2m 2s\n",
      "350:\tlearn: 0.2630432\ttotal: 1m 6s\tremaining: 2m 2s\n",
      "351:\tlearn: 0.2629806\ttotal: 1m 6s\tremaining: 2m 1s\n",
      "352:\tlearn: 0.2628937\ttotal: 1m 6s\tremaining: 2m 1s\n",
      "353:\tlearn: 0.2628253\ttotal: 1m 6s\tremaining: 2m\n",
      "354:\tlearn: 0.2627697\ttotal: 1m 6s\tremaining: 2m\n",
      "355:\tlearn: 0.2626361\ttotal: 1m 6s\tremaining: 2m\n",
      "356:\tlearn: 0.2625678\ttotal: 1m 6s\tremaining: 1m 59s\n",
      "357:\tlearn: 0.2624923\ttotal: 1m 6s\tremaining: 1m 59s\n",
      "358:\tlearn: 0.2624151\ttotal: 1m 6s\tremaining: 1m 59s\n",
      "359:\tlearn: 0.2623443\ttotal: 1m 6s\tremaining: 1m 58s\n",
      "360:\tlearn: 0.2622657\ttotal: 1m 6s\tremaining: 1m 58s\n",
      "361:\tlearn: 0.2622040\ttotal: 1m 7s\tremaining: 1m 58s\n",
      "362:\tlearn: 0.2620862\ttotal: 1m 7s\tremaining: 1m 57s\n",
      "363:\tlearn: 0.2619677\ttotal: 1m 7s\tremaining: 1m 57s\n",
      "364:\tlearn: 0.2619237\ttotal: 1m 7s\tremaining: 1m 57s\n",
      "365:\tlearn: 0.2617911\ttotal: 1m 7s\tremaining: 1m 56s\n",
      "366:\tlearn: 0.2617269\ttotal: 1m 7s\tremaining: 1m 56s\n",
      "367:\tlearn: 0.2616865\ttotal: 1m 7s\tremaining: 1m 56s\n",
      "368:\tlearn: 0.2616327\ttotal: 1m 7s\tremaining: 1m 55s\n",
      "369:\tlearn: 0.2615585\ttotal: 1m 7s\tremaining: 1m 55s\n",
      "370:\tlearn: 0.2615016\ttotal: 1m 8s\tremaining: 1m 55s\n",
      "371:\tlearn: 0.2614177\ttotal: 1m 8s\tremaining: 1m 55s\n",
      "372:\tlearn: 0.2613628\ttotal: 1m 8s\tremaining: 1m 55s\n",
      "373:\tlearn: 0.2613010\ttotal: 1m 8s\tremaining: 1m 54s\n",
      "374:\tlearn: 0.2612418\ttotal: 1m 8s\tremaining: 1m 54s\n",
      "375:\tlearn: 0.2610836\ttotal: 1m 9s\tremaining: 1m 54s\n",
      "376:\tlearn: 0.2610486\ttotal: 1m 9s\tremaining: 1m 54s\n",
      "377:\tlearn: 0.2609804\ttotal: 1m 9s\tremaining: 1m 54s\n",
      "378:\tlearn: 0.2609285\ttotal: 1m 9s\tremaining: 1m 54s\n",
      "379:\tlearn: 0.2608609\ttotal: 1m 10s\tremaining: 1m 54s\n",
      "380:\tlearn: 0.2608031\ttotal: 1m 10s\tremaining: 1m 54s\n",
      "381:\tlearn: 0.2607337\ttotal: 1m 10s\tremaining: 1m 54s\n",
      "382:\tlearn: 0.2606701\ttotal: 1m 11s\tremaining: 1m 54s\n",
      "383:\tlearn: 0.2606257\ttotal: 1m 11s\tremaining: 1m 54s\n",
      "384:\tlearn: 0.2605458\ttotal: 1m 11s\tremaining: 1m 53s\n",
      "385:\tlearn: 0.2604868\ttotal: 1m 11s\tremaining: 1m 53s\n",
      "386:\tlearn: 0.2604413\ttotal: 1m 11s\tremaining: 1m 53s\n",
      "387:\tlearn: 0.2604032\ttotal: 1m 11s\tremaining: 1m 53s\n",
      "388:\tlearn: 0.2603805\ttotal: 1m 11s\tremaining: 1m 52s\n",
      "389:\tlearn: 0.2603203\ttotal: 1m 12s\tremaining: 1m 52s\n",
      "390:\tlearn: 0.2602699\ttotal: 1m 12s\tremaining: 1m 52s\n",
      "391:\tlearn: 0.2602095\ttotal: 1m 12s\tremaining: 1m 52s\n",
      "392:\tlearn: 0.2601361\ttotal: 1m 12s\tremaining: 1m 52s\n",
      "393:\tlearn: 0.2600845\ttotal: 1m 12s\tremaining: 1m 52s\n",
      "394:\tlearn: 0.2599951\ttotal: 1m 12s\tremaining: 1m 51s\n",
      "395:\tlearn: 0.2599219\ttotal: 1m 13s\tremaining: 1m 51s\n",
      "396:\tlearn: 0.2597066\ttotal: 1m 13s\tremaining: 1m 51s\n",
      "397:\tlearn: 0.2595991\ttotal: 1m 13s\tremaining: 1m 51s\n",
      "398:\tlearn: 0.2595367\ttotal: 1m 14s\tremaining: 1m 51s\n",
      "399:\tlearn: 0.2594908\ttotal: 1m 14s\tremaining: 1m 51s\n",
      "400:\tlearn: 0.2593925\ttotal: 1m 14s\tremaining: 1m 51s\n",
      "401:\tlearn: 0.2593588\ttotal: 1m 14s\tremaining: 1m 50s\n",
      "402:\tlearn: 0.2593007\ttotal: 1m 14s\tremaining: 1m 50s\n",
      "403:\tlearn: 0.2592349\ttotal: 1m 14s\tremaining: 1m 50s\n",
      "404:\tlearn: 0.2591954\ttotal: 1m 15s\tremaining: 1m 50s\n",
      "405:\tlearn: 0.2591610\ttotal: 1m 15s\tremaining: 1m 49s\n",
      "406:\tlearn: 0.2590802\ttotal: 1m 15s\tremaining: 1m 49s\n",
      "407:\tlearn: 0.2590142\ttotal: 1m 15s\tremaining: 1m 49s\n",
      "408:\tlearn: 0.2589676\ttotal: 1m 15s\tremaining: 1m 49s\n",
      "409:\tlearn: 0.2588735\ttotal: 1m 15s\tremaining: 1m 48s\n",
      "410:\tlearn: 0.2588109\ttotal: 1m 15s\tremaining: 1m 48s\n",
      "411:\tlearn: 0.2587437\ttotal: 1m 15s\tremaining: 1m 48s\n",
      "412:\tlearn: 0.2587092\ttotal: 1m 16s\tremaining: 1m 48s\n",
      "413:\tlearn: 0.2586566\ttotal: 1m 16s\tremaining: 1m 47s\n",
      "414:\tlearn: 0.2586045\ttotal: 1m 16s\tremaining: 1m 47s\n",
      "415:\tlearn: 0.2585089\ttotal: 1m 16s\tremaining: 1m 47s\n",
      "416:\tlearn: 0.2584403\ttotal: 1m 16s\tremaining: 1m 47s\n",
      "417:\tlearn: 0.2583754\ttotal: 1m 16s\tremaining: 1m 47s\n",
      "418:\tlearn: 0.2583072\ttotal: 1m 17s\tremaining: 1m 46s\n",
      "419:\tlearn: 0.2582644\ttotal: 1m 17s\tremaining: 1m 46s\n",
      "420:\tlearn: 0.2582257\ttotal: 1m 17s\tremaining: 1m 46s\n",
      "421:\tlearn: 0.2581696\ttotal: 1m 17s\tremaining: 1m 46s\n",
      "422:\tlearn: 0.2581369\ttotal: 1m 17s\tremaining: 1m 46s\n",
      "423:\tlearn: 0.2580845\ttotal: 1m 18s\tremaining: 1m 46s\n",
      "424:\tlearn: 0.2580236\ttotal: 1m 18s\tremaining: 1m 46s\n",
      "425:\tlearn: 0.2579731\ttotal: 1m 18s\tremaining: 1m 46s\n",
      "426:\tlearn: 0.2579074\ttotal: 1m 19s\tremaining: 1m 46s\n",
      "427:\tlearn: 0.2577078\ttotal: 1m 19s\tremaining: 1m 46s\n",
      "428:\tlearn: 0.2576375\ttotal: 1m 19s\tremaining: 1m 45s\n",
      "429:\tlearn: 0.2575882\ttotal: 1m 19s\tremaining: 1m 45s\n",
      "430:\tlearn: 0.2575413\ttotal: 1m 20s\tremaining: 1m 45s\n",
      "431:\tlearn: 0.2575009\ttotal: 1m 20s\tremaining: 1m 45s\n",
      "432:\tlearn: 0.2574438\ttotal: 1m 20s\tremaining: 1m 45s\n",
      "433:\tlearn: 0.2573977\ttotal: 1m 20s\tremaining: 1m 45s\n",
      "434:\tlearn: 0.2573417\ttotal: 1m 21s\tremaining: 1m 45s\n",
      "435:\tlearn: 0.2573036\ttotal: 1m 21s\tremaining: 1m 44s\n",
      "436:\tlearn: 0.2572621\ttotal: 1m 21s\tremaining: 1m 44s\n",
      "437:\tlearn: 0.2572144\ttotal: 1m 21s\tremaining: 1m 44s\n",
      "438:\tlearn: 0.2571451\ttotal: 1m 21s\tremaining: 1m 44s\n",
      "439:\tlearn: 0.2571057\ttotal: 1m 21s\tremaining: 1m 43s\n",
      "440:\tlearn: 0.2570432\ttotal: 1m 21s\tremaining: 1m 43s\n",
      "441:\tlearn: 0.2569663\ttotal: 1m 21s\tremaining: 1m 43s\n",
      "442:\tlearn: 0.2568086\ttotal: 1m 22s\tremaining: 1m 43s\n",
      "443:\tlearn: 0.2567435\ttotal: 1m 22s\tremaining: 1m 42s\n",
      "444:\tlearn: 0.2566874\ttotal: 1m 22s\tremaining: 1m 42s\n",
      "445:\tlearn: 0.2566590\ttotal: 1m 22s\tremaining: 1m 42s\n",
      "446:\tlearn: 0.2565626\ttotal: 1m 22s\tremaining: 1m 42s\n",
      "447:\tlearn: 0.2565101\ttotal: 1m 22s\tremaining: 1m 41s\n",
      "448:\tlearn: 0.2564387\ttotal: 1m 22s\tremaining: 1m 41s\n",
      "449:\tlearn: 0.2563892\ttotal: 1m 23s\tremaining: 1m 41s\n",
      "450:\tlearn: 0.2563035\ttotal: 1m 23s\tremaining: 1m 41s\n",
      "451:\tlearn: 0.2562481\ttotal: 1m 23s\tremaining: 1m 41s\n",
      "452:\tlearn: 0.2561839\ttotal: 1m 23s\tremaining: 1m 41s\n",
      "453:\tlearn: 0.2561319\ttotal: 1m 23s\tremaining: 1m 40s\n",
      "454:\tlearn: 0.2560734\ttotal: 1m 24s\tremaining: 1m 40s\n",
      "455:\tlearn: 0.2560083\ttotal: 1m 24s\tremaining: 1m 40s\n",
      "456:\tlearn: 0.2559504\ttotal: 1m 24s\tremaining: 1m 40s\n",
      "457:\tlearn: 0.2558993\ttotal: 1m 24s\tremaining: 1m 40s\n",
      "458:\tlearn: 0.2558669\ttotal: 1m 24s\tremaining: 1m 39s\n",
      "459:\tlearn: 0.2558259\ttotal: 1m 24s\tremaining: 1m 39s\n",
      "460:\tlearn: 0.2557490\ttotal: 1m 24s\tremaining: 1m 39s\n",
      "461:\tlearn: 0.2556931\ttotal: 1m 24s\tremaining: 1m 38s\n",
      "462:\tlearn: 0.2556464\ttotal: 1m 25s\tremaining: 1m 38s\n",
      "463:\tlearn: 0.2556081\ttotal: 1m 25s\tremaining: 1m 38s\n",
      "464:\tlearn: 0.2555731\ttotal: 1m 25s\tremaining: 1m 38s\n",
      "465:\tlearn: 0.2555402\ttotal: 1m 25s\tremaining: 1m 38s\n",
      "466:\tlearn: 0.2554582\ttotal: 1m 25s\tremaining: 1m 38s\n",
      "467:\tlearn: 0.2554047\ttotal: 1m 26s\tremaining: 1m 37s\n",
      "468:\tlearn: 0.2553505\ttotal: 1m 26s\tremaining: 1m 37s\n",
      "469:\tlearn: 0.2553127\ttotal: 1m 26s\tremaining: 1m 37s\n",
      "470:\tlearn: 0.2552516\ttotal: 1m 26s\tremaining: 1m 37s\n",
      "471:\tlearn: 0.2551880\ttotal: 1m 27s\tremaining: 1m 37s\n",
      "472:\tlearn: 0.2551427\ttotal: 1m 27s\tremaining: 1m 37s\n",
      "473:\tlearn: 0.2551015\ttotal: 1m 27s\tremaining: 1m 37s\n",
      "474:\tlearn: 0.2550625\ttotal: 1m 27s\tremaining: 1m 37s\n",
      "475:\tlearn: 0.2550020\ttotal: 1m 28s\tremaining: 1m 37s\n",
      "476:\tlearn: 0.2549580\ttotal: 1m 28s\tremaining: 1m 36s\n",
      "477:\tlearn: 0.2549028\ttotal: 1m 28s\tremaining: 1m 36s\n",
      "478:\tlearn: 0.2548003\ttotal: 1m 28s\tremaining: 1m 36s\n",
      "479:\tlearn: 0.2547510\ttotal: 1m 29s\tremaining: 1m 36s\n",
      "480:\tlearn: 0.2546810\ttotal: 1m 29s\tremaining: 1m 36s\n",
      "481:\tlearn: 0.2546037\ttotal: 1m 29s\tremaining: 1m 36s\n",
      "482:\tlearn: 0.2545490\ttotal: 1m 29s\tremaining: 1m 35s\n",
      "483:\tlearn: 0.2545167\ttotal: 1m 29s\tremaining: 1m 35s\n",
      "484:\tlearn: 0.2544926\ttotal: 1m 29s\tremaining: 1m 35s\n",
      "485:\tlearn: 0.2544591\ttotal: 1m 29s\tremaining: 1m 35s\n",
      "486:\tlearn: 0.2543910\ttotal: 1m 30s\tremaining: 1m 34s\n",
      "487:\tlearn: 0.2543491\ttotal: 1m 30s\tremaining: 1m 34s\n",
      "488:\tlearn: 0.2542898\ttotal: 1m 30s\tremaining: 1m 34s\n",
      "489:\tlearn: 0.2542168\ttotal: 1m 30s\tremaining: 1m 34s\n",
      "490:\tlearn: 0.2541768\ttotal: 1m 30s\tremaining: 1m 34s\n",
      "491:\tlearn: 0.2541164\ttotal: 1m 31s\tremaining: 1m 34s\n",
      "492:\tlearn: 0.2540652\ttotal: 1m 31s\tremaining: 1m 33s\n",
      "493:\tlearn: 0.2540249\ttotal: 1m 31s\tremaining: 1m 33s\n",
      "494:\tlearn: 0.2539687\ttotal: 1m 31s\tremaining: 1m 33s\n",
      "495:\tlearn: 0.2539337\ttotal: 1m 31s\tremaining: 1m 33s\n",
      "496:\tlearn: 0.2538860\ttotal: 1m 31s\tremaining: 1m 33s\n",
      "497:\tlearn: 0.2538515\ttotal: 1m 32s\tremaining: 1m 32s\n",
      "498:\tlearn: 0.2538064\ttotal: 1m 32s\tremaining: 1m 32s\n",
      "499:\tlearn: 0.2537689\ttotal: 1m 32s\tremaining: 1m 32s\n",
      "500:\tlearn: 0.2537272\ttotal: 1m 32s\tremaining: 1m 32s\n",
      "501:\tlearn: 0.2536937\ttotal: 1m 33s\tremaining: 1m 32s\n",
      "502:\tlearn: 0.2536611\ttotal: 1m 33s\tremaining: 1m 32s\n",
      "503:\tlearn: 0.2536293\ttotal: 1m 33s\tremaining: 1m 32s\n",
      "504:\tlearn: 0.2535747\ttotal: 1m 33s\tremaining: 1m 31s\n",
      "505:\tlearn: 0.2535013\ttotal: 1m 34s\tremaining: 1m 31s\n",
      "506:\tlearn: 0.2534734\ttotal: 1m 34s\tremaining: 1m 31s\n",
      "507:\tlearn: 0.2534357\ttotal: 1m 34s\tremaining: 1m 31s\n",
      "508:\tlearn: 0.2534121\ttotal: 1m 34s\tremaining: 1m 31s\n",
      "509:\tlearn: 0.2533531\ttotal: 1m 34s\tremaining: 1m 31s\n",
      "510:\tlearn: 0.2533213\ttotal: 1m 35s\tremaining: 1m 31s\n",
      "511:\tlearn: 0.2532551\ttotal: 1m 35s\tremaining: 1m 31s\n",
      "512:\tlearn: 0.2532253\ttotal: 1m 35s\tremaining: 1m 31s\n",
      "513:\tlearn: 0.2531719\ttotal: 1m 36s\tremaining: 1m 30s\n",
      "514:\tlearn: 0.2531226\ttotal: 1m 36s\tremaining: 1m 30s\n",
      "515:\tlearn: 0.2530652\ttotal: 1m 36s\tremaining: 1m 30s\n",
      "516:\tlearn: 0.2530194\ttotal: 1m 36s\tremaining: 1m 30s\n",
      "517:\tlearn: 0.2529644\ttotal: 1m 36s\tremaining: 1m 30s\n",
      "518:\tlearn: 0.2529078\ttotal: 1m 37s\tremaining: 1m 30s\n",
      "519:\tlearn: 0.2528497\ttotal: 1m 37s\tremaining: 1m 29s\n",
      "520:\tlearn: 0.2527795\ttotal: 1m 37s\tremaining: 1m 29s\n",
      "521:\tlearn: 0.2527068\ttotal: 1m 37s\tremaining: 1m 29s\n",
      "522:\tlearn: 0.2526651\ttotal: 1m 38s\tremaining: 1m 29s\n",
      "523:\tlearn: 0.2526130\ttotal: 1m 38s\tremaining: 1m 29s\n",
      "524:\tlearn: 0.2525404\ttotal: 1m 38s\tremaining: 1m 29s\n",
      "525:\tlearn: 0.2524787\ttotal: 1m 38s\tremaining: 1m 28s\n",
      "526:\tlearn: 0.2524589\ttotal: 1m 38s\tremaining: 1m 28s\n",
      "527:\tlearn: 0.2524240\ttotal: 1m 39s\tremaining: 1m 28s\n",
      "528:\tlearn: 0.2523856\ttotal: 1m 39s\tremaining: 1m 28s\n",
      "529:\tlearn: 0.2523445\ttotal: 1m 39s\tremaining: 1m 28s\n",
      "530:\tlearn: 0.2523091\ttotal: 1m 39s\tremaining: 1m 27s\n",
      "531:\tlearn: 0.2522433\ttotal: 1m 39s\tremaining: 1m 27s\n",
      "532:\tlearn: 0.2521943\ttotal: 1m 39s\tremaining: 1m 27s\n",
      "533:\tlearn: 0.2521243\ttotal: 1m 40s\tremaining: 1m 27s\n",
      "534:\tlearn: 0.2520884\ttotal: 1m 40s\tremaining: 1m 27s\n",
      "535:\tlearn: 0.2520387\ttotal: 1m 40s\tremaining: 1m 26s\n",
      "536:\tlearn: 0.2519880\ttotal: 1m 40s\tremaining: 1m 26s\n",
      "537:\tlearn: 0.2519538\ttotal: 1m 40s\tremaining: 1m 26s\n",
      "538:\tlearn: 0.2518916\ttotal: 1m 41s\tremaining: 1m 26s\n",
      "539:\tlearn: 0.2518189\ttotal: 1m 41s\tremaining: 1m 26s\n",
      "540:\tlearn: 0.2517853\ttotal: 1m 41s\tremaining: 1m 26s\n",
      "541:\tlearn: 0.2517415\ttotal: 1m 41s\tremaining: 1m 26s\n",
      "542:\tlearn: 0.2517112\ttotal: 1m 42s\tremaining: 1m 25s\n",
      "543:\tlearn: 0.2516501\ttotal: 1m 42s\tremaining: 1m 25s\n",
      "544:\tlearn: 0.2515861\ttotal: 1m 42s\tremaining: 1m 25s\n",
      "545:\tlearn: 0.2515454\ttotal: 1m 42s\tremaining: 1m 25s\n",
      "546:\tlearn: 0.2515011\ttotal: 1m 42s\tremaining: 1m 25s\n",
      "547:\tlearn: 0.2514427\ttotal: 1m 42s\tremaining: 1m 24s\n",
      "548:\tlearn: 0.2514165\ttotal: 1m 43s\tremaining: 1m 24s\n",
      "549:\tlearn: 0.2513697\ttotal: 1m 43s\tremaining: 1m 24s\n",
      "550:\tlearn: 0.2513342\ttotal: 1m 43s\tremaining: 1m 24s\n",
      "551:\tlearn: 0.2513080\ttotal: 1m 43s\tremaining: 1m 23s\n",
      "552:\tlearn: 0.2512736\ttotal: 1m 43s\tremaining: 1m 23s\n",
      "553:\tlearn: 0.2512294\ttotal: 1m 43s\tremaining: 1m 23s\n",
      "554:\tlearn: 0.2511891\ttotal: 1m 43s\tremaining: 1m 23s\n",
      "555:\tlearn: 0.2510947\ttotal: 1m 43s\tremaining: 1m 22s\n",
      "556:\tlearn: 0.2510513\ttotal: 1m 43s\tremaining: 1m 22s\n",
      "557:\tlearn: 0.2510081\ttotal: 1m 43s\tremaining: 1m 22s\n",
      "558:\tlearn: 0.2509719\ttotal: 1m 44s\tremaining: 1m 22s\n",
      "559:\tlearn: 0.2508972\ttotal: 1m 44s\tremaining: 1m 21s\n",
      "560:\tlearn: 0.2508512\ttotal: 1m 44s\tremaining: 1m 21s\n",
      "561:\tlearn: 0.2507859\ttotal: 1m 44s\tremaining: 1m 21s\n",
      "562:\tlearn: 0.2507403\ttotal: 1m 44s\tremaining: 1m 21s\n",
      "563:\tlearn: 0.2507162\ttotal: 1m 44s\tremaining: 1m 21s\n",
      "564:\tlearn: 0.2506861\ttotal: 1m 44s\tremaining: 1m 20s\n",
      "565:\tlearn: 0.2506330\ttotal: 1m 45s\tremaining: 1m 20s\n",
      "566:\tlearn: 0.2505957\ttotal: 1m 45s\tremaining: 1m 20s\n",
      "567:\tlearn: 0.2504847\ttotal: 1m 45s\tremaining: 1m 20s\n",
      "568:\tlearn: 0.2504578\ttotal: 1m 45s\tremaining: 1m 19s\n",
      "569:\tlearn: 0.2504187\ttotal: 1m 45s\tremaining: 1m 19s\n",
      "570:\tlearn: 0.2503825\ttotal: 1m 45s\tremaining: 1m 19s\n",
      "571:\tlearn: 0.2503431\ttotal: 1m 45s\tremaining: 1m 19s\n",
      "572:\tlearn: 0.2503089\ttotal: 1m 45s\tremaining: 1m 18s\n",
      "573:\tlearn: 0.2502544\ttotal: 1m 46s\tremaining: 1m 18s\n",
      "574:\tlearn: 0.2502207\ttotal: 1m 46s\tremaining: 1m 18s\n",
      "575:\tlearn: 0.2501655\ttotal: 1m 46s\tremaining: 1m 18s\n",
      "576:\tlearn: 0.2501142\ttotal: 1m 46s\tremaining: 1m 18s\n",
      "577:\tlearn: 0.2500180\ttotal: 1m 46s\tremaining: 1m 17s\n",
      "578:\tlearn: 0.2499866\ttotal: 1m 46s\tremaining: 1m 17s\n",
      "579:\tlearn: 0.2499500\ttotal: 1m 46s\tremaining: 1m 17s\n",
      "580:\tlearn: 0.2498925\ttotal: 1m 47s\tremaining: 1m 17s\n",
      "581:\tlearn: 0.2498188\ttotal: 1m 47s\tremaining: 1m 16s\n",
      "582:\tlearn: 0.2497726\ttotal: 1m 47s\tremaining: 1m 16s\n",
      "583:\tlearn: 0.2497390\ttotal: 1m 47s\tremaining: 1m 16s\n",
      "584:\tlearn: 0.2496950\ttotal: 1m 47s\tremaining: 1m 16s\n",
      "585:\tlearn: 0.2496478\ttotal: 1m 47s\tremaining: 1m 16s\n",
      "586:\tlearn: 0.2495923\ttotal: 1m 47s\tremaining: 1m 15s\n",
      "587:\tlearn: 0.2495507\ttotal: 1m 47s\tremaining: 1m 15s\n",
      "588:\tlearn: 0.2495227\ttotal: 1m 47s\tremaining: 1m 15s\n",
      "589:\tlearn: 0.2494805\ttotal: 1m 47s\tremaining: 1m 15s\n",
      "590:\tlearn: 0.2494247\ttotal: 1m 48s\tremaining: 1m 14s\n",
      "591:\tlearn: 0.2493965\ttotal: 1m 48s\tremaining: 1m 14s\n",
      "592:\tlearn: 0.2493578\ttotal: 1m 48s\tremaining: 1m 14s\n",
      "593:\tlearn: 0.2493074\ttotal: 1m 48s\tremaining: 1m 14s\n",
      "594:\tlearn: 0.2492729\ttotal: 1m 48s\tremaining: 1m 13s\n",
      "595:\tlearn: 0.2492424\ttotal: 1m 48s\tremaining: 1m 13s\n",
      "596:\tlearn: 0.2491964\ttotal: 1m 48s\tremaining: 1m 13s\n",
      "597:\tlearn: 0.2491649\ttotal: 1m 48s\tremaining: 1m 13s\n",
      "598:\tlearn: 0.2491333\ttotal: 1m 48s\tremaining: 1m 12s\n",
      "599:\tlearn: 0.2491001\ttotal: 1m 49s\tremaining: 1m 12s\n",
      "600:\tlearn: 0.2490725\ttotal: 1m 49s\tremaining: 1m 12s\n",
      "601:\tlearn: 0.2490318\ttotal: 1m 49s\tremaining: 1m 12s\n",
      "602:\tlearn: 0.2489725\ttotal: 1m 49s\tremaining: 1m 11s\n",
      "603:\tlearn: 0.2489528\ttotal: 1m 49s\tremaining: 1m 11s\n",
      "604:\tlearn: 0.2488977\ttotal: 1m 49s\tremaining: 1m 11s\n",
      "605:\tlearn: 0.2488685\ttotal: 1m 49s\tremaining: 1m 11s\n",
      "606:\tlearn: 0.2488068\ttotal: 1m 49s\tremaining: 1m 10s\n",
      "607:\tlearn: 0.2487706\ttotal: 1m 49s\tremaining: 1m 10s\n",
      "608:\tlearn: 0.2487442\ttotal: 1m 49s\tremaining: 1m 10s\n",
      "609:\tlearn: 0.2487178\ttotal: 1m 49s\tremaining: 1m 10s\n",
      "610:\tlearn: 0.2486987\ttotal: 1m 50s\tremaining: 1m 10s\n",
      "611:\tlearn: 0.2486400\ttotal: 1m 50s\tremaining: 1m 9s\n",
      "612:\tlearn: 0.2485969\ttotal: 1m 50s\tremaining: 1m 9s\n",
      "613:\tlearn: 0.2485558\ttotal: 1m 50s\tremaining: 1m 9s\n",
      "614:\tlearn: 0.2485130\ttotal: 1m 50s\tremaining: 1m 9s\n",
      "615:\tlearn: 0.2484715\ttotal: 1m 50s\tremaining: 1m 8s\n",
      "616:\tlearn: 0.2484049\ttotal: 1m 50s\tremaining: 1m 8s\n",
      "617:\tlearn: 0.2483698\ttotal: 1m 50s\tremaining: 1m 8s\n",
      "618:\tlearn: 0.2483069\ttotal: 1m 51s\tremaining: 1m 8s\n",
      "619:\tlearn: 0.2482420\ttotal: 1m 51s\tremaining: 1m 8s\n",
      "620:\tlearn: 0.2482152\ttotal: 1m 51s\tremaining: 1m 7s\n",
      "621:\tlearn: 0.2481452\ttotal: 1m 51s\tremaining: 1m 7s\n",
      "622:\tlearn: 0.2481076\ttotal: 1m 51s\tremaining: 1m 7s\n",
      "623:\tlearn: 0.2480551\ttotal: 1m 51s\tremaining: 1m 7s\n",
      "624:\tlearn: 0.2480020\ttotal: 1m 51s\tremaining: 1m 7s\n",
      "625:\tlearn: 0.2479602\ttotal: 1m 51s\tremaining: 1m 6s\n",
      "626:\tlearn: 0.2479300\ttotal: 1m 51s\tremaining: 1m 6s\n",
      "627:\tlearn: 0.2478766\ttotal: 1m 51s\tremaining: 1m 6s\n",
      "628:\tlearn: 0.2478426\ttotal: 1m 52s\tremaining: 1m 6s\n",
      "629:\tlearn: 0.2477986\ttotal: 1m 52s\tremaining: 1m 5s\n",
      "630:\tlearn: 0.2477553\ttotal: 1m 52s\tremaining: 1m 5s\n",
      "631:\tlearn: 0.2477117\ttotal: 1m 52s\tremaining: 1m 5s\n",
      "632:\tlearn: 0.2476774\ttotal: 1m 52s\tremaining: 1m 5s\n",
      "633:\tlearn: 0.2476411\ttotal: 1m 52s\tremaining: 1m 5s\n",
      "634:\tlearn: 0.2476064\ttotal: 1m 52s\tremaining: 1m 4s\n",
      "635:\tlearn: 0.2475639\ttotal: 1m 53s\tremaining: 1m 4s\n",
      "636:\tlearn: 0.2474917\ttotal: 1m 53s\tremaining: 1m 4s\n",
      "637:\tlearn: 0.2474409\ttotal: 1m 53s\tremaining: 1m 4s\n",
      "638:\tlearn: 0.2473657\ttotal: 1m 53s\tremaining: 1m 4s\n",
      "639:\tlearn: 0.2473043\ttotal: 1m 53s\tremaining: 1m 3s\n",
      "640:\tlearn: 0.2472706\ttotal: 1m 53s\tremaining: 1m 3s\n",
      "641:\tlearn: 0.2472336\ttotal: 1m 54s\tremaining: 1m 3s\n",
      "642:\tlearn: 0.2471800\ttotal: 1m 54s\tremaining: 1m 3s\n",
      "643:\tlearn: 0.2471431\ttotal: 1m 54s\tremaining: 1m 3s\n",
      "644:\tlearn: 0.2470943\ttotal: 1m 54s\tremaining: 1m 3s\n",
      "645:\tlearn: 0.2470699\ttotal: 1m 54s\tremaining: 1m 2s\n",
      "646:\tlearn: 0.2470353\ttotal: 1m 54s\tremaining: 1m 2s\n",
      "647:\tlearn: 0.2469914\ttotal: 1m 54s\tremaining: 1m 2s\n",
      "648:\tlearn: 0.2469665\ttotal: 1m 54s\tremaining: 1m 2s\n",
      "649:\tlearn: 0.2469300\ttotal: 1m 55s\tremaining: 1m 1s\n",
      "650:\tlearn: 0.2468944\ttotal: 1m 55s\tremaining: 1m 1s\n",
      "651:\tlearn: 0.2468377\ttotal: 1m 55s\tremaining: 1m 1s\n",
      "652:\tlearn: 0.2468168\ttotal: 1m 55s\tremaining: 1m 1s\n",
      "653:\tlearn: 0.2467670\ttotal: 1m 55s\tremaining: 1m 1s\n",
      "654:\tlearn: 0.2467306\ttotal: 1m 55s\tremaining: 1m\n",
      "655:\tlearn: 0.2466836\ttotal: 1m 55s\tremaining: 1m\n",
      "656:\tlearn: 0.2466386\ttotal: 1m 55s\tremaining: 1m\n",
      "657:\tlearn: 0.2465970\ttotal: 1m 55s\tremaining: 1m\n",
      "658:\tlearn: 0.2465446\ttotal: 1m 55s\tremaining: 1m\n",
      "659:\tlearn: 0.2464885\ttotal: 1m 56s\tremaining: 59.8s\n",
      "660:\tlearn: 0.2464432\ttotal: 1m 56s\tremaining: 59.6s\n",
      "661:\tlearn: 0.2464091\ttotal: 1m 56s\tremaining: 59.4s\n",
      "662:\tlearn: 0.2463376\ttotal: 1m 56s\tremaining: 59.2s\n",
      "663:\tlearn: 0.2462732\ttotal: 1m 56s\tremaining: 59s\n",
      "664:\tlearn: 0.2461973\ttotal: 1m 56s\tremaining: 58.8s\n",
      "665:\tlearn: 0.2461373\ttotal: 1m 56s\tremaining: 58.6s\n",
      "666:\tlearn: 0.2461002\ttotal: 1m 56s\tremaining: 58.4s\n",
      "667:\tlearn: 0.2460690\ttotal: 1m 57s\tremaining: 58.2s\n",
      "668:\tlearn: 0.2460212\ttotal: 1m 57s\tremaining: 58s\n",
      "669:\tlearn: 0.2459660\ttotal: 1m 57s\tremaining: 57.8s\n",
      "670:\tlearn: 0.2459165\ttotal: 1m 57s\tremaining: 57.6s\n",
      "671:\tlearn: 0.2458880\ttotal: 1m 57s\tremaining: 57.4s\n",
      "672:\tlearn: 0.2458560\ttotal: 1m 57s\tremaining: 57.2s\n",
      "673:\tlearn: 0.2458179\ttotal: 1m 57s\tremaining: 57s\n",
      "674:\tlearn: 0.2457665\ttotal: 1m 57s\tremaining: 56.7s\n",
      "675:\tlearn: 0.2457140\ttotal: 1m 57s\tremaining: 56.5s\n",
      "676:\tlearn: 0.2456742\ttotal: 1m 58s\tremaining: 56.3s\n",
      "677:\tlearn: 0.2456374\ttotal: 1m 58s\tremaining: 56.2s\n",
      "678:\tlearn: 0.2455848\ttotal: 1m 58s\tremaining: 56s\n",
      "679:\tlearn: 0.2455673\ttotal: 1m 58s\tremaining: 55.8s\n",
      "680:\tlearn: 0.2455082\ttotal: 1m 58s\tremaining: 55.6s\n",
      "681:\tlearn: 0.2454778\ttotal: 1m 58s\tremaining: 55.4s\n",
      "682:\tlearn: 0.2454148\ttotal: 1m 58s\tremaining: 55.2s\n",
      "683:\tlearn: 0.2453618\ttotal: 1m 58s\tremaining: 54.9s\n",
      "684:\tlearn: 0.2453123\ttotal: 1m 58s\tremaining: 54.7s\n",
      "685:\tlearn: 0.2452800\ttotal: 1m 59s\tremaining: 54.5s\n",
      "686:\tlearn: 0.2452055\ttotal: 1m 59s\tremaining: 54.3s\n",
      "687:\tlearn: 0.2451524\ttotal: 1m 59s\tremaining: 54.1s\n",
      "688:\tlearn: 0.2451168\ttotal: 1m 59s\tremaining: 53.9s\n",
      "689:\tlearn: 0.2450766\ttotal: 1m 59s\tremaining: 53.6s\n",
      "690:\tlearn: 0.2449754\ttotal: 1m 59s\tremaining: 53.4s\n",
      "691:\tlearn: 0.2449469\ttotal: 1m 59s\tremaining: 53.2s\n",
      "692:\tlearn: 0.2449038\ttotal: 1m 59s\tremaining: 53s\n",
      "693:\tlearn: 0.2448750\ttotal: 1m 59s\tremaining: 52.7s\n",
      "694:\tlearn: 0.2448346\ttotal: 1m 59s\tremaining: 52.5s\n",
      "695:\tlearn: 0.2447770\ttotal: 1m 59s\tremaining: 52.3s\n",
      "696:\tlearn: 0.2447105\ttotal: 1m 59s\tremaining: 52.2s\n",
      "697:\tlearn: 0.2446857\ttotal: 2m\tremaining: 52s\n",
      "698:\tlearn: 0.2446703\ttotal: 2m\tremaining: 51.8s\n",
      "699:\tlearn: 0.2446379\ttotal: 2m\tremaining: 51.6s\n",
      "700:\tlearn: 0.2445789\ttotal: 2m\tremaining: 51.4s\n",
      "701:\tlearn: 0.2445459\ttotal: 2m\tremaining: 51.2s\n",
      "702:\tlearn: 0.2444850\ttotal: 2m\tremaining: 51s\n",
      "703:\tlearn: 0.2444289\ttotal: 2m\tremaining: 50.8s\n",
      "704:\tlearn: 0.2443859\ttotal: 2m 1s\tremaining: 50.7s\n",
      "705:\tlearn: 0.2443542\ttotal: 2m 1s\tremaining: 50.5s\n",
      "706:\tlearn: 0.2442992\ttotal: 2m 1s\tremaining: 50.3s\n",
      "707:\tlearn: 0.2442772\ttotal: 2m 1s\tremaining: 50.1s\n",
      "708:\tlearn: 0.2442558\ttotal: 2m 1s\tremaining: 50s\n",
      "709:\tlearn: 0.2442179\ttotal: 2m 1s\tremaining: 49.8s\n",
      "710:\tlearn: 0.2441906\ttotal: 2m 2s\tremaining: 49.6s\n",
      "711:\tlearn: 0.2441679\ttotal: 2m 2s\tremaining: 49.4s\n",
      "712:\tlearn: 0.2441193\ttotal: 2m 2s\tremaining: 49.3s\n",
      "713:\tlearn: 0.2440814\ttotal: 2m 2s\tremaining: 49.1s\n",
      "714:\tlearn: 0.2440459\ttotal: 2m 2s\tremaining: 49s\n",
      "715:\tlearn: 0.2440111\ttotal: 2m 3s\tremaining: 48.9s\n",
      "716:\tlearn: 0.2439767\ttotal: 2m 3s\tremaining: 48.7s\n",
      "717:\tlearn: 0.2439260\ttotal: 2m 3s\tremaining: 48.6s\n",
      "718:\tlearn: 0.2439057\ttotal: 2m 3s\tremaining: 48.4s\n",
      "719:\tlearn: 0.2438631\ttotal: 2m 3s\tremaining: 48.2s\n",
      "720:\tlearn: 0.2438178\ttotal: 2m 4s\tremaining: 48s\n",
      "721:\tlearn: 0.2437605\ttotal: 2m 4s\tremaining: 47.8s\n",
      "722:\tlearn: 0.2437071\ttotal: 2m 4s\tremaining: 47.6s\n",
      "723:\tlearn: 0.2436392\ttotal: 2m 4s\tremaining: 47.5s\n",
      "724:\tlearn: 0.2436020\ttotal: 2m 4s\tremaining: 47.3s\n",
      "725:\tlearn: 0.2435440\ttotal: 2m 4s\tremaining: 47.1s\n",
      "726:\tlearn: 0.2435291\ttotal: 2m 4s\tremaining: 46.9s\n",
      "727:\tlearn: 0.2434845\ttotal: 2m 5s\tremaining: 46.7s\n",
      "728:\tlearn: 0.2434520\ttotal: 2m 5s\tremaining: 46.6s\n",
      "729:\tlearn: 0.2434074\ttotal: 2m 5s\tremaining: 46.4s\n",
      "730:\tlearn: 0.2433551\ttotal: 2m 5s\tremaining: 46.2s\n",
      "731:\tlearn: 0.2433250\ttotal: 2m 5s\tremaining: 46.1s\n",
      "732:\tlearn: 0.2432776\ttotal: 2m 5s\tremaining: 45.9s\n",
      "733:\tlearn: 0.2432559\ttotal: 2m 6s\tremaining: 45.7s\n",
      "734:\tlearn: 0.2431836\ttotal: 2m 6s\tremaining: 45.5s\n",
      "735:\tlearn: 0.2431357\ttotal: 2m 6s\tremaining: 45.3s\n",
      "736:\tlearn: 0.2430830\ttotal: 2m 6s\tremaining: 45.2s\n",
      "737:\tlearn: 0.2430456\ttotal: 2m 6s\tremaining: 45s\n",
      "738:\tlearn: 0.2430049\ttotal: 2m 7s\tremaining: 44.9s\n",
      "739:\tlearn: 0.2429628\ttotal: 2m 7s\tremaining: 44.7s\n",
      "740:\tlearn: 0.2429388\ttotal: 2m 7s\tremaining: 44.6s\n",
      "741:\tlearn: 0.2428832\ttotal: 2m 7s\tremaining: 44.5s\n",
      "742:\tlearn: 0.2428543\ttotal: 2m 8s\tremaining: 44.4s\n",
      "743:\tlearn: 0.2428035\ttotal: 2m 8s\tremaining: 44.2s\n",
      "744:\tlearn: 0.2427593\ttotal: 2m 8s\tremaining: 44.1s\n",
      "745:\tlearn: 0.2427121\ttotal: 2m 9s\tremaining: 43.9s\n",
      "746:\tlearn: 0.2426683\ttotal: 2m 9s\tremaining: 43.8s\n",
      "747:\tlearn: 0.2426296\ttotal: 2m 9s\tremaining: 43.6s\n",
      "748:\tlearn: 0.2425784\ttotal: 2m 9s\tremaining: 43.5s\n",
      "749:\tlearn: 0.2425357\ttotal: 2m 10s\tremaining: 43.4s\n",
      "750:\tlearn: 0.2425067\ttotal: 2m 10s\tremaining: 43.3s\n",
      "751:\tlearn: 0.2424728\ttotal: 2m 10s\tremaining: 43.1s\n",
      "752:\tlearn: 0.2424428\ttotal: 2m 10s\tremaining: 43s\n",
      "753:\tlearn: 0.2424201\ttotal: 2m 11s\tremaining: 42.8s\n",
      "754:\tlearn: 0.2423929\ttotal: 2m 11s\tremaining: 42.7s\n",
      "755:\tlearn: 0.2423420\ttotal: 2m 11s\tremaining: 42.6s\n",
      "756:\tlearn: 0.2422887\ttotal: 2m 12s\tremaining: 42.4s\n",
      "757:\tlearn: 0.2422509\ttotal: 2m 12s\tremaining: 42.2s\n",
      "758:\tlearn: 0.2422288\ttotal: 2m 12s\tremaining: 42.1s\n",
      "759:\tlearn: 0.2421946\ttotal: 2m 12s\tremaining: 41.9s\n",
      "760:\tlearn: 0.2421667\ttotal: 2m 12s\tremaining: 41.7s\n",
      "761:\tlearn: 0.2421179\ttotal: 2m 12s\tremaining: 41.5s\n",
      "762:\tlearn: 0.2420900\ttotal: 2m 12s\tremaining: 41.3s\n",
      "763:\tlearn: 0.2420734\ttotal: 2m 13s\tremaining: 41.1s\n",
      "764:\tlearn: 0.2420536\ttotal: 2m 13s\tremaining: 41s\n",
      "765:\tlearn: 0.2420084\ttotal: 2m 13s\tremaining: 40.8s\n",
      "766:\tlearn: 0.2419585\ttotal: 2m 13s\tremaining: 40.6s\n",
      "767:\tlearn: 0.2419230\ttotal: 2m 14s\tremaining: 40.5s\n",
      "768:\tlearn: 0.2418839\ttotal: 2m 14s\tremaining: 40.4s\n",
      "769:\tlearn: 0.2418351\ttotal: 2m 14s\tremaining: 40.2s\n",
      "770:\tlearn: 0.2417939\ttotal: 2m 14s\tremaining: 40s\n",
      "771:\tlearn: 0.2417744\ttotal: 2m 15s\tremaining: 39.9s\n",
      "772:\tlearn: 0.2417429\ttotal: 2m 15s\tremaining: 39.7s\n",
      "773:\tlearn: 0.2416952\ttotal: 2m 15s\tremaining: 39.6s\n",
      "774:\tlearn: 0.2416360\ttotal: 2m 15s\tremaining: 39.4s\n",
      "775:\tlearn: 0.2415872\ttotal: 2m 15s\tremaining: 39.2s\n",
      "776:\tlearn: 0.2415547\ttotal: 2m 16s\tremaining: 39s\n",
      "777:\tlearn: 0.2415237\ttotal: 2m 16s\tremaining: 38.9s\n",
      "778:\tlearn: 0.2415070\ttotal: 2m 16s\tremaining: 38.7s\n",
      "779:\tlearn: 0.2414794\ttotal: 2m 16s\tremaining: 38.5s\n",
      "780:\tlearn: 0.2414287\ttotal: 2m 16s\tremaining: 38.4s\n",
      "781:\tlearn: 0.2413905\ttotal: 2m 17s\tremaining: 38.2s\n",
      "782:\tlearn: 0.2413421\ttotal: 2m 17s\tremaining: 38s\n",
      "783:\tlearn: 0.2413159\ttotal: 2m 17s\tremaining: 37.9s\n",
      "784:\tlearn: 0.2413025\ttotal: 2m 17s\tremaining: 37.7s\n",
      "785:\tlearn: 0.2412742\ttotal: 2m 17s\tremaining: 37.5s\n",
      "786:\tlearn: 0.2412306\ttotal: 2m 17s\tremaining: 37.3s\n",
      "787:\tlearn: 0.2411833\ttotal: 2m 18s\tremaining: 37.2s\n",
      "788:\tlearn: 0.2411358\ttotal: 2m 18s\tremaining: 37s\n",
      "789:\tlearn: 0.2411125\ttotal: 2m 18s\tremaining: 36.8s\n",
      "790:\tlearn: 0.2410609\ttotal: 2m 18s\tremaining: 36.6s\n",
      "791:\tlearn: 0.2410230\ttotal: 2m 18s\tremaining: 36.4s\n",
      "792:\tlearn: 0.2409871\ttotal: 2m 18s\tremaining: 36.2s\n",
      "793:\tlearn: 0.2409641\ttotal: 2m 19s\tremaining: 36.1s\n",
      "794:\tlearn: 0.2409323\ttotal: 2m 19s\tremaining: 35.9s\n",
      "795:\tlearn: 0.2408914\ttotal: 2m 19s\tremaining: 35.7s\n",
      "796:\tlearn: 0.2408588\ttotal: 2m 19s\tremaining: 35.6s\n",
      "797:\tlearn: 0.2408341\ttotal: 2m 19s\tremaining: 35.4s\n",
      "798:\tlearn: 0.2408050\ttotal: 2m 20s\tremaining: 35.3s\n",
      "799:\tlearn: 0.2407438\ttotal: 2m 20s\tremaining: 35.2s\n",
      "800:\tlearn: 0.2406961\ttotal: 2m 21s\tremaining: 35s\n",
      "801:\tlearn: 0.2406264\ttotal: 2m 21s\tremaining: 34.9s\n",
      "802:\tlearn: 0.2405795\ttotal: 2m 21s\tremaining: 34.7s\n",
      "803:\tlearn: 0.2405523\ttotal: 2m 21s\tremaining: 34.5s\n",
      "804:\tlearn: 0.2405195\ttotal: 2m 21s\tremaining: 34.4s\n",
      "805:\tlearn: 0.2404713\ttotal: 2m 21s\tremaining: 34.2s\n",
      "806:\tlearn: 0.2404478\ttotal: 2m 21s\tremaining: 34s\n",
      "807:\tlearn: 0.2404222\ttotal: 2m 22s\tremaining: 33.8s\n",
      "808:\tlearn: 0.2403708\ttotal: 2m 22s\tremaining: 33.6s\n",
      "809:\tlearn: 0.2403401\ttotal: 2m 22s\tremaining: 33.4s\n",
      "810:\tlearn: 0.2403110\ttotal: 2m 22s\tremaining: 33.2s\n",
      "811:\tlearn: 0.2402957\ttotal: 2m 22s\tremaining: 33s\n",
      "812:\tlearn: 0.2402626\ttotal: 2m 22s\tremaining: 32.8s\n",
      "813:\tlearn: 0.2402208\ttotal: 2m 22s\tremaining: 32.6s\n",
      "814:\tlearn: 0.2401758\ttotal: 2m 22s\tremaining: 32.4s\n",
      "815:\tlearn: 0.2401194\ttotal: 2m 23s\tremaining: 32.2s\n",
      "816:\tlearn: 0.2400789\ttotal: 2m 23s\tremaining: 32.1s\n",
      "817:\tlearn: 0.2400544\ttotal: 2m 23s\tremaining: 31.9s\n",
      "818:\tlearn: 0.2400094\ttotal: 2m 23s\tremaining: 31.7s\n",
      "819:\tlearn: 0.2399700\ttotal: 2m 23s\tremaining: 31.5s\n",
      "820:\tlearn: 0.2399459\ttotal: 2m 23s\tremaining: 31.3s\n",
      "821:\tlearn: 0.2399247\ttotal: 2m 23s\tremaining: 31.1s\n",
      "822:\tlearn: 0.2398916\ttotal: 2m 23s\tremaining: 30.9s\n",
      "823:\tlearn: 0.2398377\ttotal: 2m 23s\tremaining: 30.7s\n",
      "824:\tlearn: 0.2397390\ttotal: 2m 24s\tremaining: 30.6s\n",
      "825:\tlearn: 0.2397015\ttotal: 2m 24s\tremaining: 30.4s\n",
      "826:\tlearn: 0.2396360\ttotal: 2m 24s\tremaining: 30.2s\n",
      "827:\tlearn: 0.2396005\ttotal: 2m 24s\tremaining: 30s\n",
      "828:\tlearn: 0.2395682\ttotal: 2m 24s\tremaining: 29.8s\n",
      "829:\tlearn: 0.2395288\ttotal: 2m 24s\tremaining: 29.6s\n",
      "830:\tlearn: 0.2395091\ttotal: 2m 24s\tremaining: 29.4s\n",
      "831:\tlearn: 0.2394610\ttotal: 2m 24s\tremaining: 29.2s\n",
      "832:\tlearn: 0.2394244\ttotal: 2m 24s\tremaining: 29.1s\n",
      "833:\tlearn: 0.2394057\ttotal: 2m 25s\tremaining: 28.9s\n",
      "834:\tlearn: 0.2393842\ttotal: 2m 25s\tremaining: 28.7s\n",
      "835:\tlearn: 0.2393700\ttotal: 2m 25s\tremaining: 28.5s\n",
      "836:\tlearn: 0.2393326\ttotal: 2m 25s\tremaining: 28.3s\n",
      "837:\tlearn: 0.2392787\ttotal: 2m 25s\tremaining: 28.1s\n",
      "838:\tlearn: 0.2392514\ttotal: 2m 25s\tremaining: 27.9s\n",
      "839:\tlearn: 0.2392055\ttotal: 2m 25s\tremaining: 27.7s\n",
      "840:\tlearn: 0.2391855\ttotal: 2m 25s\tremaining: 27.5s\n",
      "841:\tlearn: 0.2391613\ttotal: 2m 25s\tremaining: 27.3s\n",
      "842:\tlearn: 0.2391177\ttotal: 2m 25s\tremaining: 27.2s\n",
      "843:\tlearn: 0.2390863\ttotal: 2m 25s\tremaining: 27s\n",
      "844:\tlearn: 0.2390468\ttotal: 2m 26s\tremaining: 26.8s\n",
      "845:\tlearn: 0.2390195\ttotal: 2m 26s\tremaining: 26.7s\n",
      "846:\tlearn: 0.2389632\ttotal: 2m 26s\tremaining: 26.5s\n",
      "847:\tlearn: 0.2388963\ttotal: 2m 27s\tremaining: 26.4s\n",
      "848:\tlearn: 0.2388583\ttotal: 2m 27s\tremaining: 26.2s\n",
      "849:\tlearn: 0.2388244\ttotal: 2m 27s\tremaining: 26.1s\n",
      "850:\tlearn: 0.2388099\ttotal: 2m 27s\tremaining: 25.9s\n",
      "851:\tlearn: 0.2387710\ttotal: 2m 28s\tremaining: 25.7s\n",
      "852:\tlearn: 0.2387118\ttotal: 2m 28s\tremaining: 25.5s\n",
      "853:\tlearn: 0.2386814\ttotal: 2m 28s\tremaining: 25.4s\n",
      "854:\tlearn: 0.2386166\ttotal: 2m 28s\tremaining: 25.2s\n",
      "855:\tlearn: 0.2385793\ttotal: 2m 28s\tremaining: 25s\n",
      "856:\tlearn: 0.2385578\ttotal: 2m 28s\tremaining: 24.8s\n",
      "857:\tlearn: 0.2385105\ttotal: 2m 28s\tremaining: 24.6s\n",
      "858:\tlearn: 0.2384725\ttotal: 2m 29s\tremaining: 24.5s\n",
      "859:\tlearn: 0.2384313\ttotal: 2m 29s\tremaining: 24.3s\n",
      "860:\tlearn: 0.2383985\ttotal: 2m 29s\tremaining: 24.1s\n",
      "861:\tlearn: 0.2383631\ttotal: 2m 29s\tremaining: 24s\n",
      "862:\tlearn: 0.2383236\ttotal: 2m 29s\tremaining: 23.8s\n",
      "863:\tlearn: 0.2383089\ttotal: 2m 30s\tremaining: 23.6s\n",
      "864:\tlearn: 0.2382825\ttotal: 2m 30s\tremaining: 23.5s\n",
      "865:\tlearn: 0.2382605\ttotal: 2m 30s\tremaining: 23.3s\n",
      "866:\tlearn: 0.2382210\ttotal: 2m 30s\tremaining: 23.1s\n",
      "867:\tlearn: 0.2381913\ttotal: 2m 30s\tremaining: 22.9s\n",
      "868:\tlearn: 0.2381536\ttotal: 2m 31s\tremaining: 22.8s\n",
      "869:\tlearn: 0.2380955\ttotal: 2m 31s\tremaining: 22.6s\n",
      "870:\tlearn: 0.2380725\ttotal: 2m 31s\tremaining: 22.4s\n",
      "871:\tlearn: 0.2380257\ttotal: 2m 31s\tremaining: 22.3s\n",
      "872:\tlearn: 0.2379794\ttotal: 2m 31s\tremaining: 22.1s\n",
      "873:\tlearn: 0.2379412\ttotal: 2m 32s\tremaining: 21.9s\n",
      "874:\tlearn: 0.2379103\ttotal: 2m 32s\tremaining: 21.8s\n",
      "875:\tlearn: 0.2378767\ttotal: 2m 32s\tremaining: 21.6s\n",
      "876:\tlearn: 0.2378486\ttotal: 2m 32s\tremaining: 21.4s\n",
      "877:\tlearn: 0.2378073\ttotal: 2m 33s\tremaining: 21.3s\n",
      "878:\tlearn: 0.2377466\ttotal: 2m 33s\tremaining: 21.1s\n",
      "879:\tlearn: 0.2377114\ttotal: 2m 33s\tremaining: 20.9s\n",
      "880:\tlearn: 0.2376947\ttotal: 2m 33s\tremaining: 20.8s\n",
      "881:\tlearn: 0.2376345\ttotal: 2m 34s\tremaining: 20.6s\n",
      "882:\tlearn: 0.2376164\ttotal: 2m 34s\tremaining: 20.5s\n",
      "883:\tlearn: 0.2375737\ttotal: 2m 34s\tremaining: 20.3s\n",
      "884:\tlearn: 0.2375420\ttotal: 2m 34s\tremaining: 20.1s\n",
      "885:\tlearn: 0.2374994\ttotal: 2m 34s\tremaining: 19.9s\n",
      "886:\tlearn: 0.2374564\ttotal: 2m 35s\tremaining: 19.8s\n",
      "887:\tlearn: 0.2374125\ttotal: 2m 35s\tremaining: 19.6s\n",
      "888:\tlearn: 0.2373705\ttotal: 2m 35s\tremaining: 19.4s\n",
      "889:\tlearn: 0.2373307\ttotal: 2m 35s\tremaining: 19.2s\n",
      "890:\tlearn: 0.2372984\ttotal: 2m 35s\tremaining: 19s\n",
      "891:\tlearn: 0.2372554\ttotal: 2m 35s\tremaining: 18.8s\n",
      "892:\tlearn: 0.2372199\ttotal: 2m 35s\tremaining: 18.6s\n",
      "893:\tlearn: 0.2371670\ttotal: 2m 35s\tremaining: 18.5s\n",
      "894:\tlearn: 0.2371379\ttotal: 2m 35s\tremaining: 18.3s\n",
      "895:\tlearn: 0.2371194\ttotal: 2m 35s\tremaining: 18.1s\n",
      "896:\tlearn: 0.2370609\ttotal: 2m 35s\tremaining: 17.9s\n",
      "897:\tlearn: 0.2370258\ttotal: 2m 36s\tremaining: 17.7s\n",
      "898:\tlearn: 0.2370036\ttotal: 2m 36s\tremaining: 17.6s\n",
      "899:\tlearn: 0.2369787\ttotal: 2m 36s\tremaining: 17.4s\n",
      "900:\tlearn: 0.2369432\ttotal: 2m 36s\tremaining: 17.2s\n",
      "901:\tlearn: 0.2369122\ttotal: 2m 37s\tremaining: 17.1s\n",
      "902:\tlearn: 0.2369001\ttotal: 2m 37s\tremaining: 16.9s\n",
      "903:\tlearn: 0.2368658\ttotal: 2m 37s\tremaining: 16.7s\n",
      "904:\tlearn: 0.2368254\ttotal: 2m 37s\tremaining: 16.6s\n",
      "905:\tlearn: 0.2367927\ttotal: 2m 37s\tremaining: 16.4s\n",
      "906:\tlearn: 0.2367690\ttotal: 2m 38s\tremaining: 16.2s\n",
      "907:\tlearn: 0.2367435\ttotal: 2m 38s\tremaining: 16.1s\n",
      "908:\tlearn: 0.2367001\ttotal: 2m 38s\tremaining: 15.9s\n",
      "909:\tlearn: 0.2366766\ttotal: 2m 38s\tremaining: 15.7s\n",
      "910:\tlearn: 0.2366621\ttotal: 2m 39s\tremaining: 15.5s\n",
      "911:\tlearn: 0.2366288\ttotal: 2m 39s\tremaining: 15.4s\n",
      "912:\tlearn: 0.2365783\ttotal: 2m 39s\tremaining: 15.2s\n",
      "913:\tlearn: 0.2365417\ttotal: 2m 39s\tremaining: 15.1s\n",
      "914:\tlearn: 0.2365098\ttotal: 2m 40s\tremaining: 14.9s\n",
      "915:\tlearn: 0.2364825\ttotal: 2m 40s\tremaining: 14.7s\n",
      "916:\tlearn: 0.2364683\ttotal: 2m 40s\tremaining: 14.6s\n",
      "917:\tlearn: 0.2364219\ttotal: 2m 41s\tremaining: 14.4s\n",
      "918:\tlearn: 0.2363762\ttotal: 2m 41s\tremaining: 14.2s\n",
      "919:\tlearn: 0.2363431\ttotal: 2m 41s\tremaining: 14s\n",
      "920:\tlearn: 0.2363132\ttotal: 2m 41s\tremaining: 13.9s\n",
      "921:\tlearn: 0.2362808\ttotal: 2m 42s\tremaining: 13.7s\n",
      "922:\tlearn: 0.2362189\ttotal: 2m 42s\tremaining: 13.5s\n",
      "923:\tlearn: 0.2361810\ttotal: 2m 42s\tremaining: 13.4s\n",
      "924:\tlearn: 0.2361610\ttotal: 2m 42s\tremaining: 13.2s\n",
      "925:\tlearn: 0.2361215\ttotal: 2m 42s\tremaining: 13s\n",
      "926:\tlearn: 0.2361101\ttotal: 2m 42s\tremaining: 12.8s\n",
      "927:\tlearn: 0.2360673\ttotal: 2m 42s\tremaining: 12.6s\n",
      "928:\tlearn: 0.2360137\ttotal: 2m 43s\tremaining: 12.5s\n",
      "929:\tlearn: 0.2359967\ttotal: 2m 43s\tremaining: 12.3s\n",
      "930:\tlearn: 0.2359649\ttotal: 2m 43s\tremaining: 12.1s\n",
      "931:\tlearn: 0.2359489\ttotal: 2m 43s\tremaining: 11.9s\n",
      "932:\tlearn: 0.2359126\ttotal: 2m 43s\tremaining: 11.8s\n",
      "933:\tlearn: 0.2358397\ttotal: 2m 43s\tremaining: 11.6s\n",
      "934:\tlearn: 0.2358196\ttotal: 2m 44s\tremaining: 11.4s\n",
      "935:\tlearn: 0.2358074\ttotal: 2m 44s\tremaining: 11.2s\n",
      "936:\tlearn: 0.2357816\ttotal: 2m 44s\tremaining: 11.1s\n",
      "937:\tlearn: 0.2357468\ttotal: 2m 44s\tremaining: 10.9s\n",
      "938:\tlearn: 0.2357114\ttotal: 2m 44s\tremaining: 10.7s\n",
      "939:\tlearn: 0.2356739\ttotal: 2m 44s\tremaining: 10.5s\n",
      "940:\tlearn: 0.2356549\ttotal: 2m 44s\tremaining: 10.3s\n",
      "941:\tlearn: 0.2356272\ttotal: 2m 44s\tremaining: 10.2s\n",
      "942:\tlearn: 0.2356082\ttotal: 2m 45s\tremaining: 9.98s\n",
      "943:\tlearn: 0.2355598\ttotal: 2m 45s\tremaining: 9.8s\n",
      "944:\tlearn: 0.2355371\ttotal: 2m 45s\tremaining: 9.62s\n",
      "945:\tlearn: 0.2355075\ttotal: 2m 45s\tremaining: 9.44s\n",
      "946:\tlearn: 0.2354613\ttotal: 2m 45s\tremaining: 9.25s\n",
      "947:\tlearn: 0.2354290\ttotal: 2m 45s\tremaining: 9.08s\n",
      "948:\tlearn: 0.2354121\ttotal: 2m 45s\tremaining: 8.9s\n",
      "949:\tlearn: 0.2353767\ttotal: 2m 45s\tremaining: 8.72s\n",
      "950:\tlearn: 0.2353563\ttotal: 2m 45s\tremaining: 8.54s\n",
      "951:\tlearn: 0.2353292\ttotal: 2m 45s\tremaining: 8.37s\n",
      "952:\tlearn: 0.2352904\ttotal: 2m 46s\tremaining: 8.19s\n",
      "953:\tlearn: 0.2352640\ttotal: 2m 46s\tremaining: 8.01s\n",
      "954:\tlearn: 0.2352172\ttotal: 2m 46s\tremaining: 7.83s\n",
      "955:\tlearn: 0.2351794\ttotal: 2m 46s\tremaining: 7.66s\n",
      "956:\tlearn: 0.2351336\ttotal: 2m 46s\tremaining: 7.48s\n",
      "957:\tlearn: 0.2351105\ttotal: 2m 46s\tremaining: 7.3s\n",
      "958:\tlearn: 0.2350763\ttotal: 2m 46s\tremaining: 7.13s\n",
      "959:\tlearn: 0.2350557\ttotal: 2m 46s\tremaining: 6.95s\n",
      "960:\tlearn: 0.2349814\ttotal: 2m 46s\tremaining: 6.78s\n",
      "961:\tlearn: 0.2349422\ttotal: 2m 47s\tremaining: 6.6s\n",
      "962:\tlearn: 0.2348965\ttotal: 2m 47s\tremaining: 6.42s\n",
      "963:\tlearn: 0.2348441\ttotal: 2m 47s\tremaining: 6.24s\n",
      "964:\tlearn: 0.2348114\ttotal: 2m 47s\tremaining: 6.07s\n",
      "965:\tlearn: 0.2347880\ttotal: 2m 47s\tremaining: 5.89s\n",
      "966:\tlearn: 0.2347461\ttotal: 2m 47s\tremaining: 5.72s\n",
      "967:\tlearn: 0.2346941\ttotal: 2m 47s\tremaining: 5.54s\n",
      "968:\tlearn: 0.2346601\ttotal: 2m 47s\tremaining: 5.37s\n",
      "969:\tlearn: 0.2346262\ttotal: 2m 47s\tremaining: 5.2s\n",
      "970:\tlearn: 0.2346058\ttotal: 2m 48s\tremaining: 5.02s\n",
      "971:\tlearn: 0.2345799\ttotal: 2m 48s\tremaining: 4.84s\n",
      "972:\tlearn: 0.2345419\ttotal: 2m 48s\tremaining: 4.67s\n",
      "973:\tlearn: 0.2344995\ttotal: 2m 48s\tremaining: 4.5s\n",
      "974:\tlearn: 0.2344412\ttotal: 2m 48s\tremaining: 4.32s\n",
      "975:\tlearn: 0.2344059\ttotal: 2m 48s\tremaining: 4.15s\n",
      "976:\tlearn: 0.2343774\ttotal: 2m 48s\tremaining: 3.97s\n",
      "977:\tlearn: 0.2343337\ttotal: 2m 48s\tremaining: 3.8s\n",
      "978:\tlearn: 0.2343171\ttotal: 2m 48s\tremaining: 3.63s\n",
      "979:\tlearn: 0.2343047\ttotal: 2m 49s\tremaining: 3.45s\n",
      "980:\tlearn: 0.2342619\ttotal: 2m 49s\tremaining: 3.28s\n",
      "981:\tlearn: 0.2342533\ttotal: 2m 49s\tremaining: 3.1s\n",
      "982:\tlearn: 0.2342243\ttotal: 2m 49s\tremaining: 2.93s\n",
      "983:\tlearn: 0.2341892\ttotal: 2m 49s\tremaining: 2.75s\n",
      "984:\tlearn: 0.2341404\ttotal: 2m 49s\tremaining: 2.58s\n",
      "985:\tlearn: 0.2340928\ttotal: 2m 49s\tremaining: 2.41s\n",
      "986:\tlearn: 0.2340704\ttotal: 2m 49s\tremaining: 2.23s\n",
      "987:\tlearn: 0.2340560\ttotal: 2m 49s\tremaining: 2.06s\n",
      "988:\tlearn: 0.2340081\ttotal: 2m 49s\tremaining: 1.89s\n",
      "989:\tlearn: 0.2339741\ttotal: 2m 49s\tremaining: 1.72s\n",
      "990:\tlearn: 0.2339659\ttotal: 2m 49s\tremaining: 1.54s\n",
      "991:\tlearn: 0.2339216\ttotal: 2m 50s\tremaining: 1.37s\n",
      "992:\tlearn: 0.2338871\ttotal: 2m 50s\tremaining: 1.2s\n",
      "993:\tlearn: 0.2338682\ttotal: 2m 50s\tremaining: 1.03s\n",
      "994:\tlearn: 0.2338361\ttotal: 2m 50s\tremaining: 856ms\n",
      "995:\tlearn: 0.2338144\ttotal: 2m 50s\tremaining: 685ms\n",
      "996:\tlearn: 0.2338049\ttotal: 2m 50s\tremaining: 513ms\n",
      "997:\tlearn: 0.2337756\ttotal: 2m 50s\tremaining: 342ms\n",
      "998:\tlearn: 0.2337386\ttotal: 2m 50s\tremaining: 171ms\n",
      "999:\tlearn: 0.2337127\ttotal: 2m 50s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bart/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/bart/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/ensemble/_bagging.py:719: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/bart/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/bart/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bart/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/bart/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/bart/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from interpret.glassbox import DecisionListClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "clfs = {\n",
    "    \"CART\": DecisionTreeClassifier(random_state=1234, max_depth=1000),\n",
    "    \"RNF\": RandomForestClassifier(random_state=1234),\n",
    "    \"XGB\": XGBClassifier(use_label_encoder=False),\n",
    "    \"CAT\": CatBoostClassifier(random_state=1234),\n",
    "    \"ADA\": AdaBoostClassifier(DecisionTreeClassifier(random_state=1234, max_depth=1000)),\n",
    "    \"BAG\": BaggingClassifier(DecisionTreeClassifier(random_state=1234, max_depth=1000)),\n",
    "    \"EBM\": ExplainableBoostingClassifier(),\n",
    "    \"LR_l2\": LogisticRegression(penalty=\"l2\",random_state=1234),\n",
    "    \"GNB\": GaussianNB(),\n",
    "    \"LR\": LogisticRegression(penalty=\"none\", random_state=1234),\n",
    "    \"DL\": DecisionListClassifier(random_state=1234) \n",
    "  \n",
    "}\n",
    "\n",
    "dataset = 'adult'\n",
    "\n",
    "import worstcase_helper\n",
    "import importlib\n",
    "importlib.reload(worstcase_helper)\n",
    "\n",
    "preprocess, X, y = worstcase_helper.load_dataset_with_preprocess(dataset)\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "def make_pipeline_clf(clf_name):\n",
    "    clf = make_pipeline(\n",
    "        preprocess,\n",
    "        clfs[clf_name]\n",
    "    )\n",
    "    return clf\n",
    "\n",
    "clfs_list = []\n",
    "for clf_id, clf_name in enumerate(clfs):\n",
    "    clf = make_pipeline_clf(clf_name)\n",
    "    clf.fit(X, y)\n",
    "    clfs_list.append(clf)\n",
    "\n",
    "import pickle\n",
    "\n",
    "for clf_id, clf_name in enumerate(clfs):\n",
    "    pickle.dump(clfs_list[clf_id], open(f\"adult_{clf_name}.p\", 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "for clf_id, clf_name in enumerate(clfs):\n",
    "    pickle.dump(clfs_list[clf_id], open(f\"adult_{clf_name}.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 32559 rows 14 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 32559 values\n",
      "  -> model_class       : sklearn.tree._classes.DecisionTreeClassifier (default)\n",
      "  -> label             : CART\n",
      "  -> predict function  : <function yhat_proba_default at 0x7fdee00d59d0> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 0.0, mean = 0.241, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.5, mean = 0.0, max = 0.5\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 32559 rows 14 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 32559 values\n",
      "  -> model_class       : sklearn.ensemble._forest.RandomForestClassifier (default)\n",
      "  -> label             : RNF\n",
      "  -> predict function  : <function yhat_proba_default at 0x7fdee00d59d0> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 0.0, mean = 0.242, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.48, mean = -0.000973, max = 0.531\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 32559 rows 14 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 32559 values\n",
      "  -> model_class       : xgboost.sklearn.XGBClassifier (default)\n",
      "  -> label             : XGB\n",
      "  -> predict function  : <function yhat_proba_default at 0x7fdee00d59d0> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 5.27e-06, mean = 0.241, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.989, mean = -1.51e-05, max = 0.998\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 32559 rows 14 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 32559 values\n",
      "  -> model_class       : catboost.core.CatBoostClassifier (default)\n",
      "  -> label             : CAT\n",
      "  -> predict function  : <function yhat_proba_default at 0x7fdee00d59d0> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 1e-05, mean = 0.241, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.987, mean = 5.42e-05, max = 0.999\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 32559 rows 14 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 32559 values\n",
      "  -> model_class       : sklearn.ensemble._weight_boosting.AdaBoostClassifier (default)\n",
      "  -> label             : ADA\n",
      "  -> predict function  : <function yhat_proba_default at 0x7fdee00d59d0> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 1.18e-07, mean = 0.24, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.5, mean = 0.000912, max = 0.5\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 32559 rows 14 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 32559 values\n",
      "  -> model_class       : sklearn.ensemble._bagging.BaggingClassifier (default)\n",
      "  -> label             : BAG\n",
      "  -> predict function  : <function yhat_proba_default at 0x7fdee00d59d0> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 0.0, mean = 0.243, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.8, mean = -0.00181, max = 0.9\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 32559 rows 14 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 32559 values\n",
      "  -> model_class       : interpret.glassbox.ebm.ebm.ExplainableBoostingClassifier (default)\n",
      "  -> label             : EBM\n",
      "  -> predict function  : <function yhat_proba_default at 0x7fdee00d59d0> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 2.35e-10, mean = 0.241, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.992, mean = -8.66e-05, max = 1.0\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 32559 rows 14 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 32559 values\n",
      "  -> model_class       : sklearn.linear_model._logistic.LogisticRegression (default)\n",
      "  -> label             : LR_l2\n",
      "  -> predict function  : <function yhat_proba_default at 0x7fdee00d59d0> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 3.1e-05, mean = 0.241, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -1.0, mean = 7.83e-05, max = 0.999\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 32559 rows 14 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 32559 values\n",
      "  -> model_class       : sklearn.naive_bayes.GaussianNB (default)\n",
      "  -> label             : GNB\n",
      "  -> predict function  : <function yhat_proba_default at 0x7fdee00d59d0> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 0.0, mean = 0.638, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -1.0, mean = -0.397, max = 1.0\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 32559 rows 14 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 32559 values\n",
      "  -> model_class       : sklearn.linear_model._logistic.LogisticRegression (default)\n",
      "  -> label             : LR\n",
      "  -> predict function  : <function yhat_proba_default at 0x7fdee00d59d0> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 1.42e-05, mean = 0.241, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -1.0, mean = -1.68e-05, max = 0.999\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 32559 rows 14 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 32559 values\n",
      "  -> model_class       : interpret.glassbox.skoperules.DecisionListClassifier (default)\n",
      "  -> label             : DL\n",
      "  -> predict function  : <function yhat_proba_default at 0x7fdee00d59d0> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 0.241, mean = 0.325, max = 0.996\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.996, mean = -0.0845, max = 0.759\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n"
     ]
    }
   ],
   "source": [
    "# clf_cart_exp = dx.Explainer(clf_cart, X, y, label=\"CART\")\n",
    "import dalex as dx\n",
    "clfs_explainers = []\n",
    "for clf_id, clf_name in enumerate(clfs):\n",
    "    clf_exp = dx.Explainer(clfs_list[clf_id], X, y, label=clf_name)\n",
    "    clfs_explainers.append(clf_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat = ['WorkClass', 'Education', 'MaritalStatus',\n",
    "                                  'Occupation', 'Relationship', 'Race',\n",
    "                                  'Gender', 'NativeCountry']\n",
    "cont_feat = ['Age', 'fnlwgt', 'EducationNum',\n",
    "                                  'CapitalGain', 'CapitalLoss',\n",
    "                                  'HoursPerWeek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating ceteris paribus: 100%|██████████| 8/8 [00:01<00:00,  7.13it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 8/8 [00:04<00:00,  1.92it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 8/8 [00:01<00:00,  4.72it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 8/8 [00:07<00:00,  1.14it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 8/8 [00:02<00:00,  3.31it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 8/8 [00:32<00:00,  4.12s/it]\n",
      "Calculating ceteris paribus: 100%|██████████| 8/8 [00:01<00:00,  6.03it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 8/8 [00:00<00:00, 13.93it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 8/8 [00:00<00:00, 13.89it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 8/8 [00:01<00:00,  4.03it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 6/6 [00:02<00:00,  2.56it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 6/6 [00:08<00:00,  1.38s/it]\n",
      "Calculating ceteris paribus: 100%|██████████| 6/6 [00:04<00:00,  1.33it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 6/6 [00:25<00:00,  4.28s/it]\n",
      "Calculating ceteris paribus: 100%|██████████| 6/6 [00:10<00:00,  1.74s/it]\n",
      "Calculating ceteris paribus: 100%|██████████| 6/6 [00:06<00:00,  1.05s/it]\n",
      "Calculating ceteris paribus: 100%|██████████| 6/6 [02:38<00:00, 26.47s/it]\n",
      "Calculating ceteris paribus: 100%|██████████| 6/6 [00:02<00:00,  2.01it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 6/6 [00:05<00:00,  1.18it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 6/6 [00:04<00:00,  1.42it/s]\n",
      "Calculating ceteris paribus: 100%|██████████| 6/6 [00:06<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "# import dalex as dx\n",
    "clfs_pd_cat = []\n",
    "clfs_pd_cont = []\n",
    "for clf_id, clf_name in enumerate(clfs):\n",
    "    clf_pd_cat = clfs_explainers[clf_id].model_profile( variables = cat_feat,\n",
    "                                                        variable_type='categorical')\n",
    "    clfs_pd_cat.append(clf_pd_cat)\n",
    "\n",
    "for clf_id, clf_name in enumerate(clfs):\n",
    "    clf_pd_cont = clfs_explainers[clf_id].model_profile( variables = cont_feat)\n",
    "    clfs_pd_cont.append(clf_pd_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dalex as dx\n",
    "clfs_mp = []\n",
    "for clf_id, clf_name in enumerate(clfs):\n",
    "    clf_mp = clfs_explainers[clf_id].model_parts()\n",
    "    clfs_mp.append(clf_mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "adult_mp_results = np.zeros(shape=len(clfs))\n",
    "\n",
    "for i in range(len(clfs)):\n",
    "    adult_mp_results[i] = np.abs(np.subtract(clfs_mp[0].result.dropout_loss[1:-1], clfs_mp[i].result.dropout_loss[1:-1])).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(adult_mp_results).to_csv(f\"./results/mp_adult.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_pd_cat_results = np.zeros(shape=len(clfs))\n",
    "adult_pd_cont_results = np.zeros(shape=len(clfs))\n",
    "for i in range(len(clfs)):\n",
    "    adult_pd_cat_results[i] = np.abs(np.subtract(clfs_pd_cat[0].result._yhat_, clfs_pd_cat[i].result._yhat_)).sum()\n",
    "    adult_pd_cont_results[i] = np.abs(np.subtract(clfs_pd_cont[0].result._yhat_, clfs_pd_cont[i].result._yhat_)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        ,  40.18076222,  48.75556374,  36.78137434,\n",
       "        58.33788   ,  29.70125   ,  41.517683  ,  58.96111682,\n",
       "       237.70864414,  60.7272784 ,  78.32125162])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_pd_cat_results + adult_pd_cont_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_pd_results = adult_pd_cat_results + adult_pd_cont_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(adult_pd_results).to_csv(f\"./results/pd_adult.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54107a2a0eb6a0b2996cb7a94c16d9283b5dc7f969a30a8a01f6dbe77c679ea9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mainenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
