{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['breast', 'campus', 'churn', 'climate',\n",
    "            'compas', 'diabetes', 'german', 'heart',\n",
    "            'stroke', 'student', 'water', 'credit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from interpret.glassbox import DecisionListClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "clfs = {\n",
    "    \"CART\": DecisionTreeClassifier(random_state=1234),\n",
    "    \"EBM\": ExplainableBoostingClassifier(),\n",
    "    \"LR_l2\": LogisticRegression(penalty=\"l2\",random_state=1234),\n",
    "    \"GNB\": GaussianNB(),\n",
    "    \"LR\": LogisticRegression(penalty=\"none\", random_state=1234),\n",
    "    \"DL\": DecisionListClassifier(random_state=1234) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>ssc_p</th>\n",
       "      <th>ssc_b</th>\n",
       "      <th>hsc_p</th>\n",
       "      <th>hsc_b</th>\n",
       "      <th>hsc_s</th>\n",
       "      <th>degree_p</th>\n",
       "      <th>degree_t</th>\n",
       "      <th>workex</th>\n",
       "      <th>etest_p</th>\n",
       "      <th>specialisation</th>\n",
       "      <th>mba_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>67.00</td>\n",
       "      <td>Others</td>\n",
       "      <td>91.00</td>\n",
       "      <td>Others</td>\n",
       "      <td>Commerce</td>\n",
       "      <td>58.00</td>\n",
       "      <td>Sci&amp;Tech</td>\n",
       "      <td>No</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Mkt&amp;HR</td>\n",
       "      <td>58.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>79.33</td>\n",
       "      <td>Central</td>\n",
       "      <td>78.33</td>\n",
       "      <td>Others</td>\n",
       "      <td>Science</td>\n",
       "      <td>77.48</td>\n",
       "      <td>Sci&amp;Tech</td>\n",
       "      <td>Yes</td>\n",
       "      <td>86.5</td>\n",
       "      <td>Mkt&amp;Fin</td>\n",
       "      <td>66.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>65.00</td>\n",
       "      <td>Central</td>\n",
       "      <td>68.00</td>\n",
       "      <td>Central</td>\n",
       "      <td>Arts</td>\n",
       "      <td>64.00</td>\n",
       "      <td>Comm&amp;Mgmt</td>\n",
       "      <td>No</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Mkt&amp;Fin</td>\n",
       "      <td>57.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>56.00</td>\n",
       "      <td>Central</td>\n",
       "      <td>52.00</td>\n",
       "      <td>Central</td>\n",
       "      <td>Science</td>\n",
       "      <td>52.00</td>\n",
       "      <td>Sci&amp;Tech</td>\n",
       "      <td>No</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Mkt&amp;HR</td>\n",
       "      <td>59.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>85.80</td>\n",
       "      <td>Central</td>\n",
       "      <td>73.60</td>\n",
       "      <td>Central</td>\n",
       "      <td>Commerce</td>\n",
       "      <td>73.30</td>\n",
       "      <td>Comm&amp;Mgmt</td>\n",
       "      <td>No</td>\n",
       "      <td>96.8</td>\n",
       "      <td>Mkt&amp;Fin</td>\n",
       "      <td>55.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender  ssc_p    ssc_b  hsc_p    hsc_b     hsc_s  degree_p   degree_t  \\\n",
       "0      M  67.00   Others  91.00   Others  Commerce     58.00   Sci&Tech   \n",
       "1      M  79.33  Central  78.33   Others   Science     77.48   Sci&Tech   \n",
       "2      M  65.00  Central  68.00  Central      Arts     64.00  Comm&Mgmt   \n",
       "3      M  56.00  Central  52.00  Central   Science     52.00   Sci&Tech   \n",
       "4      M  85.80  Central  73.60  Central  Commerce     73.30  Comm&Mgmt   \n",
       "\n",
       "  workex  etest_p specialisation  mba_p  \n",
       "0     No     55.0         Mkt&HR  58.80  \n",
       "1    Yes     86.5        Mkt&Fin  66.28  \n",
       "2     No     75.0        Mkt&Fin  57.80  \n",
       "3     No     66.0         Mkt&HR  59.43  \n",
       "4     No     96.8        Mkt&Fin  55.50  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import dataset\n",
    "X = pd.read_csv(f\"./datasets/cleaned/{datasets[1]}_X.csv\")\n",
    "X = X.drop(\"Unnamed: 0\", axis=1)\n",
    "y = pd.read_csv(f\"./datasets/cleaned/{datasets[1]}_y.csv\")\n",
    "y = y.drop(\"Unnamed: 0\", axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_types_df = pd.read_csv(f\"datasets/cleaned/datatypes/breast.csv\")\n",
    "\n",
    "# feature_inidices = list(map(int, list(features_types_df)))\n",
    "# features_names = pd.Series(list(features_types_df.T[0]))\n",
    "# features_types = pd.Series(list(map(int, list(features_types_df.T[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define data containers for features\n",
    "#input_queue: indices of features to be check\n",
    "#output_queue: indices of checked features (order is coresponding to given loss)\n",
    "#data_losses: data container for each step losses storing\n",
    "# input_queue = pd.Series(feature_inidices, dtype=int)\n",
    "# output_queue = pd.Series([], dtype=int)\n",
    "# run_losses = pd.Series([], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Funkcje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Methods\n",
    "from sklearn.model_selection import train_test_split\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "# Pipeline preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_col_name(output_queue, col_names):\n",
    "  output_features_names = pd.Series(dtype=\"string\")\n",
    "  for i in range(len(output_queue)):\n",
    "    output_features_names = pd.concat([output_features_names, pd.Series([col_names[output_queue].iloc[i]])])\n",
    "  return output_features_names\n",
    "\n",
    "# return preprocesing for num features only\n",
    "def num_feat_preprocessing(num_names):\n",
    "  preprocess = make_column_transformer(\n",
    "      (StandardScaler(), num_names)\n",
    "  )\n",
    "  return preprocess\n",
    "\n",
    "# return preprocesing for cat features only\n",
    "def cat_feat_preprocessing(cat_names):\n",
    "  preprocess = make_column_transformer(\n",
    "      (OneHotEncoder(), cat_names)\n",
    "  )\n",
    "  return preprocess\n",
    "\n",
    "# return preprocesing for all features\n",
    "def feat_preprocessing(num_names, cat_names):\n",
    "  preprocess = make_column_transformer(\n",
    "      (OneHotEncoder(), cat_names),\n",
    "      (StandardScaler(), num_names)\n",
    "  )\n",
    "  return preprocess\n",
    "\n",
    "def select_preprocessing_for_single_feat(init_index, col_names, col_types):\n",
    "  #tested\n",
    "  cat_feat = []\n",
    "  num_feat = []\n",
    "\n",
    "  print(f\"pre: {col_names}\\n{col_types}\")\n",
    "  print(f\"pre init: {init_index}\")\n",
    "\n",
    "  if col_types[int(init_index)] == 0:\n",
    "    num_feat.append(col_names[int(init_index)])\n",
    "    #run StandardScaler function\n",
    "    preprocess = num_feat_preprocessing(num_feat)\n",
    "  else:\n",
    "    cat_feat.append(col_names[int(init_index)])\n",
    "    preprocess = cat_feat_preprocessing(cat_feat)\n",
    "  return preprocess\n",
    "\n",
    "def select_preprocessing_for_many_feat(output_col_names, col_types, col_names):\n",
    "  cat_feat = []\n",
    "  num_feat = []\n",
    "\n",
    "  for feat_index in output_col_names:\n",
    "    if col_types[feat_index] == 0:\n",
    "      num_feat.append(col_names[feat_index])\n",
    "    else:\n",
    "      cat_feat.append(col_names[feat_index])\n",
    "  \n",
    "  print(cat_feat)\n",
    "  print(num_feat)\n",
    "  \n",
    "  #select preprocesing\n",
    "  if len(cat_feat) == 0 and len(num_feat) != 0:\n",
    "    preprocess = num_feat_preprocessing(num_feat)\n",
    "    print(\"Jestem tu!!!\")\n",
    "  if len(cat_feat) != 0 and len(num_feat) == 0:\n",
    "    preprocess = cat_feat_preprocessing(cat_feat)\n",
    "  else:\n",
    "    preprocess = feat_preprocessing(num_feat, cat_feat)\n",
    "  return preprocess\n",
    "\n",
    "def create_data_frame_for_feat(output_col_names, dataset_df):\n",
    "  # if len(output_col_names) == 1:\n",
    "  #   return pd.DataFrame(dataset_df[output_col_names], columns=[output_col_names])\n",
    "  # else:\n",
    "    return dataset_df[output_col_names]\n",
    "\n",
    "def calculate_loss_for_single_feat(X_df, y_lab, init_index, train_indices, test_indices, f_names, f_types):\n",
    "  X = X_df\n",
    "  y = y_lab\n",
    "\n",
    "  print(f\"\\n funkcja: {f_names} \\n {f_types}\")\n",
    "  print(init_index)\n",
    "\n",
    "  preprocess = select_preprocessing_for_single_feat(init_index=int(init_index),\n",
    "                                                  col_names=f_names,\n",
    "                                                  col_types=f_types)\n",
    "\n",
    "    # Split beetwen three dataset (test, train, val)\n",
    "  # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1337, shuffle=True)\n",
    "  # X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=1337)\n",
    "\n",
    "  clf = make_pipeline(\n",
    "      preprocess,\n",
    "      ExplainableBoostingClassifier()\n",
    "  )\n",
    "\n",
    "  clf.fit(X.iloc[train_indices], y.iloc[train_indices])\n",
    "\n",
    "  #Prediction\n",
    "  y_preds = clf.predict(X.iloc[test_indices])\n",
    "\n",
    "  #Calculate logloss\n",
    "  # p = np.clip(y_preds, 1e-12, 1. - 1e-12)\n",
    "  # result= np.mean(y_test * -np.log(p) + (1. - y_test) * (-np.log(1. - p)))\n",
    "  result = log_loss(y.iloc[test_indices], y_preds)\n",
    "\n",
    "  return(result, X.columns[0])\n",
    "\n",
    "def calculate_loss_for_multi_feat(X_df, y_lab, output_with_to_pred_feat, train_indices, test_indices, f_names, f_types):\n",
    "  print(X_df)\n",
    "  print(y_lab)\n",
    "  X = X_df\n",
    "  y = y_lab\n",
    "\n",
    "  preprocess = select_preprocessing_for_many_feat(output_col_names=output_with_to_pred_feat,\n",
    "                                                  col_types=f_names,\n",
    "                                                  col_names=f_types)\n",
    "  print(preprocess)\n",
    "    # Split beetwen three dataset (test, train, val)\n",
    "  # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1337, shuffle=True)\n",
    "  # X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=1337)\n",
    "\n",
    "  clf = make_pipeline(\n",
    "      preprocess,\n",
    "      ExplainableBoostingClassifier()\n",
    "  )\n",
    "\n",
    "  clf.fit(X.iloc[train_indices], y.iloc[train_indices])\n",
    "\n",
    "  #Prediction\n",
    "  y_preds = clf.predict(X.iloc[test_indices])\n",
    "\n",
    "  #Calculate logloss\n",
    "  # p = np.clip(y_preds, 1e-12, 1. - 1e-12)\n",
    "  # result= np.mean(y_test * -np.log(p) + (1. - y_test) * (-np.log(1. - p)))\n",
    "  result = log_loss(y.iloc[test_indices], y_preds)\n",
    "\n",
    "  return(result, X.columns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Obliczanie strat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_data_indices(output_queue, input_queue):\n",
    "  temp_list = list(output_queue)\n",
    "  indices_list = []\n",
    "  for index_input in input_queue:\n",
    "    temp_list.append(index_input)\n",
    "    indices_list.append(temp_list)\n",
    "    temp_list = list(output_queue)\n",
    "  return indices_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_save_losses(fold_id, clf_name, dataset_name, train_idx, test_idx):\n",
    "    features_types_df = pd.read_csv(f\"datasets/cleaned/datatypes/{dataset_name}.csv\")\n",
    "\n",
    "    feature_inidices = list(map(int, list(features_types_df)))\n",
    "    features_names = pd.Series(list(features_types_df.T[0]))\n",
    "    features_types = pd.Series(list(map(int, list(features_types_df.T[1]))))\n",
    "    print(f\"\\n{features_types}\")\n",
    "\n",
    "    #define data containers for features\n",
    "    #input_queue: indices of features to be check\n",
    "    #output_queue: indices of checked features (order is coresponding to given loss)\n",
    "    #data_losses: data container for each step losses storing\n",
    "    input_queue = pd.Series(feature_inidices, dtype=int)\n",
    "    output_queue = pd.Series([], dtype=int)\n",
    "    run_losses = pd.Series([], dtype=float)\n",
    "\n",
    "    initial_index = 0\n",
    "    test_df = create_data_frame_for_feat(get_output_col_name([initial_index], features_names), X)\n",
    "    result, name = calculate_loss_for_single_feat(test_df, y, initial_index, train_idx, test_idx, features_names, features_types)\n",
    "\n",
    "    initial_error = result\n",
    "    initial_name = name\n",
    "\n",
    "    losses_vector = np.zeros(len(input_queue))\n",
    "    for index in feature_inidices:\n",
    "        test_df = create_data_frame_for_feat(get_output_col_name([index], features_names), X)\n",
    "        result, name = calculate_loss_for_single_feat(test_df, y, index,train_idx, test_idx, features_names, features_types)\n",
    "        losses_vector[index] = result\n",
    "        print(name)\n",
    "\n",
    "    run_losses[0] = losses_vector\n",
    "    # get index of smallest loses feature\n",
    "    feature_selected_index = input_queue.iloc[run_losses[0].argmin()]\n",
    "    #pop index from input queue\n",
    "    input_queue.pop(feature_selected_index)\n",
    "    #add selected index to output_queue\n",
    "    output_queue = pd.concat([output_queue, pd.Series(feature_selected_index)])\n",
    "\n",
    "    for i in range(len(input_queue)):\n",
    "        losses_vector = np.zeros(len(input_queue))\n",
    "        lista_test = concat_data_indices(output_queue, input_queue)\n",
    "\n",
    "        for j in range(len(input_queue)):\n",
    "            test_df = create_data_frame_for_feat(get_output_col_name(list(lista_test[j]), features_names), X)\n",
    "            result, name = calculate_loss_for_multi_feat(test_df, y, list(lista_test[j]), train_idx, test_idx, features_names, features_types)\n",
    "            losses_vector[j] = result\n",
    "    \n",
    "    run_losses[i+1] = losses_vector\n",
    "    # get index of smallest loses feature\n",
    "    feature_selected_index = input_queue.iloc[run_losses[i+1].argmin()]\n",
    "    input_queue.pop(feature_selected_index)\n",
    "    #add selected index to output_queue\n",
    "    output_queue = pd.concat([output_queue, pd.Series(feature_selected_index)])\n",
    "\n",
    "    sorted_results = np.zeros(len(run_losses))\n",
    "    # sorted_results[0] = initial_error\n",
    "    for i in range(len(run_losses)):\n",
    "        print(run_losses[i].min())\n",
    "        sorted_results[i] = run_losses[i].min()\n",
    "\n",
    "    final_results = []\n",
    "    initial_result = [initial_index, \"initial_error\", initial_error]\n",
    "    final_results.append(initial_result)\n",
    "\n",
    "    for i in range(len(output_queue)):\n",
    "        temp_result = [output_queue.iloc[i],features_names[output_queue].iloc[i], sorted_results[i]]\n",
    "        final_results.append(temp_result)\n",
    "    pd.DataFrame(final_results).to_csv(index=False, path_or_buf=f\"./test_results/feature_density/{clf_name}_{dataset_name}_{fold_id}.csv\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0     1\n",
      "1     0\n",
      "2     1\n",
      "3     0\n",
      "4     1\n",
      "5     1\n",
      "6     0\n",
      "7     1\n",
      "8     1\n",
      "9     0\n",
      "10    1\n",
      "11    0\n",
      "dtype: int64\n",
      "\n",
      " funkcja: 0             gender\n",
      "1              ssc_p\n",
      "2              ssc_b\n",
      "3              hsc_p\n",
      "4              hsc_b\n",
      "5              hsc_s\n",
      "6           degree_p\n",
      "7           degree_t\n",
      "8             workex\n",
      "9            etest_p\n",
      "10    specialisation\n",
      "11             mba_p\n",
      "dtype: object \n",
      " 0     1\n",
      "1     0\n",
      "2     1\n",
      "3     0\n",
      "4     1\n",
      "5     1\n",
      "6     0\n",
      "7     1\n",
      "8     1\n",
      "9     0\n",
      "10    1\n",
      "11    0\n",
      "dtype: int64\n",
      "\n",
      " funkcja: 0             gender\n",
      "1              ssc_p\n",
      "2              ssc_b\n",
      "3              hsc_p\n",
      "4              hsc_b\n",
      "5              hsc_s\n",
      "6           degree_p\n",
      "7           degree_t\n",
      "8             workex\n",
      "9            etest_p\n",
      "10    specialisation\n",
      "11             mba_p\n",
      "dtype: object \n",
      " 0     1\n",
      "1     0\n",
      "2     1\n",
      "3     0\n",
      "4     1\n",
      "5     1\n",
      "6     0\n",
      "7     1\n",
      "8     1\n",
      "9     0\n",
      "10    1\n",
      "11    0\n",
      "dtype: int64\n",
      "gender\n",
      "\n",
      " funkcja: 0             gender\n",
      "1              ssc_p\n",
      "2              ssc_b\n",
      "3              hsc_p\n",
      "4              hsc_b\n",
      "5              hsc_s\n",
      "6           degree_p\n",
      "7           degree_t\n",
      "8             workex\n",
      "9            etest_p\n",
      "10    specialisation\n",
      "11             mba_p\n",
      "dtype: object \n",
      " 0     1\n",
      "1     0\n",
      "2     1\n",
      "3     0\n",
      "4     1\n",
      "5     1\n",
      "6     0\n",
      "7     1\n",
      "8     1\n",
      "9     0\n",
      "10    1\n",
      "11    0\n",
      "dtype: int64\n",
      "ssc_p\n",
      "\n",
      " funkcja: 0             gender\n",
      "1              ssc_p\n",
      "2              ssc_b\n",
      "3              hsc_p\n",
      "4              hsc_b\n",
      "5              hsc_s\n",
      "6           degree_p\n",
      "7           degree_t\n",
      "8             workex\n",
      "9            etest_p\n",
      "10    specialisation\n",
      "11             mba_p\n",
      "dtype: object \n",
      " 0     1\n",
      "1     0\n",
      "2     1\n",
      "3     0\n",
      "4     1\n",
      "5     1\n",
      "6     0\n",
      "7     1\n",
      "8     1\n",
      "9     0\n",
      "10    1\n",
      "11    0\n",
      "dtype: int64\n",
      "ssc_b\n",
      "\n",
      " funkcja: 0             gender\n",
      "1              ssc_p\n",
      "2              ssc_b\n",
      "3              hsc_p\n",
      "4              hsc_b\n",
      "5              hsc_s\n",
      "6           degree_p\n",
      "7           degree_t\n",
      "8             workex\n",
      "9            etest_p\n",
      "10    specialisation\n",
      "11             mba_p\n",
      "dtype: object \n",
      " 0     1\n",
      "1     0\n",
      "2     1\n",
      "3     0\n",
      "4     1\n",
      "5     1\n",
      "6     0\n",
      "7     1\n",
      "8     1\n",
      "9     0\n",
      "10    1\n",
      "11    0\n",
      "dtype: int64\n",
      "hsc_p\n",
      "\n",
      " funkcja: 0             gender\n",
      "1              ssc_p\n",
      "2              ssc_b\n",
      "3              hsc_p\n",
      "4              hsc_b\n",
      "5              hsc_s\n",
      "6           degree_p\n",
      "7           degree_t\n",
      "8             workex\n",
      "9            etest_p\n",
      "10    specialisation\n",
      "11             mba_p\n",
      "dtype: object \n",
      " 0     1\n",
      "1     0\n",
      "2     1\n",
      "3     0\n",
      "4     1\n",
      "5     1\n",
      "6     0\n",
      "7     1\n",
      "8     1\n",
      "9     0\n",
      "10    1\n",
      "11    0\n",
      "dtype: int64\n",
      "hsc_b\n",
      "\n",
      " funkcja: 0             gender\n",
      "1              ssc_p\n",
      "2              ssc_b\n",
      "3              hsc_p\n",
      "4              hsc_b\n",
      "5              hsc_s\n",
      "6           degree_p\n",
      "7           degree_t\n",
      "8             workex\n",
      "9            etest_p\n",
      "10    specialisation\n",
      "11             mba_p\n",
      "dtype: object \n",
      " 0     1\n",
      "1     0\n",
      "2     1\n",
      "3     0\n",
      "4     1\n",
      "5     1\n",
      "6     0\n",
      "7     1\n",
      "8     1\n",
      "9     0\n",
      "10    1\n",
      "11    0\n",
      "dtype: int64\n",
      "hsc_s\n",
      "\n",
      " funkcja: 0             gender\n",
      "1              ssc_p\n",
      "2              ssc_b\n",
      "3              hsc_p\n",
      "4              hsc_b\n",
      "5              hsc_s\n",
      "6           degree_p\n",
      "7           degree_t\n",
      "8             workex\n",
      "9            etest_p\n",
      "10    specialisation\n",
      "11             mba_p\n",
      "dtype: object \n",
      " 0     1\n",
      "1     0\n",
      "2     1\n",
      "3     0\n",
      "4     1\n",
      "5     1\n",
      "6     0\n",
      "7     1\n",
      "8     1\n",
      "9     0\n",
      "10    1\n",
      "11    0\n",
      "dtype: int64\n",
      "degree_p\n",
      "\n",
      " funkcja: 0             gender\n",
      "1              ssc_p\n",
      "2              ssc_b\n",
      "3              hsc_p\n",
      "4              hsc_b\n",
      "5              hsc_s\n",
      "6           degree_p\n",
      "7           degree_t\n",
      "8             workex\n",
      "9            etest_p\n",
      "10    specialisation\n",
      "11             mba_p\n",
      "dtype: object \n",
      " 0     1\n",
      "1     0\n",
      "2     1\n",
      "3     0\n",
      "4     1\n",
      "5     1\n",
      "6     0\n",
      "7     1\n",
      "8     1\n",
      "9     0\n",
      "10    1\n",
      "11    0\n",
      "dtype: int64\n",
      "degree_t\n",
      "\n",
      " funkcja: 0             gender\n",
      "1              ssc_p\n",
      "2              ssc_b\n",
      "3              hsc_p\n",
      "4              hsc_b\n",
      "5              hsc_s\n",
      "6           degree_p\n",
      "7           degree_t\n",
      "8             workex\n",
      "9            etest_p\n",
      "10    specialisation\n",
      "11             mba_p\n",
      "dtype: object \n",
      " 0     1\n",
      "1     0\n",
      "2     1\n",
      "3     0\n",
      "4     1\n",
      "5     1\n",
      "6     0\n",
      "7     1\n",
      "8     1\n",
      "9     0\n",
      "10    1\n",
      "11    0\n",
      "dtype: int64\n",
      "workex\n",
      "\n",
      " funkcja: 0             gender\n",
      "1              ssc_p\n",
      "2              ssc_b\n",
      "3              hsc_p\n",
      "4              hsc_b\n",
      "5              hsc_s\n",
      "6           degree_p\n",
      "7           degree_t\n",
      "8             workex\n",
      "9            etest_p\n",
      "10    specialisation\n",
      "11             mba_p\n",
      "dtype: object \n",
      " 0     1\n",
      "1     0\n",
      "2     1\n",
      "3     0\n",
      "4     1\n",
      "5     1\n",
      "6     0\n",
      "7     1\n",
      "8     1\n",
      "9     0\n",
      "10    1\n",
      "11    0\n",
      "dtype: int64\n",
      "etest_p\n",
      "\n",
      " funkcja: 0             gender\n",
      "1              ssc_p\n",
      "2              ssc_b\n",
      "3              hsc_p\n",
      "4              hsc_b\n",
      "5              hsc_s\n",
      "6           degree_p\n",
      "7           degree_t\n",
      "8             workex\n",
      "9            etest_p\n",
      "10    specialisation\n",
      "11             mba_p\n",
      "dtype: object \n",
      " 0     1\n",
      "1     0\n",
      "2     1\n",
      "3     0\n",
      "4     1\n",
      "5     1\n",
      "6     0\n",
      "7     1\n",
      "8     1\n",
      "9     0\n",
      "10    1\n",
      "11    0\n",
      "dtype: int64\n",
      "specialisation\n",
      "\n",
      " funkcja: 0             gender\n",
      "1              ssc_p\n",
      "2              ssc_b\n",
      "3              hsc_p\n",
      "4              hsc_b\n",
      "5              hsc_s\n",
      "6           degree_p\n",
      "7           degree_t\n",
      "8             workex\n",
      "9            etest_p\n",
      "10    specialisation\n",
      "11             mba_p\n",
      "dtype: object \n",
      " 0     1\n",
      "1     0\n",
      "2     1\n",
      "3     0\n",
      "4     1\n",
      "5     1\n",
      "6     0\n",
      "7     1\n",
      "8     1\n",
      "9     0\n",
      "10    1\n",
      "11    0\n",
      "dtype: int64\n",
      "mba_p\n",
      "     ssc_p gender\n",
      "0    67.00      M\n",
      "1    79.33      M\n",
      "2    65.00      M\n",
      "3    56.00      M\n",
      "4    85.80      M\n",
      "..     ...    ...\n",
      "210  80.60      M\n",
      "211  58.00      M\n",
      "212  67.00      M\n",
      "213  74.00      F\n",
      "214  62.00      M\n",
      "\n",
      "[215 rows x 2 columns]\n",
      "     status\n",
      "0         1\n",
      "1         1\n",
      "2         1\n",
      "3         0\n",
      "4         1\n",
      "..      ...\n",
      "210       1\n",
      "211       1\n",
      "212       1\n",
      "213       1\n",
      "214       0\n",
      "\n",
      "[215 rows x 1 columns]\n",
      "[0, 1]\n",
      "[]\n",
      "ColumnTransformer(transformers=[('onehotencoder', OneHotEncoder(), [0, 1])])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bart/anaconda3/envs/mainenv/lib/python3.9/site-packages/interpret/utils/all.py:317: RuntimeWarning: Sparse data not fully supported, will be densified for now, may cause OOM\n",
      "  warnings.warn(warn_msg, RuntimeWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found unknown categories [46.0, 54.4, 56.0, 64.6, 69.7, 70.5, 80.92, 85.8] in column 0 during transform",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5722/3036629698.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfold_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mcalculate_and_save_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"EBM\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5722/1131517663.py\u001b[0m in \u001b[0;36mcalculate_and_save_losses\u001b[0;34m(fold_id, clf_name, dataset_name, train_idx, test_idx)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_data_frame_for_feat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_output_col_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlista_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_loss_for_multi_feat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlista_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mlosses_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5722/54228974.py\u001b[0m in \u001b[0;36mcalculate_loss_for_multi_feat\u001b[0;34m(X_df, y_lab, output_with_to_pred_feat, train_indices, test_indices, f_names, f_types)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0;31m#Prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m   \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m   \u001b[0;31m#Calculate logloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m         Xs = self._fit_transform(\n\u001b[0m\u001b[1;32m    749\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[0;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[1;32m    604\u001b[0m         )\n\u001b[1;32m    605\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m             return Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m    607\u001b[0m                 delayed(func)(\n\u001b[1;32m    608\u001b[0m                     \u001b[0mtransformer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mainenv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mainenv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mainenv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mainenv/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mainenv/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mainenv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mainenv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_transform_one\u001b[0;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_transform_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m     \u001b[0;31m# if we have a weight for this transformer, multiply output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;31m# validation of X happens in _check_X called by _transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mwarn_on_unknown\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m         X_int, X_mask = self._transform(\n\u001b[0m\u001b[1;32m    510\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mainenv/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown)\u001b[0m\n\u001b[1;32m    140\u001b[0m                         \u001b[0;34m\" during transform\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                     )\n\u001b[0;32m--> 142\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mwarn_on_unknown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found unknown categories [46.0, 54.4, 56.0, 64.6, 69.7, 70.5, 80.92, 85.8] in column 0 during transform"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "n_datasets = len(datasets)\n",
    "n_splits = 10\n",
    "# repeats 5, splits 2\n",
    "skf = StratifiedKFold(n_splits=n_splits, random_state=1234, shuffle=True)\n",
    "\n",
    "# loss = np.zeros((len(clfs)+1, n_datasets, n_splits))\n",
    "\n",
    "for fold_id, (train, test) in enumerate(skf.split(X, y)):\n",
    "    calculate_and_save_losses(fold_id, \"EBM\", datasets[1], train_idx=train, test_idx=test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_id, (train, test) in enumerate(skf.split(X, y)):\n",
    "\n",
    "            clf = clone(clfs[clf_name])\n",
    "            clf_pipeline = make_pipeline(\n",
    "                preprocess,\n",
    "                clf\n",
    "            )\n",
    "                \n",
    "            clf_pipeline.fit(X.iloc[train], y.iloc[train])\n",
    "            y_preds = clf_pipeline.predict(X.iloc[test])\n",
    "            fpr, tpr, thresholds = metrics.roc_curve(y.iloc[test], y_preds)\n",
    "            auc_scores[clf_id, data_id, fold_id] = metrics.auc(fpr, tpr)\n",
    "            loss[clf_id, data_id, fold_id] = log_loss(y.iloc[test], y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define data variable for initial loss\n",
    "# initial_index = [np.random.choice(input_queue)]\n",
    "# initial_index = np.random.choice(input_queue)\n",
    "initial_index = 0\n",
    "test_df = create_data_frame_for_feat(get_output_col_name([initial_index], features_names), X)\n",
    "result, name = calculate_loss_for_single_feat(test_df, y, initial_index)\n",
    "\n",
    "initial_error = result\n",
    "initial_name = name\n",
    "\n",
    "losses_vector = np.zeros(len(input_queue))\n",
    "for index in feature_inidices:\n",
    "  test_df = create_data_frame_for_feat(get_output_col_name([index], features_names), X)\n",
    "  result, name = calculate_loss_for_single_feat(test_df, y, index)\n",
    "  losses_vector[index] = result\n",
    "  print(name)\n",
    "\n",
    "run_losses[0] = losses_vector\n",
    "# get index of smallest loses feature\n",
    "feature_selected_index = input_queue.iloc[run_losses[0].argmin()]\n",
    "#pop index from input queue\n",
    "input_queue.pop(feature_selected_index)\n",
    "#add selected index to output_queue\n",
    "output_queue = pd.concat([output_queue, pd.Series(feature_selected_index)])\n",
    "\n",
    "for i in range(len(input_queue)):\n",
    "  losses_vector = np.zeros(len(input_queue))\n",
    "  lista_test = concat_data_indices(output_queue, input_queue)\n",
    "\n",
    "  for j in range(len(input_queue)):\n",
    "    test_df = create_data_frame_for_feat(get_output_col_name(list(lista_test[j]), features_names), X)\n",
    "    result, name = calculate_loss_for_multi_feat(test_df, y, list(lista_test[j]))\n",
    "    losses_vector[j] = result\n",
    "  \n",
    "  run_losses[i+1] = losses_vector\n",
    "  # get index of smallest loses feature\n",
    "  feature_selected_index = input_queue.iloc[run_losses[i+1].argmin()]\n",
    "  input_queue.pop(feature_selected_index)\n",
    "  #add selected index to output_queue\n",
    "  output_queue = pd.concat([output_queue, pd.Series(feature_selected_index)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_results = np.zeros(len(run_losses))\n",
    "# sorted_results[0] = initial_error\n",
    "for i in range(len(run_losses)):\n",
    "    print(run_losses[i].min())\n",
    "    sorted_results[i] = run_losses[i].min()\n",
    "\n",
    "final_results = []\n",
    "initial_result = [initial_index, \"initial_error\", initial_error]\n",
    "final_results.append(initial_result)\n",
    "\n",
    "for i in range(len(output_queue)):\n",
    "    temp_result = [output_queue.iloc[i],features_names[output_queue].iloc[i], sorted_results[i]]\n",
    "    final_results.append(temp_result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(final_results).to_csv(index=False, path_or_buf=\"./test_results/feature_density/ebm_breast.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54107a2a0eb6a0b2996cb7a94c16d9283b5dc7f969a30a8a01f6dbe77c679ea9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mainenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
